{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"transformers==4.31.0\" \"datasets[s3]==2.13.0\" sagemaker --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_PROFILE=dev-admin\n",
      "env: AWS_REGION=us-east-1\n",
      "env: HF_HOME=~/.cache/huggingface\n",
      "env: TOKENIZERS_PARALLELISM=fale\n"
     ]
    }
   ],
   "source": [
    "%env AWS_PROFILE=dev-admin\n",
    "%env AWS_REGION=us-east-1\n",
    "%env HF_HOME=~/.cache/huggingface\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.tokens:Loading cached SSO token for slu-sso\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker bucket: sagemaker-ms-thesis-llm\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "from scripts.aws_init import init_sagemaker\n",
    "\n",
    "sagemaker_session_bucket = \"sagemaker-ms-thesis-llm\"\n",
    "# role = \"arn:aws:iam::171706357329:role/service-role/SageMaker-ComputeAdmin\"\n",
    "role = \"arn:aws:iam::171706357329:role/service-role/AmazonSageMakerServiceCatalogProductsExecutionRole\"\n",
    "\n",
    "sess = init_sagemaker(sagemaker_session_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/andrewbeiler/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login, HfFolder\n",
    "\n",
    "login(token=HfFolder.get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\" # sharded weights\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,use_auth_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Training Job Name \n",
    "job_name = f'goatNumAndAlphaInstruct-75-25-100K-QLORA'\n",
    "model_output_path = f's3://{sagemaker_session_bucket}/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset': \"abeiler/GOAT_Numeric_and_Alpha_Instruct\",\n",
    "  'data_rev': \"75_25_100K\",\n",
    "  'epochs': 1,                                      # number of training epochs\n",
    "  'per_device_train_batch_size': 4,                 # batch size for training\n",
    "  'lr': 1e-4,                                       # learning rate used during training\n",
    "  'merge_weights': True,                            # wether to merge LoRA into the model (needs more memory)\n",
    "  'lora_r': 64,\n",
    "  'lora_alpha': 16,\n",
    "  'lora_dropout': 0.1,\n",
    "  'output_data_path': '/opt/ml/output',\n",
    "  'push_to_hub': True,                            # Defines if we want to push the model to the hub\n",
    "  'hub_model_id': job_name, # The model id of the model to push to the hub\n",
    "  'hub_strategy': 'every_save',                   # The strategy to use when pushing the model to the hub\n",
    "  'hub_token': HfFolder.get_token()   \n",
    "}\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_clm.py',      # train script\n",
    "    source_dir           = 'phil-examples',   # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.4xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    "    output_path          = f\"{model_output_path}/\",\n",
    "    code_location        = model_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Llama-2-7b-hf\n",
      "goatNumAndAlphaInstruct-75-25-100K-QLORA\n"
     ]
    }
   ],
   "source": [
    "print(model_id)\n",
    "print(job_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start our training job, with the `.fit()` method passing our S3 path to the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS_PROFILE=dev-admin\n",
      "AWS_REGION=us-east-1\n",
      "COMMAND_MODE=unix2003\n",
      "HF_HOME=/Users/andrewbeiler/.cache/huggingface\n",
      "HOME=/Users/andrewbeiler\n",
      "HOMEBREW_CELLAR=/opt/homebrew/Cellar\n",
      "HOMEBREW_PREFIX=/opt/homebrew\n",
      "HOMEBREW_REPOSITORY=/opt/homebrew\n",
      "INFOPATH=/opt/homebrew/share/info:\n",
      "LOGNAME=andrewbeiler\n",
      "LaunchInstanceID=96BD37E2-9837-4CCA-AAD3-BA07FFD77775\n",
      "MANPATH=/opt/homebrew/share/man::\n",
      "MallocNanoZone=0\n",
      "OLDPWD=/Users/andrewbeiler/projects/llm-data-driven-optimization\n",
      "ORIGINAL_XDG_CURRENT_DESKTOP=undefined\n",
      "PATH=/Users/andrewbeiler/projects/llm-data-driven-optimization/venv_310/bin:/Library/Frameworks/Python.framework/Versions/3.8/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/Applications/VMware Fusion.app/Contents/Public:/Library/Apple/usr/bin:/Library/Frameworks/Mono.framework/Versions/Current/Commands\n",
      "PWD=/Users/andrewbeiler/projects/llm-data-driven-optimization\n",
      "SECURITYSESSIONID=186b1\n",
      "SHELL=/bin/zsh\n",
      "SHLVL=1\n",
      "SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.eHAHfG28vB/Listeners\n",
      "TMPDIR=/var/folders/b7/s1kskgdx4txd_4ctzl8t3xpr0000gn/T/\n",
      "USER=andrewbeiler\n",
      "VSCODE_AMD_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess\n",
      "VSCODE_CODE_CACHE_PATH=/Users/andrewbeiler/Library/Application Support/Code/CachedData/8b617bd08fd9e3fc94d14adb8d358b56e3f72314\n",
      "VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost\n",
      "VSCODE_CWD=/\n",
      "VSCODE_HANDLES_UNCAUGHT_ERRORS=true\n",
      "VSCODE_IPC_HOOK=/Users/andrewbeiler/Library/Application Support/Code/1.82-main.sock\n",
      "VSCODE_NLS_CONFIG={\"locale\":\"en-us\",\"osLocale\":\"en-us\",\"availableLanguages\":{},\"_languagePackSupport\":true}\n",
      "VSCODE_PID=584\n",
      "XPC_FLAGS=0x0\n",
      "XPC_SERVICE_NAME=0\n",
      "__CFBundleIdentifier=com.microsoft.VSCode\n",
      "__CF_USER_TEXT_ENCODING=0x1F5:0x0:0x0\n",
      "ELECTRON_RUN_AS_NODE=1\n",
      "VSCODE_L10N_BUNDLE_LOCATION=\n",
      "LATEXWORKSHOP_DOCKER_LATEX=\n",
      "PYTHONUNBUFFERED=1\n",
      "PYTHONIOENCODING=utf-8\n",
      "VIRTUAL_ENV=/Users/andrewbeiler/projects/llm-data-driven-optimization/venv_310\n",
      "PS1=(venv_310) \n",
      "VIRTUAL_ENV_PROMPT=(venv_310) \n",
      "LC_CTYPE=UTF-8\n",
      "PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "TERM=xterm-color\n",
      "CLICOLOR=1\n",
      "FORCE_COLOR=1\n",
      "CLICOLOR_FORCE=1\n",
      "PAGER=cat\n",
      "GIT_PAGER=cat\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "_=/usr/bin/printenv\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "! source ~/.zshrc\n",
    "! printenv\n",
    "print(os.getenv(\"TELE_API\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***REMOVED***\n",
      "***REMOVED***\n"
     ]
    }
   ],
   "source": [
    "import my_const\n",
    "\n",
    "api_key = my_const.TELE_API_KEY\n",
    "usr_id = my_const.TELE_USER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.tokens:Loading cached SSO token for slu-sso\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: goatNumAndAlphaInstruct-75-25-100K-QLOR-2023-10-09-17-10-39-967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-09 17:10:41 Starting - Starting the training job...\n",
      "2023-10-09 17:10:57 Starting - Preparing the instances for training......\n",
      "2023-10-09 17:12:14 Downloading - Downloading input data...\n",
      "2023-10-09 17:12:39 Training - Downloading the training image..............................\n",
      "2023-10-09 17:17:36 Training - Training image download completed. Training in progress.....bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2023-10-09 17:18:29,534 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2023-10-09 17:18:29,548 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-09 17:18:29,556 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2023-10-09 17:18:29,558 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2023-10-09 17:18:30,943 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.10 -m pip install -r requirements.txt\n",
      "Collecting transformers==4.33.3 (from -r requirements.txt (line 1))\n",
      "Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.6/7.6 MB 61.9 MB/s eta 0:00:00\n",
      "Collecting peft==0.4.0 (from -r requirements.txt (line 2))\n",
      "Downloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.9/72.9 kB 19.7 MB/s eta 0:00:00\n",
      "Collecting accelerate==0.21.0 (from -r requirements.txt (line 3))\n",
      "Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 244.2/244.2 kB 37.9 MB/s eta 0:00:00\n",
      "Collecting bitsandbytes==0.40.2 (from -r requirements.txt (line 4))\n",
      "Downloading bitsandbytes-0.40.2-py3-none-any.whl (92.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.5/92.5 MB 12.2 MB/s eta 0:00:00\n",
      "Collecting safetensors==0.3.3 (from -r requirements.txt (line 5))\n",
      "Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 68.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tokenizers==0.13.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.13.3)\n",
      "Collecting sagemaker-training==4.7.0 (from -r requirements.txt (line 7))\n",
      "Downloading sagemaker_training-4.7.0.tar.gz (59 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 14.7 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting auto-gptq==0.4.2 (from -r requirements.txt (line 8))\n",
      "Downloading auto_gptq-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 76.8 MB/s eta 0:00:00\n",
      "Collecting optimum (from -r requirements.txt (line 9))\n",
      "Downloading optimum-1.13.2.tar.gz (300 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.0/301.0 kB 38.1 MB/s eta 0:00:00\n",
      "Installing build dependencies: started\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.3->-r requirements.txt (line 1)) (3.12.0)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers==4.33.3->-r requirements.txt (line 1))\n",
      "Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 295.0/295.0 kB 30.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.3->-r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.3->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.3->-r requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.3->-r requirements.txt (line 1)) (2023.5.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.3->-r requirements.txt (line 1)) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.3->-r requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 2)) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training==4.7.0->-r requirements.txt (line 7)) (1.26.132)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sagemaker-training==4.7.0->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from sagemaker-training==4.7.0->-r requirements.txt (line 7)) (23.1.2)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training==4.7.0->-r requirements.txt (line 7)) (1.3.4)\n",
      "Requirement already satisfied: gevent in /opt/conda/lib/python3.10/site-packages (from sagemaker-training==4.7.0->-r requirements.txt (line 7)) (22.10.2)\n",
      "Requirement already satisfied: inotify_simple==1.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training==4.7.0->-r requirements.txt (line 7)) (1.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.15.5 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training==4.7.0->-r requirements.txt (line 7)) (2.3.4)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training==4.7.0->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: protobuf<=3.20.3,>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training==4.7.0->-r requirements.txt (line 7)) (3.20.2)\n",
      "Requirement already satisfied: scipy>=1.2.2 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training==4.7.0->-r requirements.txt (line 7)) (1.10.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from auto-gptq==0.4.2->-r requirements.txt (line 8)) (2.12.0)\n",
      "Collecting rouge (from auto-gptq==0.4.2->-r requirements.txt (line 8))\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Collecting coloredlogs (from optimum->-r requirements.txt (line 9))\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 12.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum->-r requirements.txt (line 9)) (1.11.1)\n",
      "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from optimum->-r requirements.txt (line 9)) (4.28.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.3->-r requirements.txt (line 1)) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.3->-r requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.10/site-packages (from paramiko>=2.4.2->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (4.0.1)\n",
      "Requirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.10/site-packages (from paramiko>=2.4.2->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (40.0.1)\n",
      "Requirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.10/site-packages (from paramiko>=2.4.2->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (1.5.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (3.1.2)\n",
      "INFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers[sentencepiece]>=4.26.0 (from optimum->-r requirements.txt (line 9))\n",
      "Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 95.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.3->-r requirements.txt (line 1)) (0.1.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=0.15.5->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.132 in /opt/conda/lib/python3.10/site-packages (from boto3->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (1.29.132)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (0.6.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum->-r requirements.txt (line 9))\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 21.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (3.8.4)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (0.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.3->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.3->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.3->-r requirements.txt (line 1)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.3->-r requirements.txt (line 1)) (2023.5.7)\n",
      "Requirement already satisfied: zope.event in /opt/conda/lib/python3.10/site-packages (from gevent->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (4.6)\n",
      "Requirement already satisfied: zope.interface in /opt/conda/lib/python3.10/site-packages (from gevent->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (6.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from gevent->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (65.6.3)\n",
      "Requirement already satisfied: greenlet>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from gevent->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (2.0.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.132->boto3->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (2.8.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=3.3->paramiko>=2.4.2->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (1.15.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq==0.4.2->-r requirements.txt (line 8)) (2023.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4.2->sagemaker-training==4.7.0->-r requirements.txt (line 7)) (2.21)\n",
      "Building wheels for collected packages: sagemaker-training, optimum\n",
      "Building wheel for sagemaker-training (setup.py): started\n",
      "Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "Created wheel for sagemaker-training: filename=sagemaker_training-4.7.0-cp310-cp310-linux_x86_64.whl size=78509 sha256=fd55eb9ce59fa8056819262debc8d175586707ad1027cc088e34f0822da6bec1\n",
      "Stored in directory: /root/.cache/pip/wheels/3b/48/2b/166c62ba14389a5d7d3fb956220c9e93aeb14bd21dd61a738c\n",
      "Building wheel for optimum (pyproject.toml): started\n",
      "Building wheel for optimum (pyproject.toml): finished with status 'done'\n",
      "Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=23941607957f0f736a3c3189a6f00f96902daaa4fc8e4131c968fcd44e2631b8\n",
      "Stored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\n",
      "Successfully built sagemaker-training optimum\n",
      "Installing collected packages: safetensors, bitsandbytes, rouge, humanfriendly, huggingface-hub, coloredlogs, transformers, accelerate, peft, sagemaker-training, optimum, auto-gptq\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface-hub 0.14.1\n",
      "Uninstalling huggingface-hub-0.14.1:\n",
      "Successfully uninstalled huggingface-hub-0.14.1\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.28.1\n",
      "Uninstalling transformers-4.28.1:\n",
      "Successfully uninstalled transformers-4.28.1\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.19.0\n",
      "Uninstalling accelerate-0.19.0:\n",
      "Successfully uninstalled accelerate-0.19.0\n",
      "Attempting uninstall: sagemaker-training\n",
      "Found existing installation: sagemaker-training 4.5.0\n",
      "Uninstalling sagemaker-training-4.5.0:\n",
      "Successfully uninstalled sagemaker-training-4.5.0\n",
      "Successfully installed accelerate-0.21.0 auto-gptq-0.4.2 bitsandbytes-0.40.2 coloredlogs-15.0.1 huggingface-hub-0.17.3 humanfriendly-10.0 optimum-1.13.2 peft-0.4.0 rouge-1.0.1 safetensors-0.3.3 sagemaker-training-4.7.0 transformers-4.33.3\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2023-10-09 17:18:50,240 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2023-10-09 17:18:50,240 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2023-10-09 17:18:50,271 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-09 17:18:50,295 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-09 17:18:50,318 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-09 17:18:50,328 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"data_rev\": \"75_25_100K\",\n",
      "        \"dataset\": \"abeiler/GOAT_Numeric_and_Alpha_Instruct\",\n",
      "        \"epochs\": 1,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"hub_model_id\": \"goatNumAndAlphaInstruct-75-25-100K-QLORA\",\n",
      "        \"hub_strategy\": \"every_save\",\n",
      "        \"hub_token\": \"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\",\n",
      "        \"lora_alpha\": 16,\n",
      "        \"lora_dropout\": 0.1,\n",
      "        \"lora_r\": 64,\n",
      "        \"lr\": 0.0001,\n",
      "        \"merge_weights\": true,\n",
      "        \"model_id\": \"meta-llama/Llama-2-7b-hf\",\n",
      "        \"output_data_path\": \"/opt/ml/output\",\n",
      "        \"per_device_train_batch_size\": 4,\n",
      "        \"push_to_hub\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"goatNumAndAlphaInstruct-75-25-100K-QLOR-2023-10-09-17-10-39-967\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ms-thesis-llm/models/goatNumAndAlphaInstruct-75-25-100K-QLOR-2023-10-09-17-10-39-967/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_clm\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_clm.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"data_rev\":\"75_25_100K\",\"dataset\":\"abeiler/GOAT_Numeric_and_Alpha_Instruct\",\"epochs\":1,\"hf_token\":\"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\",\"hub_model_id\":\"goatNumAndAlphaInstruct-75-25-100K-QLORA\",\"hub_strategy\":\"every_save\",\"hub_token\":\"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\",\"lora_alpha\":16,\"lora_dropout\":0.1,\"lora_r\":64,\"lr\":0.0001,\"merge_weights\":true,\"model_id\":\"meta-llama/Llama-2-7b-hf\",\"output_data_path\":\"/opt/ml/output\",\"per_device_train_batch_size\":4,\"push_to_hub\":true}\n",
      "SM_USER_ENTRY_POINT=run_clm.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=run_clm\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=16\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-ms-thesis-llm/models/goatNumAndAlphaInstruct-75-25-100K-QLOR-2023-10-09-17-10-39-967/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"data_rev\":\"75_25_100K\",\"dataset\":\"abeiler/GOAT_Numeric_and_Alpha_Instruct\",\"epochs\":1,\"hf_token\":\"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\",\"hub_model_id\":\"goatNumAndAlphaInstruct-75-25-100K-QLORA\",\"hub_strategy\":\"every_save\",\"hub_token\":\"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\",\"lora_alpha\":16,\"lora_dropout\":0.1,\"lora_r\":64,\"lr\":0.0001,\"merge_weights\":true,\"model_id\":\"meta-llama/Llama-2-7b-hf\",\"output_data_path\":\"/opt/ml/output\",\"per_device_train_batch_size\":4,\"push_to_hub\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"goatNumAndAlphaInstruct-75-25-100K-QLOR-2023-10-09-17-10-39-967\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ms-thesis-llm/models/goatNumAndAlphaInstruct-75-25-100K-QLOR-2023-10-09-17-10-39-967/source/sourcedir.tar.gz\",\"module_name\":\"run_clm\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_clm.py\"}\n",
      "SM_USER_ARGS=[\"--data_rev\",\"75_25_100K\",\"--dataset\",\"abeiler/GOAT_Numeric_and_Alpha_Instruct\",\"--epochs\",\"1\",\"--hf_token\",\"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\",\"--hub_model_id\",\"goatNumAndAlphaInstruct-75-25-100K-QLORA\",\"--hub_strategy\",\"every_save\",\"--hub_token\",\"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\",\"--lora_alpha\",\"16\",\"--lora_dropout\",\"0.1\",\"--lora_r\",\"64\",\"--lr\",\"0.0001\",\"--merge_weights\",\"True\",\"--model_id\",\"meta-llama/Llama-2-7b-hf\",\"--output_data_path\",\"/opt/ml/output\",\"--per_device_train_batch_size\",\"4\",\"--push_to_hub\",\"True\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_DATA_REV=75_25_100K\n",
      "SM_HP_DATASET=abeiler/GOAT_Numeric_and_Alpha_Instruct\n",
      "SM_HP_EPOCHS=1\n",
      "SM_HP_HF_TOKEN=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\n",
      "SM_HP_HUB_MODEL_ID=goatNumAndAlphaInstruct-75-25-100K-QLORA\n",
      "SM_HP_HUB_STRATEGY=every_save\n",
      "SM_HP_HUB_TOKEN=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\n",
      "SM_HP_LORA_ALPHA=16\n",
      "SM_HP_LORA_DROPOUT=0.1\n",
      "SM_HP_LORA_R=64\n",
      "SM_HP_LR=0.0001\n",
      "SM_HP_MERGE_WEIGHTS=true\n",
      "SM_HP_MODEL_ID=meta-llama/Llama-2-7b-hf\n",
      "SM_HP_OUTPUT_DATA_PATH=/opt/ml/output\n",
      "SM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=4\n",
      "SM_HP_PUSH_TO_HUB=true\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.10 run_clm.py --data_rev 75_25_100K --dataset abeiler/GOAT_Numeric_and_Alpha_Instruct --epochs 1 --hf_token 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 --hub_model_id goatNumAndAlphaInstruct-75-25-100K-QLORA --hub_strategy every_save --hub_token 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 --lora_alpha 16 --lora_dropout 0.1 --lora_r 64 --lr 0.0001 --merge_weights True --model_id meta-llama/Llama-2-7b-hf --output_data_path /opt/ml/output --per_device_train_batch_size 4 --push_to_hub True\n",
      "2023-10-09 17:18:50,355 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Logging into the Hugging Face Hub with token hf_weneUFv...\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n",
      "Downloading and preparing dataset json/abeiler--GOAT_Numeric_and_Alpha_Instruct to /root/.cache/huggingface/datasets/abeiler___json/abeiler--GOAT_Numeric_and_Alpha_Instruct-977c350f324ce21d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
      "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/26.2M [00:00<?, ?B/s]#033[A\n",
      "Downloading data:  45%|████▌     | 11.8M/26.2M [00:00<00:00, 118MB/s]#033[A\n",
      "Downloading data:  93%|█████████▎| 24.5M/26.2M [00:00<00:00, 123MB/s]#033[A\n",
      "Downloading data: 100%|██████████| 26.2M/26.2M [00:00<00:00, 48.8MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1616.30it/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 100000 examples [00:00, 286840.62 examples/s]\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/abeiler___json/abeiler--GOAT_Numeric_and_Alpha_Instruct-977c350f324ce21d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:640: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 776/776 [00:00<00:00, 8.99MB/s]\n",
      "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]\n",
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 53.3MB/s]\n",
      "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 31.6MB/s]\n",
      "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 414/414 [00:00<00:00, 5.66MB/s]\n",
      "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]\n",
      "Map:   1%|          | 527/100000 [00:00<00:19, 5221.49 examples/s]\n",
      "Map:   1%|▏         | 1272/100000 [00:00<00:20, 4913.89 examples/s]\n",
      "Map:   2%|▏         | 1807/100000 [00:00<00:19, 5078.42 examples/s]\n",
      "Map:   3%|▎         | 2524/100000 [00:00<00:19, 4885.13 examples/s]\n",
      "Map:   3%|▎         | 3260/100000 [00:00<00:20, 4807.61 examples/s]\n",
      "Map:   4%|▍         | 3800/100000 [00:00<00:19, 4962.02 examples/s]\n",
      "Map:   5%|▍         | 4531/100000 [00:00<00:19, 4864.81 examples/s]\n",
      "Map:   5%|▌         | 5263/100000 [00:01<00:19, 4797.99 examples/s]\n",
      "Map:   6%|▌         | 5788/100000 [00:01<00:19, 4904.74 examples/s]\n",
      "Map:   7%|▋         | 6522/100000 [00:01<00:19, 4822.39 examples/s]\n",
      "Map:   7%|▋         | 7259/100000 [00:01<00:19, 4767.65 examples/s]\n",
      "Map:   8%|▊         | 7783/100000 [00:01<00:18, 4876.73 examples/s]\n",
      "Map:   9%|▊         | 8516/100000 [00:01<00:19, 4796.66 examples/s]\n",
      "Map:   9%|▉         | 9253/100000 [00:01<00:19, 4715.21 examples/s]\n",
      "Map:  10%|▉         | 9778/100000 [00:02<00:18, 4834.57 examples/s]\n",
      "Map:  11%|█         | 10509/100000 [00:02<00:18, 4743.66 examples/s]\n",
      "Map:  11%|█         | 11000/100000 [00:02<00:19, 4652.51 examples/s]\n",
      "Map:  12%|█▏        | 11524/100000 [00:02<00:18, 4793.54 examples/s]\n",
      "Map:  12%|█▏        | 12259/100000 [00:02<00:18, 4741.57 examples/s]\n",
      "Map:  13%|█▎        | 12775/100000 [00:02<00:18, 4840.32 examples/s]\n",
      "Map:  14%|█▎        | 13521/100000 [00:02<00:18, 4772.69 examples/s]\n",
      "Map:  14%|█▍        | 14254/100000 [00:02<00:18, 4713.85 examples/s]\n",
      "Map:  15%|█▍        | 14763/100000 [00:03<00:17, 4799.47 examples/s]\n",
      "Map:  15%|█▌        | 15254/100000 [00:03<00:18, 4688.76 examples/s]\n",
      "Map:  16%|█▌        | 15780/100000 [00:03<00:17, 4831.98 examples/s]\n",
      "Map:  17%|█▋        | 16526/100000 [00:03<00:17, 4789.44 examples/s]\n",
      "Map:  17%|█▋        | 17255/100000 [00:03<00:17, 4752.14 examples/s]\n",
      "Map:  18%|█▊        | 17774/100000 [00:03<00:16, 4853.34 examples/s]\n",
      "Map:  19%|█▊        | 18519/100000 [00:03<00:17, 4787.77 examples/s]\n",
      "Map:  19%|█▉        | 19259/100000 [00:04<00:16, 4753.67 examples/s]\n",
      "Map:  20%|█▉        | 19787/100000 [00:04<00:16, 4870.62 examples/s]\n",
      "Map:  21%|██        | 20533/100000 [00:04<00:16, 4813.31 examples/s]\n",
      "Map:  21%|██▏       | 21256/100000 [00:04<00:16, 4734.47 examples/s]\n",
      "Map:  22%|██▏       | 21770/100000 [00:04<00:16, 4825.45 examples/s]\n",
      "Map:  22%|██▏       | 22261/100000 [00:04<00:16, 4724.88 examples/s]\n",
      "Map:  23%|██▎       | 22784/100000 [00:04<00:15, 4853.48 examples/s]\n",
      "Map:  24%|██▎       | 23523/100000 [00:04<00:15, 4802.32 examples/s]\n",
      "Map:  24%|██▍       | 24249/100000 [00:05<00:15, 4737.32 examples/s]\n",
      "Map:  25%|██▍       | 24768/100000 [00:05<00:15, 4844.05 examples/s]\n",
      "Map:  25%|██▌       | 25264/100000 [00:05<00:15, 4756.30 examples/s]\n",
      "Map:  26%|██▌       | 25803/100000 [00:05<00:15, 4919.03 examples/s]\n",
      "Map:  27%|██▋       | 26539/100000 [00:05<00:15, 4884.47 examples/s]\n",
      "Map:  27%|██▋       | 27271/100000 [00:05<00:14, 4859.52 examples/s]\n",
      "Map:  28%|██▊       | 27794/100000 [00:05<00:14, 4947.08 examples/s]\n",
      "Map:  29%|██▊       | 28530/100000 [00:05<00:14, 4861.26 examples/s]\n",
      "Map:  29%|██▉       | 29268/100000 [00:06<00:14, 4810.65 examples/s]\n",
      "Map:  30%|██▉       | 29783/100000 [00:06<00:14, 4887.55 examples/s]\n",
      "Map:  31%|███       | 30521/100000 [00:06<00:14, 4793.82 examples/s]\n",
      "Map:  31%|███▏      | 31264/100000 [00:06<00:14, 4756.70 examples/s]\n",
      "Map:  32%|███▏      | 31788/100000 [00:06<00:14, 4866.04 examples/s]\n",
      "Map:  33%|███▎      | 32525/100000 [00:06<00:14, 4800.95 examples/s]\n",
      "Map:  33%|███▎      | 33251/100000 [00:06<00:14, 4746.29 examples/s]\n",
      "Map:  34%|███▍      | 33750/100000 [00:07<00:13, 4799.83 examples/s]\n",
      "Map:  34%|███▍      | 34258/100000 [00:07<00:13, 4696.10 examples/s]\n",
      "Map:  35%|███▍      | 34774/100000 [00:07<00:13, 4811.64 examples/s]\n",
      "Map:  36%|███▌      | 35530/100000 [00:07<00:13, 4792.25 examples/s]\n",
      "Map:  36%|███▋      | 36254/100000 [00:07<00:13, 4714.02 examples/s]\n",
      "Map:  37%|███▋      | 36786/100000 [00:07<00:13, 4854.84 examples/s]\n",
      "Map:  38%|███▊      | 37541/100000 [00:07<00:12, 4822.07 examples/s]\n",
      "Map:  38%|███▊      | 38261/100000 [00:07<00:12, 4784.29 examples/s]\n",
      "Map:  39%|███▉      | 38800/100000 [00:08<00:12, 4921.36 examples/s]\n",
      "Map:  40%|███▉      | 39540/100000 [00:08<00:12, 4880.17 examples/s]\n",
      "Map:  40%|████      | 40261/100000 [00:08<00:12, 4825.90 examples/s]\n",
      "Map:  41%|████      | 40799/100000 [00:08<00:11, 4951.98 examples/s]\n",
      "Map:  42%|████▏     | 41525/100000 [00:08<00:12, 4861.08 examples/s]\n",
      "Map:  42%|████▏     | 42259/100000 [00:08<00:12, 4782.12 examples/s]\n",
      "Map:  43%|████▎     | 42784/100000 [00:08<00:11, 4887.23 examples/s]\n",
      "Map:  44%|████▎     | 43521/100000 [00:09<00:11, 4811.69 examples/s]\n",
      "Map:  44%|████▍     | 44263/100000 [00:09<00:11, 4786.28 examples/s]\n",
      "Map:  45%|████▍     | 44798/100000 [00:09<00:11, 4913.44 examples/s]\n",
      "Map:  46%|████▌     | 45513/100000 [00:09<00:11, 4812.17 examples/s]\n",
      "Map:  46%|████▋     | 46263/100000 [00:09<00:11, 4779.94 examples/s]\n",
      "Map:  47%|████▋     | 46793/100000 [00:09<00:10, 4896.74 examples/s]\n",
      "Map:  48%|████▊     | 47527/100000 [00:09<00:10, 4839.54 examples/s]\n",
      "Map:  48%|████▊     | 48275/100000 [00:10<00:10, 4824.23 examples/s]\n",
      "Map:  49%|████▉     | 48794/100000 [00:10<00:10, 4904.57 examples/s]\n",
      "Map:  50%|████▉     | 49522/100000 [00:10<00:10, 4840.50 examples/s]\n",
      "Map:  50%|█████     | 50257/100000 [00:10<00:10, 4795.12 examples/s]\n",
      "Map:  51%|█████     | 50785/100000 [00:10<00:10, 4905.43 examples/s]\n",
      "Map:  52%|█████▏    | 51534/100000 [00:10<00:09, 4885.73 examples/s]\n",
      "Map:  52%|█████▏    | 52257/100000 [00:10<00:09, 4818.21 examples/s]\n",
      "Map:  53%|█████▎    | 52777/100000 [00:10<00:09, 4904.24 examples/s]\n",
      "Map:  54%|█████▎    | 53519/100000 [00:11<00:09, 4821.33 examples/s]\n",
      "Map:  54%|█████▍    | 54261/100000 [00:11<00:09, 4795.91 examples/s]\n",
      "Map:  55%|█████▍    | 54787/100000 [00:11<00:09, 4899.72 examples/s]\n",
      "Map:  56%|█████▌    | 55516/100000 [00:11<00:09, 4809.00 examples/s]\n",
      "Map:  56%|█████▋    | 56270/100000 [00:11<00:09, 4814.52 examples/s]\n",
      "Map:  57%|█████▋    | 56801/100000 [00:11<00:08, 4925.18 examples/s]\n",
      "Map:  58%|█████▊    | 57528/100000 [00:11<00:08, 4855.18 examples/s]\n",
      "Map:  58%|█████▊    | 58262/100000 [00:12<00:08, 4818.21 examples/s]\n",
      "Map:  59%|█████▉    | 58800/100000 [00:12<00:08, 4946.02 examples/s]\n",
      "Map:  60%|█████▉    | 59548/100000 [00:12<00:08, 4907.77 examples/s]\n",
      "Map:  60%|██████    | 60263/100000 [00:12<00:08, 4859.55 examples/s]\n",
      "Map:  61%|██████    | 60797/100000 [00:12<00:07, 4969.61 examples/s]\n",
      "Map:  62%|██████▏   | 61528/100000 [00:12<00:07, 4909.44 examples/s]\n",
      "Map:  62%|██████▏   | 62264/100000 [00:12<00:07, 4866.07 examples/s]\n",
      "Map:  63%|██████▎   | 62787/100000 [00:12<00:07, 4949.61 examples/s]\n",
      "Map:  64%|██████▎   | 63531/100000 [00:13<00:07, 4876.41 examples/s]\n",
      "Map:  64%|██████▍   | 64258/100000 [00:13<00:07, 4826.51 examples/s]\n",
      "Map:  65%|██████▍   | 64794/100000 [00:13<00:07, 4946.57 examples/s]\n",
      "Map:  66%|██████▌   | 65531/100000 [00:13<00:07, 4876.26 examples/s]\n",
      "Map:  66%|██████▋   | 66254/100000 [00:13<00:07, 4798.46 examples/s]\n",
      "Map:  67%|██████▋   | 66793/100000 [00:13<00:06, 4933.08 examples/s]\n",
      "Map:  68%|██████▊   | 67539/100000 [00:13<00:06, 4890.01 examples/s]\n",
      "Map:  68%|██████▊   | 68260/100000 [00:14<00:06, 4792.02 examples/s]\n",
      "Map:  69%|██████▉   | 68794/100000 [00:14<00:06, 4915.52 examples/s]\n",
      "Map:  70%|██████▉   | 69544/100000 [00:14<00:06, 4890.55 examples/s]\n",
      "Map:  70%|███████   | 70268/100000 [00:14<00:06, 4850.34 examples/s]\n",
      "Map:  71%|███████   | 70804/100000 [00:14<00:05, 4965.55 examples/s]\n",
      "Map:  72%|███████▏  | 71536/100000 [00:14<00:05, 4910.40 examples/s]\n",
      "Map:  72%|███████▏  | 72265/100000 [00:14<00:05, 4862.24 examples/s]\n",
      "Map:  73%|███████▎  | 72782/100000 [00:15<00:05, 4930.93 examples/s]\n",
      "Map:  74%|███████▎  | 73536/100000 [00:15<00:05, 4852.26 examples/s]\n",
      "Map:  74%|███████▍  | 74265/100000 [00:15<00:05, 4829.14 examples/s]\n",
      "Map:  75%|███████▍  | 74795/100000 [00:15<00:05, 4935.82 examples/s]\n",
      "Map:  76%|███████▌  | 75529/100000 [00:15<00:05, 4867.90 examples/s]\n",
      "Map:  76%|███████▋  | 76266/100000 [00:15<00:04, 4814.24 examples/s]\n",
      "Map:  77%|███████▋  | 76803/100000 [00:15<00:04, 4939.90 examples/s]\n",
      "Map:  78%|███████▊  | 77536/100000 [00:16<00:04, 4888.30 examples/s]\n",
      "Map:  78%|███████▊  | 78256/100000 [00:16<00:04, 4803.77 examples/s]\n",
      "Map:  79%|███████▉  | 78788/100000 [00:16<00:04, 4920.27 examples/s]\n",
      "Map:  80%|███████▉  | 79523/100000 [00:16<00:04, 4853.69 examples/s]\n",
      "Map:  80%|████████  | 80262/100000 [00:16<00:04, 4802.57 examples/s]\n",
      "Map:  81%|████████  | 80787/100000 [00:16<00:03, 4902.96 examples/s]\n",
      "Map:  82%|████████▏ | 81521/100000 [00:16<00:03, 4827.69 examples/s]\n",
      "Map:  82%|████████▏ | 82265/100000 [00:17<00:03, 4788.00 examples/s]\n",
      "Map:  83%|████████▎ | 82790/100000 [00:17<00:03, 4891.22 examples/s]\n",
      "Map:  84%|████████▎ | 83522/100000 [00:17<00:03, 4822.53 examples/s]\n",
      "Map:  84%|████████▍ | 84268/100000 [00:17<00:03, 4810.67 examples/s]\n",
      "Map:  85%|████████▍ | 84796/100000 [00:17<00:03, 4916.27 examples/s]\n",
      "Map:  86%|████████▌ | 85539/100000 [00:17<00:02, 4872.98 examples/s]\n",
      "Map:  86%|████████▋ | 86258/100000 [00:17<00:02, 4787.00 examples/s]\n",
      "Map:  87%|████████▋ | 86780/100000 [00:17<00:02, 4883.64 examples/s]\n",
      "Map:  88%|████████▊ | 87530/100000 [00:18<00:02, 4811.15 examples/s]\n",
      "Map:  88%|████████▊ | 88257/100000 [00:18<00:02, 4761.62 examples/s]\n",
      "Map:  89%|████████▉ | 88780/100000 [00:18<00:02, 4867.23 examples/s]\n",
      "Map:  90%|████████▉ | 89515/100000 [00:18<00:02, 4782.57 examples/s]\n",
      "Map:  90%|█████████ | 90000/100000 [00:18<00:02, 4714.38 examples/s]\n",
      "Map:  91%|█████████ | 90521/100000 [00:18<00:01, 4836.58 examples/s]\n",
      "Map:  91%|█████████▏| 91264/100000 [00:18<00:01, 4794.81 examples/s]\n",
      "Map:  92%|█████████▏| 91794/100000 [00:18<00:01, 4916.49 examples/s]\n",
      "Map:  93%|█████████▎| 92519/100000 [00:19<00:01, 4845.47 examples/s]\n",
      "Map:  93%|█████████▎| 93253/100000 [00:19<00:01, 4776.40 examples/s]\n",
      "Map:  94%|█████████▍| 93781/100000 [00:19<00:01, 4891.17 examples/s]\n",
      "Map:  95%|█████████▍| 94523/100000 [00:19<00:01, 4830.04 examples/s]\n",
      "Map:  95%|█████████▌| 95256/100000 [00:19<00:00, 4756.59 examples/s]\n",
      "Map:  96%|█████████▌| 95775/100000 [00:19<00:00, 4854.42 examples/s]\n",
      "Map:  97%|█████████▋| 96542/100000 [00:19<00:00, 4856.19 examples/s]\n",
      "Map:  97%|█████████▋| 97265/100000 [00:20<00:00, 4818.31 examples/s]\n",
      "Map:  98%|█████████▊| 97808/100000 [00:20<00:00, 4958.39 examples/s]\n",
      "Map:  99%|█████████▊| 98540/100000 [00:20<00:00, 4915.13 examples/s]\n",
      "Map:  99%|█████████▉| 99258/100000 [00:20<00:00, 4849.77 examples/s]\n",
      "Map: 100%|█████████▉| 99796/100000 [00:20<00:00, 4970.66 examples/s]\n",
      "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]\n",
      "Map:   1%|          | 1000/100000 [00:00<00:10, 9733.39 examples/s]\n",
      "Map:   2%|▏         | 2000/100000 [00:00<00:10, 9694.50 examples/s]\n",
      "Map:   3%|▎         | 3000/100000 [00:00<00:10, 9677.45 examples/s]\n",
      "Map:   5%|▌         | 5000/100000 [00:00<00:09, 9928.29 examples/s]\n",
      "Map:   6%|▌         | 6000/100000 [00:00<00:09, 9904.53 examples/s]\n",
      "Map:   7%|▋         | 7000/100000 [00:00<00:09, 9914.01 examples/s]\n",
      "Map:   9%|▉         | 9000/100000 [00:00<00:09, 9900.07 examples/s]\n",
      "Map:  11%|█         | 11000/100000 [00:01<00:08, 9930.45 examples/s]\n",
      "Map:  13%|█▎        | 13000/100000 [00:01<00:08, 9976.69 examples/s]\n",
      "Map:  14%|█▍        | 14000/100000 [00:01<00:08, 9934.94 examples/s]\n",
      "Map:  15%|█▌        | 15000/100000 [00:01<00:08, 9887.51 examples/s]\n",
      "Map:  17%|█▋        | 17000/100000 [00:01<00:08, 10001.92 examples/s]\n",
      "Map:  19%|█▉        | 19000/100000 [00:01<00:08, 10060.82 examples/s]\n",
      "Map:  21%|██        | 21000/100000 [00:02<00:07, 9964.71 examples/s]\n",
      "Map:  23%|██▎       | 23000/100000 [00:02<00:07, 10041.16 examples/s]\n",
      "Map:  25%|██▌       | 25000/100000 [00:02<00:07, 10005.43 examples/s]\n",
      "Map:  27%|██▋       | 27000/100000 [00:02<00:07, 10011.93 examples/s]\n",
      "Map:  29%|██▉       | 29000/100000 [00:02<00:07, 10015.86 examples/s]\n",
      "Map:  31%|███       | 31000/100000 [00:03<00:06, 10058.13 examples/s]\n",
      "Map:  33%|███▎      | 33000/100000 [00:03<00:06, 10067.69 examples/s]\n",
      "Map:  35%|███▌      | 35000/100000 [00:03<00:06, 10142.39 examples/s]\n",
      "Map:  37%|███▋      | 37000/100000 [00:03<00:06, 10072.63 examples/s]\n",
      "Map:  39%|███▉      | 39000/100000 [00:03<00:06, 10066.29 examples/s]\n",
      "Map:  41%|████      | 41000/100000 [00:04<00:05, 9999.06 examples/s]\n",
      "Map:  43%|████▎     | 43000/100000 [00:04<00:05, 9928.05 examples/s]\n",
      "Map:  44%|████▍     | 44000/100000 [00:04<00:05, 9919.70 examples/s]\n",
      "Map:  46%|████▌     | 46000/100000 [00:04<00:05, 9924.57 examples/s]\n",
      "Map:  47%|████▋     | 47000/100000 [00:04<00:05, 9924.86 examples/s]\n",
      "Map:  48%|████▊     | 48000/100000 [00:04<00:05, 9926.14 examples/s]\n",
      "Map:  49%|████▉     | 49000/100000 [00:04<00:05, 9936.30 examples/s]\n",
      "Map:  51%|█████     | 51000/100000 [00:05<00:04, 10076.10 examples/s]\n",
      "Map:  53%|█████▎    | 53000/100000 [00:05<00:04, 10007.62 examples/s]\n",
      "Map:  55%|█████▌    | 55000/100000 [00:05<00:04, 10009.83 examples/s]\n",
      "Map:  57%|█████▋    | 57000/100000 [00:05<00:04, 10122.09 examples/s]\n",
      "Map:  59%|█████▉    | 59000/100000 [00:05<00:04, 10162.04 examples/s]\n",
      "Map:  61%|██████    | 61000/100000 [00:06<00:03, 10276.14 examples/s]\n",
      "Map:  63%|██████▎   | 63000/100000 [00:06<00:03, 10181.32 examples/s]\n",
      "Map:  65%|██████▌   | 65000/100000 [00:06<00:03, 10202.28 examples/s]\n",
      "Map:  67%|██████▋   | 67000/100000 [00:06<00:03, 10098.61 examples/s]\n",
      "Map:  69%|██████▉   | 69000/100000 [00:06<00:03, 10003.20 examples/s]\n",
      "Map:  71%|███████   | 71000/100000 [00:07<00:02, 10082.44 examples/s]\n",
      "Map:  73%|███████▎  | 73000/100000 [00:07<00:02, 10056.46 examples/s]\n",
      "Map:  75%|███████▌  | 75000/100000 [00:07<00:02, 10068.16 examples/s]\n",
      "Map:  77%|███████▋  | 77000/100000 [00:07<00:02, 10093.70 examples/s]\n",
      "Map:  79%|███████▉  | 79000/100000 [00:07<00:02, 10173.89 examples/s]\n",
      "Map:  81%|████████  | 81000/100000 [00:08<00:01, 10109.40 examples/s]\n",
      "Map:  83%|████████▎ | 83000/100000 [00:08<00:01, 10036.66 examples/s]\n",
      "Map:  85%|████████▌ | 85000/100000 [00:08<00:01, 10107.14 examples/s]\n",
      "Map:  87%|████████▋ | 87000/100000 [00:08<00:01, 10063.15 examples/s]\n",
      "Map:  89%|████████▉ | 89000/100000 [00:08<00:01, 10050.72 examples/s]\n",
      "Map:  91%|█████████ | 91000/100000 [00:09<00:00, 10153.44 examples/s]\n",
      "Map:  93%|█████████▎| 93000/100000 [00:09<00:00, 10200.04 examples/s]\n",
      "Map:  95%|█████████▌| 95000/100000 [00:09<00:00, 10152.71 examples/s]\n",
      "Map:  97%|█████████▋| 97000/100000 [00:09<00:00, 10100.05 examples/s]\n",
      "Map:  99%|█████████▉| 99000/100000 [00:09<00:00, 10185.43 examples/s]\n",
      "*** /opt/ml ***\n",
      "Downloading (…)lve/main/config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 609/609 [00:00<00:00, 7.18MB/s]\n",
      "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]\n",
      "Downloading (…)fetensors.index.json: 100%|██████████| 26.8k/26.8k [00:00<00:00, 181MB/s]\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 21.0M/9.98G [00:00<02:33, 64.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 41.9M/9.98G [00:00<03:34, 46.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 52.4M/9.98G [00:01<03:34, 46.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 73.4M/9.98G [00:01<03:27, 47.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 83.9M/9.98G [00:01<03:42, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 105M/9.98G [00:02<03:39, 44.9MB/s] #033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 115M/9.98G [00:02<03:19, 49.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|▏         | 136M/9.98G [00:02<03:05, 53.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|▏         | 147M/9.98G [00:02<03:10, 51.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 168M/9.98G [00:03<03:18, 49.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 178M/9.98G [00:04<04:38, 35.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 189M/9.98G [00:04<04:51, 33.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 199M/9.98G [00:04<04:45, 34.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 210M/9.98G [00:05<04:56, 32.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 231M/9.98G [00:05<04:19, 37.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 241M/9.98G [00:05<04:38, 35.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 262M/9.98G [00:06<03:28, 46.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 273M/9.98G [00:06<04:19, 37.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 294M/9.98G [00:06<03:24, 47.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 304M/9.98G [00:06<03:11, 50.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 325M/9.98G [00:07<03:04, 52.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 336M/9.98G [00:07<02:58, 53.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 346M/9.98G [00:07<02:55, 55.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▎         | 357M/9.98G [00:08<04:20, 37.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▎         | 367M/9.98G [00:08<03:45, 42.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 377M/9.98G [00:08<03:29, 45.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 388M/9.98G [00:08<03:58, 40.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 409M/9.98G [00:09<03:09, 50.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 419M/9.98G [00:09<03:39, 43.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 440M/9.98G [00:09<02:59, 53.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 451M/9.98G [00:10<03:29, 45.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 472M/9.98G [00:10<02:40, 59.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 482M/9.98G [00:10<03:11, 49.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 503M/9.98G [00:10<02:50, 55.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 514M/9.98G [00:11<02:40, 58.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 524M/9.98G [00:11<03:24, 46.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 535M/9.98G [00:11<03:47, 41.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 545M/9.98G [00:12<03:54, 40.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 566M/9.98G [00:12<03:57, 39.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 577M/9.98G [00:12<03:46, 41.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 598M/9.98G [00:13<03:20, 46.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 608M/9.98G [00:13<03:28, 44.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▋         | 629M/9.98G [00:13<03:16, 47.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▋         | 640M/9.98G [00:14<03:41, 42.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 650M/9.98G [00:14<04:03, 38.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 661M/9.98G [00:14<03:48, 40.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 682M/9.98G [00:15<02:44, 56.6MB/s]\n",
      "#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 692M/9.98G [00:15<03:27, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 713M/9.98G [00:15<03:16, 47.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 724M/9.98G [00:16<03:53, 39.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 734M/9.98G [00:16<03:59, 38.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 744M/9.98G [00:16<03:46, 40.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 755M/9.98G [00:16<03:29, 44.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 776M/9.98G [00:17<03:09, 48.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 786M/9.98G [00:17<03:07, 48.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 807M/9.98G [00:17<02:59, 51.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 818M/9.98G [00:18<03:02, 50.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 839M/9.98G [00:18<02:30, 60.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▊         | 849M/9.98G [00:18<03:10, 47.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▊         | 870M/9.98G [00:19<03:09, 48.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 881M/9.98G [00:19<03:03, 49.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 902M/9.98G [00:19<02:50, 53.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 912M/9.98G [00:19<02:51, 52.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 933M/9.98G [00:20<02:49, 53.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 944M/9.98G [00:20<03:53, 38.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 954M/9.98G [00:21<04:12, 35.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 965M/9.98G [00:21<03:38, 41.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 986M/9.98G [00:21<03:18, 45.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 996M/9.98G [00:22<03:31, 42.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 1.02G/9.98G [00:22<02:52, 51.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 1.03G/9.98G [00:22<02:57, 50.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.05G/9.98G [00:22<02:25, 61.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.06G/9.98G [00:23<03:08, 47.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.08G/9.98G [00:23<02:33, 57.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.09G/9.98G [00:23<02:52, 51.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.11G/9.98G [00:23<02:33, 57.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.12G/9.98G [00:24<03:05, 47.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█▏        | 1.13G/9.98G [00:24<03:03, 48.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█▏        | 1.14G/9.98G [00:24<03:04, 47.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.15G/9.98G [00:25<03:32, 41.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.17G/9.98G [00:25<03:07, 46.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.18G/9.98G [00:25<03:44, 39.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.21G/9.98G [00:26<03:29, 41.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.22G/9.98G [00:26<03:24, 42.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.23G/9.98G [00:26<03:13, 45.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.24G/9.98G [00:27<03:20, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.25G/9.98G [00:27<02:55, 49.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.26G/9.98G [00:27<03:17, 44.1MB/s]\n",
      "#033[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.27G/9.98G [00:27<03:16, 44.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.29G/9.98G [00:27<02:25, 59.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.30G/9.98G [00:28<03:37, 39.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.32G/9.98G [00:28<03:17, 43.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.33G/9.98G [00:29<03:42, 38.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▎        | 1.35G/9.98G [00:29<03:09, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▎        | 1.36G/9.98G [00:29<03:40, 39.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.38G/9.98G [00:30<03:12, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.39G/9.98G [00:30<03:19, 43.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.42G/9.98G [00:30<02:40, 53.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.43G/9.98G [00:31<02:49, 50.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.45G/9.98G [00:31<03:03, 46.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.46G/9.98G [00:32<03:37, 39.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.48G/9.98G [00:32<03:24, 41.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.49G/9.98G [00:32<03:23, 41.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.51G/9.98G [00:33<03:21, 42.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.52G/9.98G [00:33<03:36, 39.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.54G/9.98G [00:33<03:04, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.55G/9.98G [00:34<03:14, 43.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.56G/9.98G [00:34<03:08, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.57G/9.98G [00:34<03:55, 35.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.59G/9.98G [00:35<03:10, 44.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.60G/9.98G [00:35<03:52, 36.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▋        | 1.63G/9.98G [00:35<02:45, 50.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▋        | 1.64G/9.98G [00:36<03:04, 45.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.66G/9.98G [00:36<02:34, 53.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.67G/9.98G [00:36<03:01, 45.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.69G/9.98G [00:37<02:37, 52.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.70G/9.98G [00:37<02:35, 53.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.72G/9.98G [00:37<02:14, 61.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.73G/9.98G [00:37<02:29, 55.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.75G/9.98G [00:38<02:22, 57.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.76G/9.98G [00:38<03:34, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.77G/9.98G [00:38<03:02, 44.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.78G/9.98G [00:39<03:23, 40.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.79G/9.98G [00:39<03:55, 34.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.81G/9.98G [00:39<03:05, 44.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.82G/9.98G [00:40<03:08, 43.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.85G/9.98G [00:40<02:47, 48.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▊        | 1.86G/9.98G [00:40<02:41, 50.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▊        | 1.87G/9.98G [00:41<03:13, 42.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.88G/9.98G [00:41<02:56, 45.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.90G/9.98G [00:41<02:32, 53.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.91G/9.98G [00:41<03:14, 41.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.93G/9.98G [00:42<02:48, 47.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.94G/9.98G [00:42<03:30, 38.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.95G/9.98G [00:42<03:01, 44.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.96G/9.98G [00:43<02:51, 46.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.97G/9.98G [00:43<02:50, 47.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.99G/9.98G [00:43<02:46, 47.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 2.00G/9.98G [00:43<02:44, 48.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 2.02G/9.98G [00:44<02:28, 53.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 2.03G/9.98G [00:44<02:41, 49.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.06G/9.98G [00:45<03:26, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.07G/9.98G [00:45<03:24, 38.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.09G/9.98G [00:45<02:56, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.10G/9.98G [00:46<03:11, 41.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.12G/9.98G [00:46<02:59, 43.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██▏       | 2.13G/9.98G [00:47<03:26, 38.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.15G/9.98G [00:47<02:38, 49.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.16G/9.98G [00:47<02:49, 46.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.18G/9.98G [00:48<02:54, 44.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.19G/9.98G [00:48<02:44, 47.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.20G/9.98G [00:48<02:56, 44.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.21G/9.98G [00:48<03:19, 38.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.23G/9.98G [00:49<03:06, 41.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.24G/9.98G [00:49<03:18, 38.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.26G/9.98G [00:49<02:48, 45.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.28G/9.98G [00:50<02:50, 45.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.30G/9.98G [00:50<02:36, 49.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.31G/9.98G [00:50<02:54, 43.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.33G/9.98G [00:51<02:55, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.34G/9.98G [00:51<03:07, 40.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▎       | 2.36G/9.98G [00:52<02:43, 46.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.37G/9.98G [00:52<03:02, 41.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.39G/9.98G [00:52<02:40, 47.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.40G/9.98G [00:53<02:54, 43.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.41G/9.98G [00:53<02:44, 46.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.42G/9.98G [00:53<02:59, 42.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.43G/9.98G [00:53<03:18, 38.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 2.45G/9.98G [00:54<02:39, 47.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 2.46G/9.98G [00:54<03:02, 41.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 2.49G/9.98G [00:54<02:42, 46.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.50G/9.98G [00:55<02:43, 45.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.51G/9.98G [00:55<02:47, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.52G/9.98G [00:56<03:44, 33.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.54G/9.98G [00:56<03:19, 37.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.55G/9.98G [00:56<03:25, 36.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.57G/9.98G [00:57<03:10, 39.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.58G/9.98G [00:57<03:31, 35.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.59G/9.98G [00:57<03:29, 35.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.60G/9.98G [00:58<03:28, 35.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.61G/9.98G [00:58<04:09, 29.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▋       | 2.63G/9.98G [00:59<03:18, 37.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▋       | 2.64G/9.98G [00:59<03:40, 33.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.66G/9.98G [00:59<02:49, 43.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.67G/9.98G [01:00<02:48, 43.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.68G/9.98G [01:00<03:18, 36.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.69G/9.98G [01:00<03:24, 35.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.71G/9.98G [01:01<03:35, 33.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.73G/9.98G [01:01<03:07, 38.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.74G/9.98G [01:01<03:23, 35.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.76G/9.98G [01:02<03:00, 39.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.77G/9.98G [01:02<03:03, 39.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.79G/9.98G [01:03<02:39, 45.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.80G/9.98G [01:03<02:36, 45.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.81G/9.98G [01:03<02:22, 50.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.82G/9.98G [01:03<02:49, 42.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.84G/9.98G [01:04<02:37, 45.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▊       | 2.85G/9.98G [01:04<03:08, 37.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.87G/9.98G [01:04<02:36, 45.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.88G/9.98G [01:05<02:41, 44.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.90G/9.98G [01:05<02:26, 48.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.92G/9.98G [01:05<02:50, 41.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.93G/9.98G [01:06<02:38, 44.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.94G/9.98G [01:06<02:24, 48.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.95G/9.98G [01:06<02:38, 44.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.97G/9.98G [01:07<02:37, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.98G/9.98G [01:07<02:52, 40.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.00G/9.98G [01:07<02:38, 44.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.01G/9.98G [01:08<02:40, 43.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.02G/9.98G [01:08<02:40, 43.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.03G/9.98G [01:08<02:48, 41.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.04G/9.98G [01:08<02:37, 44.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.06G/9.98G [01:09<02:09, 53.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.07G/9.98G [01:09<02:04, 55.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.09G/9.98G [01:09<01:51, 61.7MB/s]\n",
      "#033[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.11G/9.98G [01:09<02:02, 56.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███▏      | 3.12G/9.98G [01:10<02:54, 39.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.15G/9.98G [01:11<03:01, 37.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.16G/9.98G [01:11<03:18, 34.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.18G/9.98G [01:11<02:46, 40.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.19G/9.98G [01:12<02:47, 40.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.21G/9.98G [01:12<02:32, 44.4MB/s]\n",
      "#033[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.22G/9.98G [01:12<02:29, 45.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.24G/9.98G [01:13<02:42, 41.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.25G/9.98G [01:13<02:48, 39.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.26G/9.98G [01:13<02:37, 42.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.27G/9.98G [01:13<02:16, 49.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.28G/9.98G [01:14<02:14, 49.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.30G/9.98G [01:14<02:08, 52.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.31G/9.98G [01:14<02:45, 40.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.33G/9.98G [01:15<02:21, 47.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▎      | 3.34G/9.98G [01:15<02:27, 45.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▎      | 3.37G/9.98G [01:15<01:53, 58.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.38G/9.98G [01:16<02:13, 49.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.40G/9.98G [01:16<02:07, 51.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.41G/9.98G [01:16<02:00, 54.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.42G/9.98G [01:17<02:37, 41.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.43G/9.98G [01:17<03:20, 32.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.44G/9.98G [01:18<03:43, 29.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.45G/9.98G [01:18<03:14, 33.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.46G/9.98G [01:18<03:07, 34.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.47G/9.98G [01:18<02:37, 41.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.48G/9.98G [01:18<02:30, 43.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.49G/9.98G [01:19<02:34, 42.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 3.51G/9.98G [01:19<02:07, 50.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 3.52G/9.98G [01:19<02:32, 42.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 3.53G/9.98G [01:20<02:33, 42.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.54G/9.98G [01:20<02:28, 43.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.55G/9.98G [01:20<03:00, 35.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.58G/9.98G [01:21<02:27, 43.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.59G/9.98G [01:21<02:26, 43.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.61G/9.98G [01:21<02:14, 47.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▋      | 3.62G/9.98G [01:22<02:36, 40.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▋      | 3.64G/9.98G [01:22<02:11, 48.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.65G/9.98G [01:22<02:19, 45.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.67G/9.98G [01:23<02:05, 50.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.68G/9.98G [01:23<02:24, 43.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.70G/9.98G [01:23<02:09, 48.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.72G/9.98G [01:24<02:00, 52.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.73G/9.98G [01:24<02:01, 51.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.75G/9.98G [01:24<02:01, 51.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.76G/9.98G [01:25<02:33, 40.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.77G/9.98G [01:25<02:27, 41.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.79G/9.98G [01:25<02:32, 40.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.80G/9.98G [01:25<02:14, 46.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.82G/9.98G [01:26<02:05, 49.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.83G/9.98G [01:26<02:07, 48.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▊      | 3.85G/9.98G [01:26<01:45, 58.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▊      | 3.86G/9.98G [01:26<01:54, 53.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.88G/9.98G [01:27<01:45, 57.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.89G/9.98G [01:27<02:00, 50.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.91G/9.98G [01:27<02:00, 50.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.92G/9.98G [01:28<02:33, 39.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.93G/9.98G [01:28<02:21, 42.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.94G/9.98G [01:28<02:32, 39.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.95G/9.98G [01:29<02:33, 39.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.96G/9.98G [01:29<02:18, 43.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.97G/9.98G [01:29<02:38, 37.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.98G/9.98G [01:30<02:37, 38.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.01G/9.98G [01:30<02:20, 42.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.02G/9.98G [01:30<02:34, 38.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.04G/9.98G [01:31<02:10, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.06G/9.98G [01:31<01:50, 53.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.07G/9.98G [01:31<02:06, 46.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.09G/9.98G [01:32<02:12, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.10G/9.98G [01:32<02:39, 36.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.11G/9.98G [01:32<02:25, 40.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████▏     | 4.12G/9.98G [01:33<02:22, 41.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████▏     | 4.13G/9.98G [01:33<02:29, 39.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.15G/9.98G [01:33<02:10, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.16G/9.98G [01:34<02:15, 43.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.18G/9.98G [01:34<01:58, 48.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.19G/9.98G [01:34<02:15, 42.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.20G/9.98G [01:35<02:12, 43.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.22G/9.98G [01:35<02:15, 42.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.23G/9.98G [01:35<02:28, 38.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.25G/9.98G [01:36<02:09, 44.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.26G/9.98G [01:36<02:28, 38.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.27G/9.98G [01:36<02:05, 45.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.28G/9.98G [01:36<02:02, 46.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.29G/9.98G [01:36<02:04, 45.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.31G/9.98G [01:37<02:42, 34.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.32G/9.98G [01:38<02:35, 36.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▎     | 4.34G/9.98G [01:38<02:14, 41.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▎     | 4.35G/9.98G [01:38<02:31, 37.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▎     | 4.36G/9.98G [01:38<02:16, 41.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.37G/9.98G [01:39<02:14, 41.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.39G/9.98G [01:39<01:49, 51.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.40G/9.98G [01:40<02:31, 36.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.42G/9.98G [01:40<01:54, 48.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.44G/9.98G [01:40<01:54, 48.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.45G/9.98G [01:40<01:41, 54.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.46G/9.98G [01:40<01:49, 50.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.47G/9.98G [01:41<02:07, 43.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.49G/9.98G [01:41<01:54, 48.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▌     | 4.50G/9.98G [01:41<02:10, 42.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▌     | 4.52G/9.98G [01:42<02:04, 43.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▌     | 4.53G/9.98G [01:42<02:06, 43.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.54G/9.98G [01:42<01:59, 45.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.55G/9.98G [01:42<01:52, 48.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.56G/9.98G [01:43<02:23, 37.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.58G/9.98G [01:43<02:01, 44.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.59G/9.98G [01:44<02:16, 39.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.61G/9.98G [01:44<01:56, 46.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▋     | 4.62G/9.98G [01:44<01:45, 50.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.65G/9.98G [01:45<01:51, 47.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.66G/9.98G [01:45<01:46, 49.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.67G/9.98G [01:45<01:35, 55.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.68G/9.98G [01:45<01:47, 49.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.70G/9.98G [01:46<01:33, 56.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.71G/9.98G [01:46<01:41, 51.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.72G/9.98G [01:46<01:37, 54.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.73G/9.98G [01:46<01:31, 57.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.74G/9.98G [01:46<01:56, 45.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.76G/9.98G [01:47<02:15, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.77G/9.98G [01:47<02:08, 40.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.79G/9.98G [01:48<01:51, 46.7MB/s]\n",
      "#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.80G/9.98G [01:48<02:01, 42.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.81G/9.98G [01:48<01:57, 44.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.82G/9.98G [01:48<01:56, 44.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.83G/9.98G [01:49<02:21, 36.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▊     | 4.85G/9.98G [01:49<02:00, 42.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.87G/9.98G [01:50<02:05, 40.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.88G/9.98G [01:50<02:10, 39.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.89G/9.98G [01:50<02:10, 38.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.90G/9.98G [01:50<02:03, 41.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.92G/9.98G [01:51<01:50, 46.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.93G/9.98G [01:51<01:44, 48.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.95G/9.98G [01:51<01:31, 55.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.96G/9.98G [01:51<01:38, 51.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.97G/9.98G [01:52<02:01, 41.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.98G/9.98G [01:52<02:09, 38.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 4.99G/9.98G [01:52<01:58, 42.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 5.00G/9.98G [01:53<01:44, 47.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 5.01G/9.98G [01:53<02:07, 39.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 5.03G/9.98G [01:53<01:57, 42.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.04G/9.98G [01:54<02:05, 39.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.05G/9.98G [01:54<02:00, 40.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.06G/9.98G [01:54<02:13, 36.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.08G/9.98G [01:55<02:07, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.10G/9.98G [01:55<01:40, 48.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.11G/9.98G [01:55<01:52, 43.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████▏    | 5.13G/9.98G [01:55<01:28, 55.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.14G/9.98G [01:55<01:22, 58.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.16G/9.98G [01:56<01:20, 59.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.17G/9.98G [01:56<01:37, 49.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.19G/9.98G [01:57<01:32, 52.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.20G/9.98G [01:57<01:35, 50.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.22G/9.98G [01:57<01:22, 57.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.23G/9.98G [01:57<01:35, 49.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.25G/9.98G [01:58<01:27, 54.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.26G/9.98G [01:58<01:52, 42.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.27G/9.98G [01:58<02:00, 38.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.28G/9.98G [01:59<02:00, 38.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.30G/9.98G [01:59<01:50, 42.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.31G/9.98G [02:00<03:12, 24.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.32G/9.98G [02:00<03:14, 23.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.33G/9.98G [02:01<02:41, 28.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.34G/9.98G [02:01<02:22, 32.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▎    | 5.35G/9.98G [02:01<02:15, 34.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▎    | 5.36G/9.98G [02:01<01:54, 40.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.37G/9.98G [02:02<02:08, 35.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.38G/9.98G [02:02<02:15, 34.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.40G/9.98G [02:03<02:21, 32.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.41G/9.98G [02:03<02:34, 29.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.43G/9.98G [02:03<02:00, 37.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.44G/9.98G [02:04<01:57, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.46G/9.98G [02:04<01:54, 39.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.47G/9.98G [02:04<01:49, 41.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.49G/9.98G [02:05<01:35, 47.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.51G/9.98G [02:05<01:40, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.53G/9.98G [02:05<01:19, 55.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.54G/9.98G [02:05<01:25, 52.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.56G/9.98G [02:06<01:30, 48.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.57G/9.98G [02:06<01:29, 49.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.58G/9.98G [02:06<01:36, 45.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.59G/9.98G [02:07<01:42, 42.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.61G/9.98G [02:07<01:21, 53.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▋    | 5.62G/9.98G [02:07<01:41, 42.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.64G/9.98G [02:08<01:19, 54.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.65G/9.98G [02:08<01:22, 52.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.67G/9.98G [02:08<01:24, 50.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.68G/9.98G [02:08<01:19, 54.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.70G/9.98G [02:09<01:25, 50.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.71G/9.98G [02:09<01:29, 47.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.74G/9.98G [02:10<01:37, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.75G/9.98G [02:10<01:41, 41.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.77G/9.98G [02:10<01:31, 45.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.78G/9.98G [02:11<01:31, 45.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.80G/9.98G [02:11<01:30, 46.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.81G/9.98G [02:11<01:32, 45.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.83G/9.98G [02:12<01:29, 46.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▊    | 5.84G/9.98G [02:12<01:45, 39.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.86G/9.98G [02:13<01:48, 38.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.87G/9.98G [02:13<02:01, 33.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.89G/9.98G [02:14<01:49, 37.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.90G/9.98G [02:14<01:55, 35.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.91G/9.98G [02:14<01:51, 36.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.92G/9.98G [02:15<02:04, 32.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.95G/9.98G [02:15<01:42, 39.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.96G/9.98G [02:15<01:44, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.98G/9.98G [02:16<01:30, 44.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 5.99G/9.98G [02:16<01:58, 33.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 6.01G/9.98G [02:17<01:35, 41.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 6.02G/9.98G [02:17<01:32, 42.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.04G/9.98G [02:17<01:13, 53.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.05G/9.98G [02:17<01:20, 48.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.07G/9.98G [02:18<01:15, 51.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.08G/9.98G [02:18<01:21, 48.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.10G/9.98G [02:18<01:09, 55.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████▏   | 6.11G/9.98G [02:19<01:22, 46.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████▏   | 6.13G/9.98G [02:19<01:04, 59.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.14G/9.98G [02:19<01:07, 56.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.17G/9.98G [02:19<01:12, 52.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.18G/9.98G [02:20<01:24, 44.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.20G/9.98G [02:20<01:22, 45.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.22G/9.98G [02:20<01:06, 56.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.23G/9.98G [02:21<01:11, 52.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.24G/9.98G [02:21<01:10, 53.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.25G/9.98G [02:21<01:14, 50.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.26G/9.98G [02:21<01:17, 48.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.28G/9.98G [02:22<01:12, 51.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.29G/9.98G [02:22<01:17, 47.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.31G/9.98G [02:22<01:16, 47.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.32G/9.98G [02:23<01:33, 39.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▎   | 6.34G/9.98G [02:23<01:17, 47.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▎   | 6.35G/9.98G [02:24<01:29, 40.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.38G/9.98G [02:24<01:18, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.39G/9.98G [02:24<01:31, 39.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.41G/9.98G [02:25<01:34, 37.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.42G/9.98G [02:25<01:29, 39.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.44G/9.98G [02:25<01:16, 46.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.45G/9.98G [02:26<01:26, 40.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.46G/9.98G [02:26<01:32, 38.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.47G/9.98G [02:26<01:23, 41.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.48G/9.98G [02:27<01:20, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.50G/9.98G [02:27<01:11, 48.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.52G/9.98G [02:27<01:05, 52.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.53G/9.98G [02:28<01:14, 46.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.54G/9.98G [02:28<01:10, 48.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.55G/9.98G [02:28<01:08, 49.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.56G/9.98G [02:28<01:14, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.57G/9.98G [02:29<01:13, 46.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.59G/9.98G [02:29<01:18, 43.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.60G/9.98G [02:29<01:29, 37.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▋   | 6.62G/9.98G [02:29<01:12, 46.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▋   | 6.63G/9.98G [02:30<01:16, 44.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.65G/9.98G [02:30<01:04, 51.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.66G/9.98G [02:31<01:22, 40.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.67G/9.98G [02:31<01:17, 42.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.68G/9.98G [02:31<01:27, 37.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.69G/9.98G [02:31<01:25, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.70G/9.98G [02:32<01:22, 39.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.71G/9.98G [02:32<01:19, 41.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.72G/9.98G [02:32<01:19, 41.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.73G/9.98G [02:32<01:07, 47.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.74G/9.98G [02:33<01:21, 39.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.75G/9.98G [02:33<01:17, 41.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.77G/9.98G [02:33<01:08, 46.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.78G/9.98G [02:34<01:15, 42.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.81G/9.98G [02:34<01:05, 48.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.82G/9.98G [02:34<01:01, 51.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.83G/9.98G [02:34<00:54, 57.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.84G/9.98G [02:34<01:03, 49.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.85G/9.98G [02:35<01:03, 48.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.86G/9.98G [02:35<01:03, 48.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.87G/9.98G [02:35<01:15, 41.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.89G/9.98G [02:36<01:12, 42.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.90G/9.98G [02:36<01:16, 40.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.92G/9.98G [02:36<01:06, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.93G/9.98G [02:37<01:20, 37.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.95G/9.98G [02:37<01:07, 44.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.96G/9.98G [02:37<01:15, 40.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.98G/9.98G [02:38<01:07, 44.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 6.99G/9.98G [02:38<01:16, 38.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 7.01G/9.98G [02:39<01:17, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 7.03G/9.98G [02:39<01:14, 39.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.05G/9.98G [02:40<01:13, 39.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.06G/9.98G [02:40<01:21, 35.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.08G/9.98G [02:40<01:12, 39.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.09G/9.98G [02:41<01:15, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████▏  | 7.11G/9.98G [02:41<01:03, 45.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████▏  | 7.13G/9.98G [02:41<00:53, 53.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.14G/9.98G [02:42<00:54, 51.6MB/s]\n",
      "#033[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.16G/9.98G [02:42<00:47, 59.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.17G/9.98G [02:42<00:54, 51.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.19G/9.98G [02:42<00:41, 66.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.20G/9.98G [02:42<00:40, 67.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.22G/9.98G [02:43<00:47, 58.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.24G/9.98G [02:43<00:53, 51.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.26G/9.98G [02:44<00:51, 52.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.27G/9.98G [02:44<00:59, 45.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.29G/9.98G [02:44<00:53, 50.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.30G/9.98G [02:45<00:56, 47.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.32G/9.98G [02:45<00:45, 58.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.33G/9.98G [02:45<00:44, 59.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▎  | 7.34G/9.98G [02:45<00:42, 62.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▎  | 7.35G/9.98G [02:45<00:43, 60.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.36G/9.98G [02:46<01:38, 26.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.38G/9.98G [02:47<01:15, 34.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.39G/9.98G [02:47<01:14, 34.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.40G/9.98G [02:47<01:15, 34.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.41G/9.98G [02:48<01:14, 34.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.42G/9.98G [02:48<01:06, 38.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.43G/9.98G [02:48<01:13, 34.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.44G/9.98G [02:48<01:12, 35.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.47G/9.98G [02:49<01:18, 32.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.48G/9.98G [02:49<01:15, 33.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.50G/9.98G [02:50<01:00, 40.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.51G/9.98G [02:50<01:00, 40.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.53G/9.98G [02:51<01:02, 39.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.54G/9.98G [02:51<01:06, 36.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.56G/9.98G [02:51<00:50, 47.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.57G/9.98G [02:52<01:04, 37.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.59G/9.98G [02:52<00:55, 43.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.60G/9.98G [02:52<01:01, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▋  | 7.61G/9.98G [02:53<00:56, 41.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▋  | 7.62G/9.98G [02:53<01:08, 34.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.63G/9.98G [02:53<01:04, 36.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.65G/9.98G [02:54<00:52, 44.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.67G/9.98G [02:54<00:55, 42.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.68G/9.98G [02:54<00:52, 43.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.69G/9.98G [02:54<00:52, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.70G/9.98G [02:55<00:58, 39.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.71G/9.98G [02:55<00:48, 46.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.72G/9.98G [02:55<00:47, 47.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.73G/9.98G [02:55<00:50, 44.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.74G/9.98G [02:55<00:46, 48.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.75G/9.98G [02:56<01:00, 37.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.76G/9.98G [02:56<00:49, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.77G/9.98G [02:56<00:46, 47.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.78G/9.98G [02:56<00:46, 47.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.79G/9.98G [02:57<00:53, 41.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.80G/9.98G [02:57<00:58, 37.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.81G/9.98G [02:57<00:54, 39.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.82G/9.98G [02:57<00:46, 46.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▊  | 7.83G/9.98G [02:58<00:44, 47.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▊  | 7.84G/9.98G [02:58<00:45, 46.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.86G/9.98G [02:59<00:54, 39.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.87G/9.98G [02:59<00:58, 36.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.90G/9.98G [02:59<00:51, 40.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.91G/9.98G [03:00<00:52, 39.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.92G/9.98G [03:00<00:58, 35.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.93G/9.98G [03:00<00:59, 34.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.94G/9.98G [03:01<00:55, 37.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.95G/9.98G [03:01<00:49, 41.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.96G/9.98G [03:01<00:49, 41.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.97G/9.98G [03:01<00:48, 41.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 7.99G/9.98G [03:02<00:40, 49.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 8.00G/9.98G [03:02<00:58, 33.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 8.02G/9.98G [03:02<00:40, 48.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.03G/9.98G [03:03<00:38, 50.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.05G/9.98G [03:03<00:34, 55.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.07G/9.98G [03:03<00:28, 65.7MB/s]\n",
      "#033[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.08G/9.98G [03:03<00:35, 53.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.11G/9.98G [03:04<00:33, 55.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████▏ | 8.12G/9.98G [03:04<00:41, 44.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.14G/9.98G [03:05<00:40, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.15G/9.98G [03:05<00:50, 36.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.17G/9.98G [03:06<00:53, 33.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.18G/9.98G [03:06<00:49, 36.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.20G/9.98G [03:06<00:37, 46.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.21G/9.98G [03:07<00:43, 40.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.23G/9.98G [03:07<00:37, 46.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.24G/9.98G [03:07<00:40, 43.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.26G/9.98G [03:08<00:35, 47.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.27G/9.98G [03:08<00:36, 46.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.29G/9.98G [03:08<00:35, 47.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.30G/9.98G [03:09<00:41, 40.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.33G/9.98G [03:09<00:33, 48.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▎ | 8.34G/9.98G [03:09<00:35, 45.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.36G/9.98G [03:10<00:37, 43.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.37G/9.98G [03:10<00:33, 48.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.38G/9.98G [03:10<00:37, 43.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.39G/9.98G [03:11<00:38, 41.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.41G/9.98G [03:11<00:36, 43.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.42G/9.98G [03:11<00:43, 35.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.44G/9.98G [03:12<00:40, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.45G/9.98G [03:12<00:35, 42.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.47G/9.98G [03:13<00:36, 40.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.48G/9.98G [03:13<00:38, 39.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.50G/9.98G [03:14<00:37, 38.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.51G/9.98G [03:14<00:37, 38.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.54G/9.98G [03:14<00:30, 46.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.55G/9.98G [03:15<00:40, 35.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.57G/9.98G [03:15<00:37, 37.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.58G/9.98G [03:15<00:38, 36.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.60G/9.98G [03:16<00:29, 47.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▋ | 8.61G/9.98G [03:16<00:32, 41.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▋ | 8.62G/9.98G [03:16<00:31, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.63G/9.98G [03:17<00:35, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.64G/9.98G [03:17<00:44, 30.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.66G/9.98G [03:18<00:36, 36.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.67G/9.98G [03:18<00:31, 41.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.68G/9.98G [03:18<00:30, 42.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.69G/9.98G [03:18<00:36, 34.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.70G/9.98G [03:19<00:39, 32.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.71G/9.98G [03:19<00:43, 29.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.72G/9.98G [03:19<00:35, 34.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.75G/9.98G [03:20<00:24, 50.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.76G/9.98G [03:20<00:27, 43.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.78G/9.98G [03:20<00:24, 49.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.79G/9.98G [03:21<00:24, 48.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.81G/9.98G [03:21<00:25, 46.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.82G/9.98G [03:21<00:27, 41.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▊ | 8.84G/9.98G [03:22<00:22, 50.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▊ | 8.85G/9.98G [03:22<00:26, 42.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.87G/9.98G [03:22<00:19, 57.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.88G/9.98G [03:22<00:20, 54.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.89G/9.98G [03:23<00:22, 48.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.90G/9.98G [03:23<00:25, 42.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.91G/9.98G [03:23<00:28, 36.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.92G/9.98G [03:24<00:27, 38.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.93G/9.98G [03:24<00:28, 36.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.94G/9.98G [03:24<00:31, 32.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.97G/9.98G [03:25<00:23, 42.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 8.99G/9.98G [03:25<00:18, 53.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 9.00G/9.98G [03:25<00:18, 52.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 9.02G/9.98G [03:26<00:18, 52.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 9.03G/9.98G [03:26<00:18, 50.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.04G/9.98G [03:26<00:16, 57.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.05G/9.98G [03:26<00:17, 54.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.06G/9.98G [03:27<00:21, 42.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.08G/9.98G [03:27<00:17, 50.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.09G/9.98G [03:27<00:23, 38.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████▏| 9.11G/9.98G [03:28<00:19, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████▏| 9.12G/9.98G [03:28<00:19, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.13G/9.98G [03:28<00:19, 43.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.14G/9.98G [03:29<00:24, 33.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.15G/9.98G [03:29<00:24, 34.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.18G/9.98G [03:30<00:25, 31.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.19G/9.98G [03:30<00:23, 33.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.21G/9.98G [03:30<00:18, 41.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.22G/9.98G [03:31<00:17, 42.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.24G/9.98G [03:31<00:18, 39.8MB/s]\n",
      "#033[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.25G/9.98G [03:31<00:17, 40.8MB/s]\n",
      "#033[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.27G/9.98G [03:32<00:15, 46.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.28G/9.98G [03:32<00:15, 46.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.29G/9.98G [03:32<00:16, 42.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.30G/9.98G [03:33<00:18, 36.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.32G/9.98G [03:33<00:15, 42.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▎| 9.33G/9.98G [03:33<00:14, 43.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.35G/9.98G [03:34<00:12, 48.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.36G/9.98G [03:34<00:11, 51.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.38G/9.98G [03:34<00:09, 63.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.40G/9.98G [03:34<00:10, 54.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.42G/9.98G [03:35<00:12, 46.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.43G/9.98G [03:35<00:12, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.45G/9.98G [03:35<00:10, 48.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.46G/9.98G [03:36<00:10, 49.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.48G/9.98G [03:36<00:10, 48.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.49G/9.98G [03:36<00:10, 46.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.51G/9.98G [03:37<00:08, 53.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.52G/9.98G [03:37<00:09, 48.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.54G/9.98G [03:37<00:07, 54.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.55G/9.98G [03:37<00:07, 57.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.56G/9.98G [03:38<00:09, 45.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.57G/9.98G [03:38<00:09, 42.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.58G/9.98G [03:38<00:08, 48.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.59G/9.98G [03:38<00:07, 54.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▋| 9.60G/9.98G [03:39<00:06, 56.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▋| 9.63G/9.98G [03:39<00:05, 58.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.64G/9.98G [03:39<00:05, 57.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.66G/9.98G [03:39<00:05, 56.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.67G/9.98G [03:40<00:06, 46.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.69G/9.98G [03:40<00:05, 51.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.70G/9.98G [03:40<00:06, 45.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.72G/9.98G [03:41<00:05, 51.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.73G/9.98G [03:41<00:05, 45.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.75G/9.98G [03:42<00:04, 48.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.76G/9.98G [03:42<00:06, 34.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.78G/9.98G [03:43<00:05, 36.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.79G/9.98G [03:43<00:05, 33.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.81G/9.98G [03:44<00:04, 35.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.83G/9.98G [03:44<00:04, 34.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▊| 9.84G/9.98G [03:44<00:03, 41.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▊| 9.85G/9.98G [03:44<00:03, 34.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.86G/9.98G [03:45<00:03, 30.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.88G/9.98G [03:45<00:02, 39.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.89G/9.98G [03:46<00:02, 36.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.91G/9.98G [03:46<00:01, 36.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.92G/9.98G [03:47<00:01, 34.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.93G/9.98G [03:47<00:01, 39.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.94G/9.98G [03:47<00:00, 40.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.96G/9.98G [03:47<00:00, 47.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.97G/9.98G [03:48<00:00, 37.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 9.98G/9.98G [03:48<00:00, 35.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 9.98G/9.98G [03:48<00:00, 43.7MB/s]\n",
      "Downloading shards:  50%|█████     | 1/2 [03:48<03:48, 228.59s/it]\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 21.0M/3.50G [00:00<01:19, 43.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 31.5M/3.50G [00:00<01:20, 43.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 41.9M/3.50G [00:00<01:14, 46.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   1%|▏         | 52.4M/3.50G [00:01<01:21, 42.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 73.4M/3.50G [00:01<01:06, 51.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 83.9M/3.50G [00:01<00:59, 57.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 105M/3.50G [00:02<01:02, 53.9MB/s] #033[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 115M/3.50G [00:02<01:14, 45.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 136M/3.50G [00:02<01:21, 41.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 147M/3.50G [00:03<01:21, 40.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 168M/3.50G [00:03<01:13, 45.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 178M/3.50G [00:04<01:31, 36.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 189M/3.50G [00:04<01:16, 43.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 199M/3.50G [00:04<01:23, 39.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 210M/3.50G [00:04<01:22, 39.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 231M/3.50G [00:05<01:01, 52.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 241M/3.50G [00:05<01:01, 52.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 262M/3.50G [00:05<01:00, 53.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 273M/3.50G [00:05<01:08, 46.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 283M/3.50G [00:06<01:04, 49.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 294M/3.50G [00:06<01:16, 42.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▊         | 304M/3.50G [00:07<01:40, 31.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 325M/3.50G [00:07<01:32, 34.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 346M/3.50G [00:07<01:11, 44.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 357M/3.50G [00:08<01:20, 39.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 367M/3.50G [00:08<01:12, 43.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 377M/3.50G [00:08<01:25, 36.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 388M/3.50G [00:09<01:30, 34.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█▏        | 398M/3.50G [00:09<01:22, 37.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 409M/3.50G [00:09<01:30, 34.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 419M/3.50G [00:10<01:26, 35.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 440M/3.50G [00:10<01:08, 44.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 451M/3.50G [00:10<01:22, 37.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 472M/3.50G [00:11<01:10, 43.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 482M/3.50G [00:11<01:23, 36.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 503M/3.50G [00:11<01:09, 42.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 514M/3.50G [00:12<01:11, 41.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 535M/3.50G [00:12<01:05, 45.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 545M/3.50G [00:12<01:06, 44.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 566M/3.50G [00:13<01:03, 46.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▋        | 577M/3.50G [00:13<01:08, 42.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 587M/3.50G [00:13<01:03, 46.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 598M/3.50G [00:14<01:17, 37.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 608M/3.50G [00:14<01:11, 40.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 629M/3.50G [00:14<01:07, 42.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 640M/3.50G [00:15<01:19, 35.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▊        | 650M/3.50G [00:15<01:12, 39.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 661M/3.50G [00:15<01:22, 34.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 671M/3.50G [00:16<01:12, 39.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 682M/3.50G [00:16<01:08, 41.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 692M/3.50G [00:16<01:06, 42.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 703M/3.50G [00:16<00:58, 47.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 713M/3.50G [00:16<00:58, 47.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 724M/3.50G [00:17<01:07, 41.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██▏       | 744M/3.50G [00:17<01:07, 40.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 755M/3.50G [00:18<01:29, 30.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 776M/3.50G [00:18<01:14, 36.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 786M/3.50G [00:19<01:15, 36.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 797M/3.50G [00:19<01:03, 42.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 807M/3.50G [00:19<01:01, 43.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 818M/3.50G [00:19<01:04, 41.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▎       | 828M/3.50G [00:19<00:54, 48.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 839M/3.50G [00:20<01:09, 38.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 849M/3.50G [00:20<01:09, 38.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 870M/3.50G [00:20<00:57, 46.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 881M/3.50G [00:21<00:55, 47.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 902M/3.50G [00:21<00:52, 49.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 912M/3.50G [00:21<01:00, 43.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 933M/3.50G [00:22<00:53, 47.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 954M/3.50G [00:22<00:52, 48.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 965M/3.50G [00:22<00:54, 46.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 975M/3.50G [00:22<00:47, 52.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 986M/3.50G [00:23<00:57, 44.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 996M/3.50G [00:23<01:03, 39.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 1.02G/3.50G [00:24<01:07, 36.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 1.03G/3.50G [00:24<01:02, 39.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 1.05G/3.50G [00:24<00:51, 47.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 1.06G/3.50G [00:25<01:02, 38.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 1.08G/3.50G [00:25<00:49, 49.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 1.09G/3.50G [00:25<00:50, 47.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 1.11G/3.50G [00:26<00:50, 46.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 1.12G/3.50G [00:26<00:53, 44.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 1.14G/3.50G [00:26<00:43, 54.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 1.15G/3.50G [00:27<00:50, 46.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▎      | 1.17G/3.50G [00:27<00:46, 50.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 1.18G/3.50G [00:27<00:52, 44.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 1.21G/3.50G [00:28<00:53, 43.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 1.22G/3.50G [00:28<00:59, 38.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 1.24G/3.50G [00:28<00:46, 48.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 1.25G/3.50G [00:29<00:41, 53.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 1.26G/3.50G [00:29<00:42, 52.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 1.27G/3.50G [00:29<00:52, 42.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 1.29G/3.50G [00:30<01:00, 36.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 1.30G/3.50G [00:30<01:01, 35.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 1.32G/3.50G [00:30<00:49, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 1.33G/3.50G [00:31<00:50, 42.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 1.34G/3.50G [00:31<00:46, 46.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▊      | 1.35G/3.50G [00:31<00:45, 47.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 1.36G/3.50G [00:31<00:46, 45.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 1.38G/3.50G [00:32<00:38, 54.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 1.39G/3.50G [00:32<00:36, 57.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 1.42G/3.50G [00:32<00:32, 63.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 1.43G/3.50G [00:32<00:38, 53.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████▏     | 1.45G/3.50G [00:33<00:42, 47.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 1.46G/3.50G [00:33<00:50, 40.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 1.48G/3.50G [00:34<00:44, 45.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 1.49G/3.50G [00:34<00:45, 44.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 1.50G/3.50G [00:34<00:46, 43.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 1.51G/3.50G [00:35<00:56, 35.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 1.52G/3.50G [00:35<00:48, 40.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▎     | 1.53G/3.50G [00:35<00:40, 48.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 1.54G/3.50G [00:35<00:45, 43.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 1.55G/3.50G [00:35<00:43, 45.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 1.56G/3.50G [00:36<00:45, 42.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 1.57G/3.50G [00:36<00:58, 32.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▌     | 1.58G/3.50G [00:37<00:59, 32.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 1.59G/3.50G [00:37<00:56, 33.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 1.60G/3.50G [00:37<01:07, 28.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▋     | 1.63G/3.50G [00:38<00:47, 39.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 1.64G/3.50G [00:38<00:49, 37.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 1.66G/3.50G [00:38<00:40, 46.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 1.67G/3.50G [00:38<00:39, 46.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 1.68G/3.50G [00:39<00:35, 51.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 1.69G/3.50G [00:39<00:32, 55.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▊     | 1.70G/3.50G [00:39<00:34, 51.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 1.72G/3.50G [00:39<00:38, 46.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 1.73G/3.50G [00:40<00:40, 44.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 1.74G/3.50G [00:40<00:37, 46.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 1.75G/3.50G [00:40<00:32, 53.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 1.76G/3.50G [00:40<00:40, 42.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 1.78G/3.50G [00:41<00:33, 50.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 1.79G/3.50G [00:41<00:37, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 1.81G/3.50G [00:41<00:31, 54.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 1.82G/3.50G [00:42<00:35, 47.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 1.85G/3.50G [00:42<00:34, 47.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 1.86G/3.50G [00:42<00:33, 48.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 1.87G/3.50G [00:42<00:32, 50.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▎    | 1.88G/3.50G [00:43<00:35, 46.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 1.90G/3.50G [00:43<00:32, 49.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 1.91G/3.50G [00:43<00:37, 42.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 1.92G/3.50G [00:44<00:37, 42.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 1.93G/3.50G [00:44<00:36, 43.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 1.94G/3.50G [00:44<00:41, 38.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 1.96G/3.50G [00:45<00:45, 34.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▋    | 1.97G/3.50G [00:45<00:45, 33.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 1.99G/3.50G [00:46<00:38, 39.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 2.00G/3.50G [00:46<00:41, 36.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.01G/3.50G [00:46<00:36, 40.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.02G/3.50G [00:47<00:37, 39.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.03G/3.50G [00:47<00:39, 37.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▊    | 2.06G/3.50G [00:47<00:38, 38.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 2.07G/3.50G [00:48<00:42, 33.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 2.09G/3.50G [00:48<00:32, 42.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 2.10G/3.50G [00:48<00:33, 41.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 2.12G/3.50G [00:49<00:33, 41.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 2.13G/3.50G [00:49<00:34, 40.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████▏   | 2.15G/3.50G [00:50<00:32, 42.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 2.16G/3.50G [00:50<00:32, 40.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 2.17G/3.50G [00:50<00:28, 47.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 2.18G/3.50G [00:50<00:29, 45.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 2.20G/3.50G [00:51<00:22, 56.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 2.21G/3.50G [00:51<00:26, 48.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▎   | 2.22G/3.50G [00:51<00:26, 48.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 2.23G/3.50G [00:51<00:25, 49.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 2.24G/3.50G [00:52<00:25, 48.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 2.25G/3.50G [00:52<00:24, 50.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 2.26G/3.50G [00:52<00:27, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 2.28G/3.50G [00:52<00:27, 44.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 2.30G/3.50G [00:53<00:24, 48.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 2.31G/3.50G [00:53<00:29, 41.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 2.32G/3.50G [00:53<00:25, 46.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.33G/3.50G [00:53<00:26, 44.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.34G/3.50G [00:54<00:27, 41.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.36G/3.50G [00:54<00:21, 53.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 2.37G/3.50G [00:54<00:25, 44.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 2.39G/3.50G [00:55<00:24, 45.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▊   | 2.40G/3.50G [00:55<00:25, 43.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 2.42G/3.50G [00:55<00:22, 47.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 2.43G/3.50G [00:56<00:28, 37.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 2.45G/3.50G [00:56<00:27, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 2.46G/3.50G [00:57<00:32, 32.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 2.47G/3.50G [00:57<00:26, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 2.49G/3.50G [00:57<00:28, 35.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████▏  | 2.50G/3.50G [00:58<00:30, 32.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 2.51G/3.50G [00:58<00:37, 26.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 2.52G/3.50G [00:59<00:32, 30.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 2.54G/3.50G [00:59<00:24, 39.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 2.55G/3.50G [00:59<00:26, 35.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 2.56G/3.50G [01:00<00:32, 29.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▎  | 2.58G/3.50G [01:00<00:24, 38.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 2.59G/3.50G [01:01<00:25, 36.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 2.60G/3.50G [01:01<00:24, 37.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 2.61G/3.50G [01:01<00:24, 36.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 2.62G/3.50G [01:02<00:26, 33.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 2.63G/3.50G [01:02<00:26, 32.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 2.64G/3.50G [01:02<00:23, 37.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 2.66G/3.50G [01:02<00:18, 44.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▋  | 2.67G/3.50G [01:03<00:21, 38.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 2.69G/3.50G [01:03<00:23, 35.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 2.71G/3.50G [01:04<00:24, 32.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 2.73G/3.50G [01:04<00:18, 41.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 2.74G/3.50G [01:05<00:21, 35.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 2.76G/3.50G [01:05<00:17, 42.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 2.77G/3.50G [01:05<00:16, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 2.78G/3.50G [01:05<00:15, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 2.79G/3.50G [01:06<00:18, 39.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 2.80G/3.50G [01:06<00:15, 45.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 2.81G/3.50G [01:06<00:14, 48.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 2.82G/3.50G [01:06<00:15, 43.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 2.84G/3.50G [01:07<00:15, 43.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████▏ | 2.85G/3.50G [01:07<00:16, 40.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 2.87G/3.50G [01:08<00:15, 40.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 2.88G/3.50G [01:08<00:14, 43.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 2.90G/3.50G [01:08<00:12, 46.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 2.92G/3.50G [01:09<00:13, 41.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 2.94G/3.50G [01:09<00:11, 50.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 2.95G/3.50G [01:09<00:10, 52.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 2.97G/3.50G [01:09<00:09, 57.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 2.98G/3.50G [01:10<00:09, 56.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 3.00G/3.50G [01:10<00:07, 64.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 3.01G/3.50G [01:10<00:08, 54.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 3.03G/3.50G [01:10<00:07, 64.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 3.04G/3.50G [01:11<00:08, 57.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 3.06G/3.50G [01:11<00:07, 60.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 3.07G/3.50G [01:11<00:08, 49.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 3.09G/3.50G [01:12<00:07, 57.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▊ | 3.10G/3.50G [01:12<00:10, 39.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 3.11G/3.50G [01:12<00:08, 42.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 3.12G/3.50G [01:13<00:08, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 3.15G/3.50G [01:13<00:07, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 3.16G/3.50G [01:13<00:08, 42.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 3.17G/3.50G [01:13<00:06, 47.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 3.18G/3.50G [01:14<00:06, 51.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 3.19G/3.50G [01:14<00:06, 49.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████▏| 3.20G/3.50G [01:14<00:05, 53.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 3.21G/3.50G [01:14<00:05, 50.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 3.22G/3.50G [01:14<00:06, 45.2MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.24G/3.50G [01:15<00:05, 46.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.25G/3.50G [01:15<00:05, 48.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.27G/3.50G [01:15<00:04, 55.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 3.28G/3.50G [01:16<00:04, 45.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 3.30G/3.50G [01:16<00:04, 44.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▍| 3.31G/3.50G [01:17<00:04, 43.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 3.33G/3.50G [01:17<00:03, 48.5MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 3.34G/3.50G [01:17<00:03, 47.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 3.37G/3.50G [01:17<00:02, 51.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▋| 3.38G/3.50G [01:18<00:02, 51.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 3.40G/3.50G [01:18<00:02, 47.6MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 3.41G/3.50G [01:18<00:01, 47.7MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 3.42G/3.50G [01:19<00:01, 43.0MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 3.43G/3.50G [01:19<00:01, 41.3MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▊| 3.45G/3.50G [01:19<00:00, 53.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 3.46G/3.50G [01:20<00:00, 47.8MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 3.47G/3.50G [01:20<00:00, 52.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 3.48G/3.50G [01:20<00:00, 45.4MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 3.49G/3.50G [01:20<00:00, 51.1MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 3.50G/3.50G [01:20<00:00, 52.9MB/s]#033[A\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 3.50G/3.50G [01:20<00:00, 43.3MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [05:09<00:00, 141.78s/it]\n",
      "Downloading shards: 100%|██████████| 2/2 [05:09<00:00, 154.80s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.53s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.02it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n",
      "Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 188/188 [00:00<00:00, 2.26MB/s]\n",
      "trainable params: 67,108,864 || all params: 3,567,521,792 || trainable%: 1.881105930466591\n",
      "0%|          | 0/1111 [00:00<?, ?it/s]\n",
      "0%|          | 1/1111 [00:13<4:15:08, 13.79s/it]\n",
      "0%|          | 2/1111 [00:27<4:12:43, 13.67s/it]\n",
      "0%|          | 3/1111 [00:40<4:11:48, 13.64s/it]\n",
      "0%|          | 4/1111 [00:54<4:11:16, 13.62s/it]\n",
      "0%|          | 5/1111 [01:08<4:10:51, 13.61s/it]\n",
      "1%|          | 6/1111 [01:21<4:10:31, 13.60s/it]\n",
      "1%|          | 7/1111 [01:35<4:10:12, 13.60s/it]\n",
      "1%|          | 8/1111 [01:48<4:09:56, 13.60s/it]\n",
      "1%|          | 9/1111 [02:02<4:09:40, 13.59s/it]\n",
      "1%|          | 10/1111 [02:16<4:09:26, 13.59s/it]\n",
      "{'loss': 1.3172, 'learning_rate': 9.90999099909991e-05, 'epoch': 0.01}\n",
      "1%|          | 10/1111 [02:16<4:09:26, 13.59s/it]\n",
      "1%|          | 11/1111 [02:29<4:09:11, 13.59s/it]\n",
      "1%|          | 12/1111 [02:43<4:08:57, 13.59s/it]\n",
      "1%|          | 13/1111 [02:56<4:08:42, 13.59s/it]\n",
      "1%|▏         | 14/1111 [03:10<4:08:31, 13.59s/it]\n",
      "1%|▏         | 15/1111 [03:24<4:08:19, 13.59s/it]\n",
      "1%|▏         | 16/1111 [03:37<4:08:07, 13.60s/it]\n",
      "2%|▏         | 17/1111 [03:51<4:07:55, 13.60s/it]\n",
      "2%|▏         | 18/1111 [04:04<4:07:42, 13.60s/it]\n",
      "2%|▏         | 19/1111 [04:18<4:07:29, 13.60s/it]\n",
      "2%|▏         | 20/1111 [04:32<4:07:16, 13.60s/it]\n",
      "{'loss': 0.999, 'learning_rate': 9.819981998199821e-05, 'epoch': 0.02}\n",
      "2%|▏         | 20/1111 [04:32<4:07:16, 13.60s/it]\n",
      "2%|▏         | 21/1111 [04:45<4:07:03, 13.60s/it]\n",
      "2%|▏         | 22/1111 [04:59<4:06:49, 13.60s/it]\n",
      "2%|▏         | 23/1111 [05:12<4:06:36, 13.60s/it]\n",
      "2%|▏         | 24/1111 [05:26<4:06:22, 13.60s/it]\n",
      "2%|▏         | 25/1111 [05:40<4:06:09, 13.60s/it]\n",
      "2%|▏         | 26/1111 [05:53<4:05:56, 13.60s/it]\n",
      "2%|▏         | 27/1111 [06:07<4:05:42, 13.60s/it]\n",
      "3%|▎         | 28/1111 [06:20<4:05:28, 13.60s/it]\n",
      "3%|▎         | 29/1111 [06:34<4:05:14, 13.60s/it]\n",
      "3%|▎         | 30/1111 [06:48<4:05:00, 13.60s/it]\n",
      "{'loss': 0.7478, 'learning_rate': 9.72997299729973e-05, 'epoch': 0.03}\n",
      "3%|▎         | 30/1111 [06:48<4:05:00, 13.60s/it]\n",
      "3%|▎         | 31/1111 [07:01<4:04:46, 13.60s/it]\n",
      "3%|▎         | 32/1111 [07:15<4:04:32, 13.60s/it]\n",
      "3%|▎         | 33/1111 [07:28<4:04:19, 13.60s/it]\n",
      "3%|▎         | 34/1111 [07:42<4:04:05, 13.60s/it]\n",
      "3%|▎         | 35/1111 [07:56<4:03:51, 13.60s/it]\n",
      "3%|▎         | 36/1111 [08:09<4:03:38, 13.60s/it]\n",
      "3%|▎         | 37/1111 [08:23<4:03:25, 13.60s/it]\n",
      "3%|▎         | 38/1111 [08:36<4:03:11, 13.60s/it]\n",
      "4%|▎         | 39/1111 [08:50<4:02:57, 13.60s/it]\n",
      "4%|▎         | 40/1111 [09:04<4:02:44, 13.60s/it]\n",
      "{'loss': 0.5691, 'learning_rate': 9.63996399639964e-05, 'epoch': 0.04}\n",
      "4%|▎         | 40/1111 [09:04<4:02:44, 13.60s/it]\n",
      "4%|▎         | 41/1111 [09:17<4:02:30, 13.60s/it]\n",
      "4%|▍         | 42/1111 [09:31<4:02:16, 13.60s/it]\n",
      "4%|▍         | 43/1111 [09:44<4:02:03, 13.60s/it]\n",
      "4%|▍         | 44/1111 [09:58<4:01:50, 13.60s/it]\n",
      "4%|▍         | 45/1111 [10:12<4:01:36, 13.60s/it]\n",
      "4%|▍         | 46/1111 [10:25<4:01:23, 13.60s/it]\n",
      "4%|▍         | 47/1111 [10:39<4:01:10, 13.60s/it]\n",
      "4%|▍         | 48/1111 [10:52<4:00:57, 13.60s/it]\n",
      "4%|▍         | 49/1111 [11:06<4:00:42, 13.60s/it]\n",
      "5%|▍         | 50/1111 [11:20<4:00:28, 13.60s/it]\n",
      "{'loss': 0.5399, 'learning_rate': 9.54995499549955e-05, 'epoch': 0.05}\n",
      "5%|▍         | 50/1111 [11:20<4:00:28, 13.60s/it]\n",
      "5%|▍         | 51/1111 [11:33<4:00:15, 13.60s/it]\n",
      "5%|▍         | 52/1111 [11:47<4:00:02, 13.60s/it]\n",
      "5%|▍         | 53/1111 [12:00<3:59:48, 13.60s/it]\n",
      "5%|▍         | 54/1111 [12:14<3:59:34, 13.60s/it]\n",
      "5%|▍         | 55/1111 [12:28<3:59:20, 13.60s/it]\n",
      "5%|▌         | 56/1111 [12:41<3:59:06, 13.60s/it]\n",
      "5%|▌         | 57/1111 [12:55<3:58:52, 13.60s/it]\n",
      "5%|▌         | 58/1111 [13:08<3:58:39, 13.60s/it]\n",
      "5%|▌         | 59/1111 [13:22<3:58:25, 13.60s/it]\n",
      "5%|▌         | 60/1111 [13:36<3:58:12, 13.60s/it]\n",
      "{'loss': 0.499, 'learning_rate': 9.45994599459946e-05, 'epoch': 0.05}\n",
      "5%|▌         | 60/1111 [13:36<3:58:12, 13.60s/it]\n",
      "5%|▌         | 61/1111 [13:49<3:57:59, 13.60s/it]\n",
      "6%|▌         | 62/1111 [14:03<3:57:45, 13.60s/it]\n",
      "6%|▌         | 63/1111 [14:16<3:57:31, 13.60s/it]\n",
      "6%|▌         | 64/1111 [14:30<3:57:18, 13.60s/it]\n",
      "6%|▌         | 65/1111 [14:44<3:57:04, 13.60s/it]\n",
      "6%|▌         | 66/1111 [14:57<3:56:50, 13.60s/it]\n",
      "6%|▌         | 67/1111 [15:11<3:56:37, 13.60s/it]\n",
      "6%|▌         | 68/1111 [15:24<3:56:23, 13.60s/it]\n",
      "6%|▌         | 69/1111 [15:38<3:56:10, 13.60s/it]\n",
      "6%|▋         | 70/1111 [15:52<3:55:57, 13.60s/it]\n",
      "{'loss': 0.4759, 'learning_rate': 9.36993699369937e-05, 'epoch': 0.06}\n",
      "6%|▋         | 70/1111 [15:52<3:55:57, 13.60s/it]\n",
      "6%|▋         | 71/1111 [16:05<3:55:43, 13.60s/it]\n",
      "6%|▋         | 72/1111 [16:19<3:55:29, 13.60s/it]\n",
      "7%|▋         | 73/1111 [16:32<3:55:15, 13.60s/it]\n",
      "7%|▋         | 74/1111 [16:46<3:55:01, 13.60s/it]\n",
      "7%|▋         | 75/1111 [17:00<3:54:48, 13.60s/it]\n",
      "7%|▋         | 76/1111 [17:13<3:54:34, 13.60s/it]\n",
      "7%|▋         | 77/1111 [17:27<3:54:20, 13.60s/it]\n",
      "7%|▋         | 78/1111 [17:40<3:54:07, 13.60s/it]\n",
      "7%|▋         | 79/1111 [17:54<3:53:54, 13.60s/it]\n",
      "7%|▋         | 80/1111 [18:08<3:53:41, 13.60s/it]\n",
      "{'loss': 0.4859, 'learning_rate': 9.27992799279928e-05, 'epoch': 0.07}\n",
      "7%|▋         | 80/1111 [18:08<3:53:41, 13.60s/it]\n",
      "7%|▋         | 81/1111 [18:21<3:53:27, 13.60s/it]\n",
      "7%|▋         | 82/1111 [18:35<3:53:13, 13.60s/it]\n",
      "7%|▋         | 83/1111 [18:48<3:53:00, 13.60s/it]\n",
      "8%|▊         | 84/1111 [19:02<3:52:46, 13.60s/it]\n",
      "8%|▊         | 85/1111 [19:16<3:52:33, 13.60s/it]\n",
      "8%|▊         | 86/1111 [19:29<3:52:19, 13.60s/it]\n",
      "8%|▊         | 87/1111 [19:43<3:52:05, 13.60s/it]\n",
      "8%|▊         | 88/1111 [19:56<3:51:51, 13.60s/it]\n",
      "8%|▊         | 89/1111 [20:10<3:51:38, 13.60s/it]\n",
      "8%|▊         | 90/1111 [20:24<3:51:24, 13.60s/it]\n",
      "{'loss': 0.4491, 'learning_rate': 9.18991899189919e-05, 'epoch': 0.08}\n",
      "8%|▊         | 90/1111 [20:24<3:51:24, 13.60s/it]\n",
      "8%|▊         | 91/1111 [20:37<3:51:11, 13.60s/it]\n",
      "8%|▊         | 92/1111 [20:51<3:50:58, 13.60s/it]\n",
      "8%|▊         | 93/1111 [21:04<3:50:44, 13.60s/it]\n",
      "8%|▊         | 94/1111 [21:18<3:50:29, 13.60s/it]\n",
      "9%|▊         | 95/1111 [21:32<3:50:16, 13.60s/it]\n",
      "9%|▊         | 96/1111 [21:45<3:50:03, 13.60s/it]\n",
      "9%|▊         | 97/1111 [21:59<3:49:49, 13.60s/it]\n",
      "9%|▉         | 98/1111 [22:12<3:49:35, 13.60s/it]\n",
      "9%|▉         | 99/1111 [22:26<3:49:22, 13.60s/it]\n",
      "9%|▉         | 100/1111 [22:40<3:49:09, 13.60s/it]\n",
      "{'loss': 0.4446, 'learning_rate': 9.099909990999101e-05, 'epoch': 0.09}\n",
      "9%|▉         | 100/1111 [22:40<3:49:09, 13.60s/it]\n",
      "9%|▉         | 101/1111 [22:53<3:48:55, 13.60s/it]\n",
      "9%|▉         | 102/1111 [23:07<3:48:42, 13.60s/it]\n",
      "9%|▉         | 103/1111 [23:20<3:48:28, 13.60s/it]\n",
      "9%|▉         | 104/1111 [23:34<3:48:14, 13.60s/it]\n",
      "9%|▉         | 105/1111 [23:48<3:48:00, 13.60s/it]\n",
      "10%|▉         | 106/1111 [24:01<3:47:46, 13.60s/it]\n",
      "10%|▉         | 107/1111 [24:15<3:47:32, 13.60s/it]\n",
      "10%|▉         | 108/1111 [24:28<3:47:19, 13.60s/it]\n",
      "10%|▉         | 109/1111 [24:42<3:47:05, 13.60s/it]\n",
      "10%|▉         | 110/1111 [24:55<3:46:51, 13.60s/it]\n",
      "{'loss': 0.4531, 'learning_rate': 9.009900990099011e-05, 'epoch': 0.1}\n",
      "10%|▉         | 110/1111 [24:55<3:46:51, 13.60s/it]\n",
      "10%|▉         | 111/1111 [25:09<3:46:38, 13.60s/it]\n",
      "10%|█         | 112/1111 [25:23<3:46:25, 13.60s/it]\n",
      "10%|█         | 113/1111 [25:36<3:46:11, 13.60s/it]\n",
      "10%|█         | 114/1111 [25:50<3:45:57, 13.60s/it]\n",
      "10%|█         | 115/1111 [26:03<3:45:44, 13.60s/it]\n",
      "10%|█         | 116/1111 [26:17<3:45:30, 13.60s/it]\n",
      "11%|█         | 117/1111 [26:31<3:45:16, 13.60s/it]\n",
      "11%|█         | 118/1111 [26:44<3:45:03, 13.60s/it]\n",
      "11%|█         | 119/1111 [26:58<3:44:50, 13.60s/it]\n",
      "11%|█         | 120/1111 [27:11<3:44:37, 13.60s/it]\n",
      "{'loss': 0.4457, 'learning_rate': 8.919891989198921e-05, 'epoch': 0.11}\n",
      "11%|█         | 120/1111 [27:11<3:44:37, 13.60s/it]\n",
      "11%|█         | 121/1111 [27:25<3:44:23, 13.60s/it]\n",
      "11%|█         | 122/1111 [27:39<3:44:09, 13.60s/it]\n",
      "11%|█         | 123/1111 [27:52<3:43:55, 13.60s/it]\n",
      "11%|█         | 124/1111 [28:06<3:43:42, 13.60s/it]\n",
      "11%|█▏        | 125/1111 [28:19<3:43:29, 13.60s/it]\n",
      "11%|█▏        | 126/1111 [28:33<3:43:15, 13.60s/it]\n",
      "11%|█▏        | 127/1111 [28:47<3:43:02, 13.60s/it]\n",
      "12%|█▏        | 128/1111 [29:00<3:42:48, 13.60s/it]\n",
      "12%|█▏        | 129/1111 [29:14<3:42:34, 13.60s/it]\n",
      "12%|█▏        | 130/1111 [29:27<3:42:20, 13.60s/it]\n",
      "{'loss': 0.4375, 'learning_rate': 8.82988298829883e-05, 'epoch': 0.12}\n",
      "12%|█▏        | 130/1111 [29:27<3:42:20, 13.60s/it]\n",
      "12%|█▏        | 131/1111 [29:41<3:42:06, 13.60s/it]\n",
      "12%|█▏        | 132/1111 [29:55<3:41:53, 13.60s/it]\n",
      "12%|█▏        | 133/1111 [30:08<3:41:40, 13.60s/it]\n",
      "12%|█▏        | 134/1111 [30:22<3:41:26, 13.60s/it]\n",
      "12%|█▏        | 135/1111 [30:35<3:41:12, 13.60s/it]\n",
      "12%|█▏        | 136/1111 [30:49<3:40:58, 13.60s/it]\n",
      "12%|█▏        | 137/1111 [31:03<3:40:45, 13.60s/it]\n",
      "12%|█▏        | 138/1111 [31:16<3:40:31, 13.60s/it]\n",
      "13%|█▎        | 139/1111 [31:30<3:40:18, 13.60s/it]\n",
      "13%|█▎        | 140/1111 [31:43<3:40:04, 13.60s/it]\n",
      "{'loss': 0.4298, 'learning_rate': 8.73987398739874e-05, 'epoch': 0.13}\n",
      "13%|█▎        | 140/1111 [31:43<3:40:04, 13.60s/it]\n",
      "13%|█▎        | 141/1111 [31:57<3:39:50, 13.60s/it]\n",
      "13%|█▎        | 142/1111 [32:11<3:39:38, 13.60s/it]\n",
      "13%|█▎        | 143/1111 [32:24<3:39:24, 13.60s/it]\n",
      "13%|█▎        | 144/1111 [32:38<3:39:10, 13.60s/it]\n",
      "13%|█▎        | 145/1111 [32:51<3:38:57, 13.60s/it]\n",
      "13%|█▎        | 146/1111 [33:05<3:38:43, 13.60s/it]\n",
      "13%|█▎        | 147/1111 [33:19<3:38:29, 13.60s/it]\n",
      "13%|█▎        | 148/1111 [33:32<3:38:16, 13.60s/it]\n",
      "13%|█▎        | 149/1111 [33:46<3:38:02, 13.60s/it]\n",
      "14%|█▎        | 150/1111 [33:59<3:37:49, 13.60s/it]\n",
      "{'loss': 0.4118, 'learning_rate': 8.64986498649865e-05, 'epoch': 0.14}\n",
      "14%|█▎        | 150/1111 [33:59<3:37:49, 13.60s/it]\n",
      "14%|█▎        | 151/1111 [34:13<3:37:36, 13.60s/it]\n",
      "14%|█▎        | 152/1111 [34:27<3:37:22, 13.60s/it]\n",
      "14%|█▍        | 153/1111 [34:40<3:37:08, 13.60s/it]\n",
      "14%|█▍        | 154/1111 [34:54<3:36:54, 13.60s/it]\n",
      "14%|█▍        | 155/1111 [35:07<3:36:41, 13.60s/it]\n",
      "14%|█▍        | 156/1111 [35:21<3:36:27, 13.60s/it]\n",
      "14%|█▍        | 157/1111 [35:35<3:36:13, 13.60s/it]\n",
      "14%|█▍        | 158/1111 [35:48<3:36:00, 13.60s/it]\n",
      "14%|█▍        | 159/1111 [36:02<3:35:47, 13.60s/it]\n",
      "14%|█▍        | 160/1111 [36:15<3:35:34, 13.60s/it]\n",
      "{'loss': 0.4127, 'learning_rate': 8.55985598559856e-05, 'epoch': 0.14}\n",
      "14%|█▍        | 160/1111 [36:15<3:35:34, 13.60s/it]\n",
      "14%|█▍        | 161/1111 [36:29<3:35:21, 13.60s/it]\n",
      "15%|█▍        | 162/1111 [36:43<3:35:07, 13.60s/it]\n",
      "15%|█▍        | 163/1111 [36:56<3:34:52, 13.60s/it]\n",
      "15%|█▍        | 164/1111 [37:10<3:34:39, 13.60s/it]\n",
      "15%|█▍        | 165/1111 [37:23<3:34:26, 13.60s/it]\n",
      "15%|█▍        | 166/1111 [37:37<3:34:12, 13.60s/it]\n",
      "15%|█▌        | 167/1111 [37:51<3:33:58, 13.60s/it]\n",
      "15%|█▌        | 168/1111 [38:04<3:33:45, 13.60s/it]\n",
      "15%|█▌        | 169/1111 [38:18<3:33:31, 13.60s/it]\n",
      "15%|█▌        | 170/1111 [38:31<3:33:17, 13.60s/it]\n",
      "{'loss': 0.4197, 'learning_rate': 8.46984698469847e-05, 'epoch': 0.15}\n",
      "15%|█▌        | 170/1111 [38:31<3:33:17, 13.60s/it]\n",
      "15%|█▌        | 171/1111 [38:45<3:33:03, 13.60s/it]\n",
      "15%|█▌        | 172/1111 [38:59<3:32:49, 13.60s/it]\n",
      "16%|█▌        | 173/1111 [39:12<3:32:35, 13.60s/it]\n",
      "16%|█▌        | 174/1111 [39:26<3:32:22, 13.60s/it]\n",
      "16%|█▌        | 175/1111 [39:39<3:32:09, 13.60s/it]\n",
      "16%|█▌        | 176/1111 [39:53<3:31:56, 13.60s/it]\n",
      "16%|█▌        | 177/1111 [40:07<3:31:42, 13.60s/it]\n",
      "16%|█▌        | 178/1111 [40:20<3:31:28, 13.60s/it]\n",
      "16%|█▌        | 179/1111 [40:34<3:31:15, 13.60s/it]\n",
      "16%|█▌        | 180/1111 [40:47<3:31:01, 13.60s/it]\n",
      "{'loss': 0.3894, 'learning_rate': 8.379837983798379e-05, 'epoch': 0.16}\n",
      "16%|█▌        | 180/1111 [40:47<3:31:01, 13.60s/it]\n",
      "16%|█▋        | 181/1111 [41:01<3:30:48, 13.60s/it]\n",
      "16%|█▋        | 182/1111 [41:15<3:30:34, 13.60s/it]\n",
      "16%|█▋        | 183/1111 [41:28<3:30:21, 13.60s/it]\n",
      "17%|█▋        | 184/1111 [41:42<3:30:07, 13.60s/it]\n",
      "17%|█▋        | 185/1111 [41:55<3:29:53, 13.60s/it]\n",
      "17%|█▋        | 186/1111 [42:09<3:29:39, 13.60s/it]\n",
      "17%|█▋        | 187/1111 [42:23<3:29:26, 13.60s/it]\n",
      "17%|█▋        | 188/1111 [42:36<3:29:12, 13.60s/it]\n",
      "17%|█▋        | 189/1111 [42:50<3:28:58, 13.60s/it]\n",
      "17%|█▋        | 190/1111 [43:03<3:28:45, 13.60s/it]\n",
      "{'loss': 0.403, 'learning_rate': 8.28982898289829e-05, 'epoch': 0.17}\n",
      "17%|█▋        | 190/1111 [43:03<3:28:45, 13.60s/it]\n",
      "17%|█▋        | 191/1111 [43:17<3:28:32, 13.60s/it]\n",
      "17%|█▋        | 192/1111 [43:31<3:28:18, 13.60s/it]\n",
      "17%|█▋        | 193/1111 [43:44<3:28:04, 13.60s/it]\n",
      "17%|█▋        | 194/1111 [43:58<3:27:50, 13.60s/it]\n",
      "18%|█▊        | 195/1111 [44:11<3:27:37, 13.60s/it]\n",
      "18%|█▊        | 196/1111 [44:25<3:27:24, 13.60s/it]\n",
      "18%|█▊        | 197/1111 [44:39<3:27:10, 13.60s/it]\n",
      "18%|█▊        | 198/1111 [44:52<3:26:56, 13.60s/it]\n",
      "18%|█▊        | 199/1111 [45:06<3:26:42, 13.60s/it]\n",
      "18%|█▊        | 200/1111 [45:19<3:26:29, 13.60s/it]\n",
      "{'loss': 0.3964, 'learning_rate': 8.1998199819982e-05, 'epoch': 0.18}\n",
      "18%|█▊        | 200/1111 [45:19<3:26:29, 13.60s/it]\n",
      "18%|█▊        | 201/1111 [45:33<3:26:15, 13.60s/it]\n",
      "18%|█▊        | 202/1111 [45:47<3:26:01, 13.60s/it]\n",
      "18%|█▊        | 203/1111 [46:00<3:25:48, 13.60s/it]\n",
      "18%|█▊        | 204/1111 [46:14<3:25:34, 13.60s/it]\n",
      "18%|█▊        | 205/1111 [46:27<3:25:21, 13.60s/it]\n",
      "19%|█▊        | 206/1111 [46:41<3:25:07, 13.60s/it]\n",
      "19%|█▊        | 207/1111 [46:55<3:24:53, 13.60s/it]\n",
      "19%|█▊        | 208/1111 [47:08<3:24:40, 13.60s/it]\n",
      "19%|█▉        | 209/1111 [47:22<3:24:26, 13.60s/it]\n",
      "19%|█▉        | 210/1111 [47:35<3:24:13, 13.60s/it]\n",
      "{'loss': 0.4152, 'learning_rate': 8.109810981098111e-05, 'epoch': 0.19}\n",
      "19%|█▉        | 210/1111 [47:35<3:24:13, 13.60s/it]\n",
      "19%|█▉        | 211/1111 [47:49<3:24:00, 13.60s/it]\n",
      "19%|█▉        | 212/1111 [48:03<3:23:46, 13.60s/it]\n",
      "19%|█▉        | 213/1111 [48:16<3:23:32, 13.60s/it]\n",
      "19%|█▉        | 214/1111 [48:30<3:23:19, 13.60s/it]\n",
      "19%|█▉        | 215/1111 [48:43<3:23:05, 13.60s/it]\n",
      "19%|█▉        | 216/1111 [48:57<3:22:51, 13.60s/it]\n",
      "20%|█▉        | 217/1111 [49:11<3:22:37, 13.60s/it]\n",
      "20%|█▉        | 218/1111 [49:24<3:22:24, 13.60s/it]\n",
      "20%|█▉        | 219/1111 [49:38<3:22:10, 13.60s/it]\n",
      "20%|█▉        | 220/1111 [49:51<3:21:57, 13.60s/it]\n",
      "{'loss': 0.3849, 'learning_rate': 8.019801980198021e-05, 'epoch': 0.2}\n",
      "20%|█▉        | 220/1111 [49:51<3:21:57, 13.60s/it]\n",
      "20%|█▉        | 221/1111 [50:05<3:21:43, 13.60s/it]\n",
      "20%|█▉        | 222/1111 [50:19<3:21:29, 13.60s/it]\n",
      "20%|██        | 223/1111 [50:32<3:21:15, 13.60s/it]\n",
      "20%|██        | 224/1111 [50:46<3:21:02, 13.60s/it]\n",
      "20%|██        | 225/1111 [50:59<3:20:49, 13.60s/it]\n",
      "20%|██        | 226/1111 [51:13<3:20:36, 13.60s/it]\n",
      "20%|██        | 227/1111 [51:27<3:20:22, 13.60s/it]\n",
      "21%|██        | 228/1111 [51:40<3:20:08, 13.60s/it]\n",
      "21%|██        | 229/1111 [51:54<3:19:55, 13.60s/it]\n",
      "21%|██        | 230/1111 [52:07<3:19:41, 13.60s/it]\n",
      "{'loss': 0.3828, 'learning_rate': 7.92979297929793e-05, 'epoch': 0.21}\n",
      "21%|██        | 230/1111 [52:07<3:19:41, 13.60s/it]\n",
      "21%|██        | 231/1111 [52:21<3:19:28, 13.60s/it]\n",
      "21%|██        | 232/1111 [52:35<3:19:15, 13.60s/it]\n",
      "21%|██        | 233/1111 [52:48<3:19:01, 13.60s/it]\n",
      "21%|██        | 234/1111 [53:02<3:18:47, 13.60s/it]\n",
      "21%|██        | 235/1111 [53:15<3:18:33, 13.60s/it]\n",
      "21%|██        | 236/1111 [53:29<3:18:19, 13.60s/it]\n",
      "21%|██▏       | 237/1111 [53:43<3:18:05, 13.60s/it]\n",
      "21%|██▏       | 238/1111 [53:56<3:17:52, 13.60s/it]\n",
      "22%|██▏       | 239/1111 [54:10<3:17:38, 13.60s/it]\n",
      "22%|██▏       | 240/1111 [54:23<3:17:24, 13.60s/it]\n",
      "{'loss': 0.4029, 'learning_rate': 7.83978397839784e-05, 'epoch': 0.22}\n",
      "22%|██▏       | 240/1111 [54:23<3:17:24, 13.60s/it]\n",
      "22%|██▏       | 241/1111 [54:37<3:17:11, 13.60s/it]\n",
      "22%|██▏       | 242/1111 [54:51<3:16:57, 13.60s/it]\n",
      "22%|██▏       | 243/1111 [55:04<3:16:44, 13.60s/it]\n",
      "22%|██▏       | 244/1111 [55:18<3:16:30, 13.60s/it]\n",
      "22%|██▏       | 245/1111 [55:31<3:16:17, 13.60s/it]\n",
      "22%|██▏       | 246/1111 [55:45<3:16:04, 13.60s/it]\n",
      "22%|██▏       | 247/1111 [55:59<3:15:50, 13.60s/it]\n",
      "22%|██▏       | 248/1111 [56:12<3:15:36, 13.60s/it]\n",
      "22%|██▏       | 249/1111 [56:26<3:15:22, 13.60s/it]\n",
      "23%|██▎       | 250/1111 [56:39<3:15:09, 13.60s/it]\n",
      "{'loss': 0.3946, 'learning_rate': 7.74977497749775e-05, 'epoch': 0.23}\n",
      "23%|██▎       | 250/1111 [56:39<3:15:09, 13.60s/it]\n",
      "23%|██▎       | 251/1111 [56:53<3:14:55, 13.60s/it]\n",
      "23%|██▎       | 252/1111 [57:07<3:14:42, 13.60s/it]\n",
      "23%|██▎       | 253/1111 [57:20<3:14:28, 13.60s/it]\n",
      "23%|██▎       | 254/1111 [57:34<3:14:15, 13.60s/it]\n",
      "23%|██▎       | 255/1111 [57:47<3:14:01, 13.60s/it]\n",
      "23%|██▎       | 256/1111 [58:01<3:13:47, 13.60s/it]\n",
      "23%|██▎       | 257/1111 [58:15<3:13:33, 13.60s/it]\n",
      "23%|██▎       | 258/1111 [58:28<3:13:20, 13.60s/it]\n",
      "23%|██▎       | 259/1111 [58:42<3:13:06, 13.60s/it]\n",
      "23%|██▎       | 260/1111 [58:55<3:12:53, 13.60s/it]\n",
      "{'loss': 0.3897, 'learning_rate': 7.65976597659766e-05, 'epoch': 0.23}\n",
      "23%|██▎       | 260/1111 [58:55<3:12:53, 13.60s/it]\n",
      "23%|██▎       | 261/1111 [59:09<3:12:39, 13.60s/it]\n",
      "24%|██▎       | 262/1111 [59:23<3:12:25, 13.60s/it]\n",
      "24%|██▎       | 263/1111 [59:36<3:12:11, 13.60s/it]\n",
      "24%|██▍       | 264/1111 [59:50<3:11:58, 13.60s/it]\n",
      "24%|██▍       | 265/1111 [1:00:03<3:11:45, 13.60s/it]\n",
      "24%|██▍       | 266/1111 [1:00:17<3:11:31, 13.60s/it]\n",
      "24%|██▍       | 267/1111 [1:00:31<3:11:18, 13.60s/it]\n",
      "24%|██▍       | 268/1111 [1:00:44<3:11:04, 13.60s/it]\n",
      "24%|██▍       | 269/1111 [1:00:58<3:10:51, 13.60s/it]\n",
      "24%|██▍       | 270/1111 [1:01:11<3:10:37, 13.60s/it]\n",
      "{'loss': 0.4001, 'learning_rate': 7.56975697569757e-05, 'epoch': 0.24}\n",
      "24%|██▍       | 270/1111 [1:01:11<3:10:37, 13.60s/it]\n",
      "24%|██▍       | 271/1111 [1:01:25<3:10:23, 13.60s/it]\n",
      "24%|██▍       | 272/1111 [1:01:39<3:10:09, 13.60s/it]\n",
      "25%|██▍       | 273/1111 [1:01:52<3:09:56, 13.60s/it]\n",
      "25%|██▍       | 274/1111 [1:02:06<3:09:43, 13.60s/it]\n",
      "25%|██▍       | 275/1111 [1:02:19<3:09:29, 13.60s/it]\n",
      "25%|██▍       | 276/1111 [1:02:33<3:09:16, 13.60s/it]\n",
      "25%|██▍       | 277/1111 [1:02:47<3:09:02, 13.60s/it]\n",
      "25%|██▌       | 278/1111 [1:03:00<3:08:49, 13.60s/it]\n",
      "25%|██▌       | 279/1111 [1:03:14<3:08:35, 13.60s/it]\n",
      "25%|██▌       | 280/1111 [1:03:27<3:08:22, 13.60s/it]\n",
      "{'loss': 0.3926, 'learning_rate': 7.47974797479748e-05, 'epoch': 0.25}\n",
      "25%|██▌       | 280/1111 [1:03:27<3:08:22, 13.60s/it]\n",
      "25%|██▌       | 281/1111 [1:03:41<3:08:08, 13.60s/it]\n",
      "25%|██▌       | 282/1111 [1:03:55<3:07:55, 13.60s/it]\n",
      "25%|██▌       | 283/1111 [1:04:08<3:07:41, 13.60s/it]\n",
      "26%|██▌       | 284/1111 [1:04:22<3:07:27, 13.60s/it]\n",
      "26%|██▌       | 285/1111 [1:04:35<3:07:13, 13.60s/it]\n",
      "26%|██▌       | 286/1111 [1:04:49<3:06:59, 13.60s/it]\n",
      "26%|██▌       | 287/1111 [1:05:03<3:06:46, 13.60s/it]\n",
      "26%|██▌       | 288/1111 [1:05:16<3:06:32, 13.60s/it]\n",
      "26%|██▌       | 289/1111 [1:05:30<3:06:18, 13.60s/it]\n",
      "26%|██▌       | 290/1111 [1:05:43<3:06:04, 13.60s/it]\n",
      "{'loss': 0.3817, 'learning_rate': 7.38973897389739e-05, 'epoch': 0.26}\n",
      "26%|██▌       | 290/1111 [1:05:43<3:06:04, 13.60s/it]\n",
      "26%|██▌       | 291/1111 [1:05:57<3:05:51, 13.60s/it]\n",
      "26%|██▋       | 292/1111 [1:06:11<3:05:37, 13.60s/it]\n",
      "26%|██▋       | 293/1111 [1:06:24<3:05:24, 13.60s/it]\n",
      "26%|██▋       | 294/1111 [1:06:38<3:05:10, 13.60s/it]\n",
      "27%|██▋       | 295/1111 [1:06:51<3:04:56, 13.60s/it]\n",
      "27%|██▋       | 296/1111 [1:07:05<3:04:43, 13.60s/it]\n",
      "27%|██▋       | 297/1111 [1:07:19<3:04:30, 13.60s/it]\n",
      "27%|██▋       | 298/1111 [1:07:32<3:04:17, 13.60s/it]\n",
      "27%|██▋       | 299/1111 [1:07:46<3:04:03, 13.60s/it]\n",
      "27%|██▋       | 300/1111 [1:07:59<3:03:49, 13.60s/it]\n",
      "{'loss': 0.3762, 'learning_rate': 7.2997299729973e-05, 'epoch': 0.27}\n",
      "27%|██▋       | 300/1111 [1:07:59<3:03:49, 13.60s/it]\n",
      "27%|██▋       | 301/1111 [1:08:13<3:03:35, 13.60s/it]\n",
      "27%|██▋       | 302/1111 [1:08:27<3:03:22, 13.60s/it]\n",
      "27%|██▋       | 303/1111 [1:08:40<3:03:08, 13.60s/it]\n",
      "27%|██▋       | 304/1111 [1:08:54<3:02:55, 13.60s/it]\n",
      "27%|██▋       | 305/1111 [1:09:07<3:02:41, 13.60s/it]\n",
      "28%|██▊       | 306/1111 [1:09:21<3:02:27, 13.60s/it]\n",
      "28%|██▊       | 307/1111 [1:09:35<3:02:14, 13.60s/it]\n",
      "28%|██▊       | 308/1111 [1:09:48<3:02:00, 13.60s/it]\n",
      "28%|██▊       | 309/1111 [1:10:02<3:01:47, 13.60s/it]\n",
      "28%|██▊       | 310/1111 [1:10:15<3:01:33, 13.60s/it]\n",
      "{'loss': 0.3908, 'learning_rate': 7.20972097209721e-05, 'epoch': 0.28}\n",
      "28%|██▊       | 310/1111 [1:10:15<3:01:33, 13.60s/it]\n",
      "28%|██▊       | 311/1111 [1:10:29<3:01:20, 13.60s/it]\n",
      "28%|██▊       | 312/1111 [1:10:43<3:01:06, 13.60s/it]\n",
      "28%|██▊       | 313/1111 [1:10:56<3:00:52, 13.60s/it]\n",
      "28%|██▊       | 314/1111 [1:11:10<3:00:39, 13.60s/it]\n",
      "28%|██▊       | 315/1111 [1:11:23<3:00:25, 13.60s/it]\n",
      "28%|██▊       | 316/1111 [1:11:37<3:00:12, 13.60s/it]\n",
      "29%|██▊       | 317/1111 [1:11:51<2:59:58, 13.60s/it]\n",
      "29%|██▊       | 318/1111 [1:12:04<2:59:44, 13.60s/it]\n",
      "29%|██▊       | 319/1111 [1:12:18<2:59:31, 13.60s/it]\n",
      "29%|██▉       | 320/1111 [1:12:31<2:59:17, 13.60s/it]\n",
      "{'loss': 0.3844, 'learning_rate': 7.11971197119712e-05, 'epoch': 0.29}\n",
      "29%|██▉       | 320/1111 [1:12:31<2:59:17, 13.60s/it]\n",
      "29%|██▉       | 321/1111 [1:12:45<2:59:03, 13.60s/it]\n",
      "29%|██▉       | 322/1111 [1:12:59<2:58:49, 13.60s/it]\n",
      "29%|██▉       | 323/1111 [1:13:12<2:58:35, 13.60s/it]\n",
      "29%|██▉       | 324/1111 [1:13:26<2:58:22, 13.60s/it]\n",
      "29%|██▉       | 325/1111 [1:13:39<2:58:08, 13.60s/it]\n",
      "29%|██▉       | 326/1111 [1:13:53<2:57:55, 13.60s/it]\n",
      "29%|██▉       | 327/1111 [1:14:07<2:57:41, 13.60s/it]\n",
      "30%|██▉       | 328/1111 [1:14:20<2:57:28, 13.60s/it]\n",
      "30%|██▉       | 329/1111 [1:14:34<2:57:14, 13.60s/it]\n",
      "30%|██▉       | 330/1111 [1:14:47<2:57:00, 13.60s/it]\n",
      "{'loss': 0.3897, 'learning_rate': 7.02970297029703e-05, 'epoch': 0.3}\n",
      "30%|██▉       | 330/1111 [1:14:47<2:57:00, 13.60s/it]\n",
      "30%|██▉       | 331/1111 [1:15:01<2:56:47, 13.60s/it]\n",
      "30%|██▉       | 332/1111 [1:15:15<2:56:34, 13.60s/it]\n",
      "30%|██▉       | 333/1111 [1:15:28<2:56:20, 13.60s/it]\n",
      "30%|███       | 334/1111 [1:15:42<2:56:06, 13.60s/it]\n",
      "30%|███       | 335/1111 [1:15:55<2:55:52, 13.60s/it]\n",
      "30%|███       | 336/1111 [1:16:09<2:55:39, 13.60s/it]\n",
      "30%|███       | 337/1111 [1:16:23<2:55:25, 13.60s/it]\n",
      "30%|███       | 338/1111 [1:16:36<2:55:12, 13.60s/it]\n",
      "31%|███       | 339/1111 [1:16:50<2:54:58, 13.60s/it]\n",
      "31%|███       | 340/1111 [1:17:03<2:54:45, 13.60s/it]\n",
      "{'loss': 0.385, 'learning_rate': 6.93969396939694e-05, 'epoch': 0.31}\n",
      "31%|███       | 340/1111 [1:17:03<2:54:45, 13.60s/it]\n",
      "31%|███       | 341/1111 [1:17:17<2:54:31, 13.60s/it]\n",
      "31%|███       | 342/1111 [1:17:31<2:54:18, 13.60s/it]\n",
      "31%|███       | 343/1111 [1:17:44<2:54:04, 13.60s/it]\n",
      "31%|███       | 344/1111 [1:17:58<2:53:51, 13.60s/it]\n",
      "31%|███       | 345/1111 [1:18:11<2:53:37, 13.60s/it]\n",
      "31%|███       | 346/1111 [1:18:25<2:53:24, 13.60s/it]\n",
      "31%|███       | 347/1111 [1:18:39<2:53:10, 13.60s/it]\n",
      "31%|███▏      | 348/1111 [1:18:52<2:52:56, 13.60s/it]\n",
      "31%|███▏      | 349/1111 [1:19:06<2:52:43, 13.60s/it]\n",
      "32%|███▏      | 350/1111 [1:19:19<2:52:29, 13.60s/it]\n",
      "{'loss': 0.3699, 'learning_rate': 6.84968496849685e-05, 'epoch': 0.32}\n",
      "32%|███▏      | 350/1111 [1:19:19<2:52:29, 13.60s/it]\n",
      "32%|███▏      | 351/1111 [1:19:33<2:52:16, 13.60s/it]\n",
      "32%|███▏      | 352/1111 [1:19:47<2:52:02, 13.60s/it]\n",
      "32%|███▏      | 353/1111 [1:20:00<2:51:48, 13.60s/it]\n",
      "32%|███▏      | 354/1111 [1:20:14<2:51:35, 13.60s/it]\n",
      "32%|███▏      | 355/1111 [1:20:27<2:51:21, 13.60s/it]\n",
      "32%|███▏      | 356/1111 [1:20:41<2:51:08, 13.60s/it]\n",
      "32%|███▏      | 357/1111 [1:20:55<2:50:54, 13.60s/it]\n",
      "32%|███▏      | 358/1111 [1:21:08<2:50:40, 13.60s/it]\n",
      "32%|███▏      | 359/1111 [1:21:22<2:50:27, 13.60s/it]\n",
      "32%|███▏      | 360/1111 [1:21:35<2:50:13, 13.60s/it]\n",
      "{'loss': 0.3628, 'learning_rate': 6.759675967596761e-05, 'epoch': 0.32}\n",
      "32%|███▏      | 360/1111 [1:21:35<2:50:13, 13.60s/it]\n",
      "32%|███▏      | 361/1111 [1:21:49<2:50:00, 13.60s/it]\n",
      "33%|███▎      | 362/1111 [1:22:03<2:49:46, 13.60s/it]\n",
      "33%|███▎      | 363/1111 [1:22:16<2:49:32, 13.60s/it]\n",
      "33%|███▎      | 364/1111 [1:22:30<2:49:18, 13.60s/it]\n",
      "33%|███▎      | 365/1111 [1:22:43<2:49:05, 13.60s/it]\n",
      "33%|███▎      | 366/1111 [1:22:57<2:48:51, 13.60s/it]\n",
      "33%|███▎      | 367/1111 [1:23:11<2:48:37, 13.60s/it]\n",
      "33%|███▎      | 368/1111 [1:23:24<2:48:23, 13.60s/it]\n",
      "33%|███▎      | 369/1111 [1:23:38<2:48:10, 13.60s/it]\n",
      "33%|███▎      | 370/1111 [1:23:51<2:47:56, 13.60s/it]\n",
      "{'loss': 0.3711, 'learning_rate': 6.669666966696671e-05, 'epoch': 0.33}\n",
      "33%|███▎      | 370/1111 [1:23:51<2:47:56, 13.60s/it]\n",
      "33%|███▎      | 371/1111 [1:24:05<2:47:43, 13.60s/it]\n",
      "33%|███▎      | 372/1111 [1:24:19<2:47:30, 13.60s/it]\n",
      "34%|███▎      | 373/1111 [1:24:32<2:47:16, 13.60s/it]\n",
      "34%|███▎      | 374/1111 [1:24:46<2:47:02, 13.60s/it]\n",
      "34%|███▍      | 375/1111 [1:24:59<2:46:49, 13.60s/it]\n",
      "34%|███▍      | 376/1111 [1:25:13<2:46:35, 13.60s/it]\n",
      "34%|███▍      | 377/1111 [1:25:27<2:46:21, 13.60s/it]\n",
      "34%|███▍      | 378/1111 [1:25:40<2:46:08, 13.60s/it]\n",
      "34%|███▍      | 379/1111 [1:25:54<2:45:54, 13.60s/it]\n",
      "34%|███▍      | 380/1111 [1:26:07<2:45:41, 13.60s/it]\n",
      "{'loss': 0.3527, 'learning_rate': 6.57965796579658e-05, 'epoch': 0.34}\n",
      "34%|███▍      | 380/1111 [1:26:07<2:45:41, 13.60s/it]\n",
      "34%|███▍      | 381/1111 [1:26:21<2:45:28, 13.60s/it]\n",
      "34%|███▍      | 382/1111 [1:26:35<2:45:14, 13.60s/it]\n",
      "34%|███▍      | 383/1111 [1:26:48<2:45:00, 13.60s/it]\n",
      "35%|███▍      | 384/1111 [1:27:02<2:44:47, 13.60s/it]\n",
      "35%|███▍      | 385/1111 [1:27:15<2:44:33, 13.60s/it]\n",
      "35%|███▍      | 386/1111 [1:27:29<2:44:19, 13.60s/it]\n",
      "35%|███▍      | 387/1111 [1:27:43<2:44:05, 13.60s/it]\n",
      "35%|███▍      | 388/1111 [1:27:56<2:43:52, 13.60s/it]\n",
      "35%|███▌      | 389/1111 [1:28:10<2:43:38, 13.60s/it]\n",
      "35%|███▌      | 390/1111 [1:28:23<2:43:25, 13.60s/it]\n",
      "{'loss': 0.3587, 'learning_rate': 6.48964896489649e-05, 'epoch': 0.35}\n",
      "35%|███▌      | 390/1111 [1:28:23<2:43:25, 13.60s/it]\n",
      "35%|███▌      | 391/1111 [1:28:37<2:43:12, 13.60s/it]\n",
      "35%|███▌      | 392/1111 [1:28:51<2:42:58, 13.60s/it]\n",
      "35%|███▌      | 393/1111 [1:29:04<2:42:44, 13.60s/it]\n",
      "35%|███▌      | 394/1111 [1:29:18<2:42:30, 13.60s/it]\n",
      "36%|███▌      | 395/1111 [1:29:31<2:42:17, 13.60s/it]\n",
      "36%|███▌      | 396/1111 [1:29:45<2:42:03, 13.60s/it]\n",
      "36%|███▌      | 397/1111 [1:29:59<2:41:49, 13.60s/it]\n",
      "36%|███▌      | 398/1111 [1:30:12<2:41:35, 13.60s/it]\n",
      "36%|███▌      | 399/1111 [1:30:26<2:41:22, 13.60s/it]\n",
      "36%|███▌      | 400/1111 [1:30:39<2:41:09, 13.60s/it]\n",
      "{'loss': 0.3756, 'learning_rate': 6.3996399639964e-05, 'epoch': 0.36}\n",
      "36%|███▌      | 400/1111 [1:30:39<2:41:09, 13.60s/it]\n",
      "36%|███▌      | 401/1111 [1:30:53<2:40:55, 13.60s/it]\n",
      "36%|███▌      | 402/1111 [1:31:07<2:40:42, 13.60s/it]\n",
      "36%|███▋      | 403/1111 [1:31:20<2:40:28, 13.60s/it]\n",
      "36%|███▋      | 404/1111 [1:31:34<2:40:15, 13.60s/it]\n",
      "36%|███▋      | 405/1111 [1:31:47<2:40:01, 13.60s/it]\n",
      "37%|███▋      | 406/1111 [1:32:01<2:39:47, 13.60s/it]\n",
      "37%|███▋      | 407/1111 [1:32:15<2:39:34, 13.60s/it]\n",
      "37%|███▋      | 408/1111 [1:32:28<2:39:20, 13.60s/it]\n",
      "37%|███▋      | 409/1111 [1:32:42<2:39:06, 13.60s/it]\n",
      "37%|███▋      | 410/1111 [1:32:55<2:38:52, 13.60s/it]\n",
      "{'loss': 0.371, 'learning_rate': 6.30963096309631e-05, 'epoch': 0.37}\n",
      "37%|███▋      | 410/1111 [1:32:55<2:38:52, 13.60s/it]\n",
      "37%|███▋      | 411/1111 [1:33:09<2:38:39, 13.60s/it]\n",
      "37%|███▋      | 412/1111 [1:33:23<2:38:26, 13.60s/it]\n",
      "37%|███▋      | 413/1111 [1:33:36<2:38:12, 13.60s/it]\n",
      "37%|███▋      | 414/1111 [1:33:50<2:37:59, 13.60s/it]\n",
      "37%|███▋      | 415/1111 [1:34:03<2:37:45, 13.60s/it]\n",
      "37%|███▋      | 416/1111 [1:34:17<2:37:31, 13.60s/it]\n",
      "38%|███▊      | 417/1111 [1:34:31<2:37:18, 13.60s/it]\n",
      "38%|███▊      | 418/1111 [1:34:44<2:37:04, 13.60s/it]\n",
      "38%|███▊      | 419/1111 [1:34:58<2:36:50, 13.60s/it]\n",
      "38%|███▊      | 420/1111 [1:35:11<2:36:36, 13.60s/it]\n",
      "{'loss': 0.3694, 'learning_rate': 6.21962196219622e-05, 'epoch': 0.38}\n",
      "38%|███▊      | 420/1111 [1:35:11<2:36:36, 13.60s/it]\n",
      "38%|███▊      | 421/1111 [1:35:25<2:36:22, 13.60s/it]\n",
      "38%|███▊      | 422/1111 [1:35:39<2:36:09, 13.60s/it]\n",
      "38%|███▊      | 423/1111 [1:35:52<2:35:56, 13.60s/it]\n",
      "38%|███▊      | 424/1111 [1:36:06<2:35:42, 13.60s/it]\n",
      "38%|███▊      | 425/1111 [1:36:19<2:35:29, 13.60s/it]\n",
      "38%|███▊      | 426/1111 [1:36:33<2:35:15, 13.60s/it]\n",
      "38%|███▊      | 427/1111 [1:36:47<2:35:01, 13.60s/it]\n",
      "39%|███▊      | 428/1111 [1:37:00<2:34:48, 13.60s/it]\n",
      "39%|███▊      | 429/1111 [1:37:14<2:34:34, 13.60s/it]\n",
      "39%|███▊      | 430/1111 [1:37:27<2:34:21, 13.60s/it]\n",
      "{'loss': 0.3586, 'learning_rate': 6.129612961296129e-05, 'epoch': 0.39}\n",
      "39%|███▊      | 430/1111 [1:37:27<2:34:21, 13.60s/it]\n",
      "39%|███▉      | 431/1111 [1:37:41<2:34:08, 13.60s/it]\n",
      "39%|███▉      | 432/1111 [1:37:55<2:33:54, 13.60s/it]\n",
      "39%|███▉      | 433/1111 [1:38:08<2:33:41, 13.60s/it]\n",
      "39%|███▉      | 434/1111 [1:38:22<2:33:27, 13.60s/it]\n",
      "39%|███▉      | 435/1111 [1:38:35<2:33:13, 13.60s/it]\n",
      "39%|███▉      | 436/1111 [1:38:49<2:32:59, 13.60s/it]\n",
      "39%|███▉      | 437/1111 [1:39:03<2:32:45, 13.60s/it]\n",
      "39%|███▉      | 438/1111 [1:39:16<2:32:32, 13.60s/it]\n",
      "40%|███▉      | 439/1111 [1:39:30<2:32:18, 13.60s/it]\n",
      "40%|███▉      | 440/1111 [1:39:43<2:32:04, 13.60s/it]\n",
      "{'loss': 0.3688, 'learning_rate': 6.03960396039604e-05, 'epoch': 0.4}\n",
      "40%|███▉      | 440/1111 [1:39:43<2:32:04, 13.60s/it]\n",
      "40%|███▉      | 441/1111 [1:39:57<2:31:51, 13.60s/it]\n",
      "40%|███▉      | 442/1111 [1:40:11<2:31:38, 13.60s/it]\n",
      "40%|███▉      | 443/1111 [1:40:24<2:31:24, 13.60s/it]\n",
      "40%|███▉      | 444/1111 [1:40:38<2:31:10, 13.60s/it]\n",
      "40%|████      | 445/1111 [1:40:51<2:30:56, 13.60s/it]\n",
      "40%|████      | 446/1111 [1:41:05<2:30:43, 13.60s/it]\n",
      "40%|████      | 447/1111 [1:41:19<2:30:29, 13.60s/it]\n",
      "40%|████      | 448/1111 [1:41:32<2:30:16, 13.60s/it]\n",
      "40%|████      | 449/1111 [1:41:46<2:30:02, 13.60s/it]\n",
      "41%|████      | 450/1111 [1:41:59<2:29:49, 13.60s/it]\n",
      "{'loss': 0.3614, 'learning_rate': 5.94959495949595e-05, 'epoch': 0.41}\n",
      "41%|████      | 450/1111 [1:41:59<2:29:49, 13.60s/it]\n",
      "41%|████      | 451/1111 [1:42:13<2:29:36, 13.60s/it]\n",
      "41%|████      | 452/1111 [1:42:27<2:29:22, 13.60s/it]\n",
      "41%|████      | 453/1111 [1:42:40<2:29:08, 13.60s/it]\n",
      "41%|████      | 454/1111 [1:42:54<2:28:54, 13.60s/it]\n",
      "41%|████      | 455/1111 [1:43:07<2:28:41, 13.60s/it]\n",
      "41%|████      | 456/1111 [1:43:21<2:28:27, 13.60s/it]\n",
      "41%|████      | 457/1111 [1:43:35<2:28:13, 13.60s/it]\n",
      "41%|████      | 458/1111 [1:43:48<2:28:00, 13.60s/it]\n",
      "41%|████▏     | 459/1111 [1:44:02<2:27:46, 13.60s/it]\n",
      "41%|████▏     | 460/1111 [1:44:15<2:27:33, 13.60s/it]\n",
      "{'loss': 0.3657, 'learning_rate': 5.85958595859586e-05, 'epoch': 0.41}\n",
      "41%|████▏     | 460/1111 [1:44:15<2:27:33, 13.60s/it]\n",
      "41%|████▏     | 461/1111 [1:44:29<2:27:20, 13.60s/it]\n",
      "42%|████▏     | 462/1111 [1:44:43<2:27:06, 13.60s/it]\n",
      "42%|████▏     | 463/1111 [1:44:56<2:26:52, 13.60s/it]\n",
      "42%|████▏     | 464/1111 [1:45:10<2:26:39, 13.60s/it]\n",
      "42%|████▏     | 465/1111 [1:45:23<2:26:25, 13.60s/it]\n",
      "42%|████▏     | 466/1111 [1:45:37<2:26:11, 13.60s/it]\n",
      "42%|████▏     | 467/1111 [1:45:51<2:25:58, 13.60s/it]\n",
      "42%|████▏     | 468/1111 [1:46:04<2:25:44, 13.60s/it]\n",
      "42%|████▏     | 469/1111 [1:46:18<2:25:30, 13.60s/it]\n",
      "42%|████▏     | 470/1111 [1:46:31<2:25:17, 13.60s/it]\n",
      "{'loss': 0.3712, 'learning_rate': 5.7695769576957704e-05, 'epoch': 0.42}\n",
      "42%|████▏     | 470/1111 [1:46:31<2:25:17, 13.60s/it]\n",
      "42%|████▏     | 471/1111 [1:46:45<2:25:04, 13.60s/it]\n",
      "42%|████▏     | 472/1111 [1:46:59<2:24:50, 13.60s/it]\n",
      "43%|████▎     | 473/1111 [1:47:12<2:24:36, 13.60s/it]\n",
      "43%|████▎     | 474/1111 [1:47:26<2:24:22, 13.60s/it]\n",
      "43%|████▎     | 475/1111 [1:47:39<2:24:09, 13.60s/it]\n",
      "43%|████▎     | 476/1111 [1:47:53<2:23:55, 13.60s/it]\n",
      "43%|████▎     | 477/1111 [1:48:07<2:23:41, 13.60s/it]\n",
      "43%|████▎     | 478/1111 [1:48:20<2:23:28, 13.60s/it]\n",
      "43%|████▎     | 479/1111 [1:48:34<2:23:14, 13.60s/it]\n",
      "43%|████▎     | 480/1111 [1:48:47<2:23:01, 13.60s/it]\n",
      "{'loss': 0.3695, 'learning_rate': 5.679567956795679e-05, 'epoch': 0.43}\n",
      "43%|████▎     | 480/1111 [1:48:47<2:23:01, 13.60s/it]\n",
      "43%|████▎     | 481/1111 [1:49:01<2:22:47, 13.60s/it]\n",
      "43%|████▎     | 482/1111 [1:49:15<2:22:34, 13.60s/it]\n",
      "43%|████▎     | 483/1111 [1:49:28<2:22:20, 13.60s/it]\n",
      "44%|████▎     | 484/1111 [1:49:42<2:22:06, 13.60s/it]\n",
      "44%|████▎     | 485/1111 [1:49:55<2:21:53, 13.60s/it]\n",
      "44%|████▎     | 486/1111 [1:50:09<2:21:39, 13.60s/it]\n",
      "44%|████▍     | 487/1111 [1:50:23<2:21:26, 13.60s/it]\n",
      "44%|████▍     | 488/1111 [1:50:36<2:21:12, 13.60s/it]\n",
      "44%|████▍     | 489/1111 [1:50:50<2:20:58, 13.60s/it]\n",
      "44%|████▍     | 490/1111 [1:51:03<2:20:45, 13.60s/it]\n",
      "{'loss': 0.3621, 'learning_rate': 5.5895589558955894e-05, 'epoch': 0.44}\n",
      "44%|████▍     | 490/1111 [1:51:03<2:20:45, 13.60s/it]\n",
      "44%|████▍     | 491/1111 [1:51:17<2:20:31, 13.60s/it]\n",
      "44%|████▍     | 492/1111 [1:51:31<2:20:18, 13.60s/it]\n",
      "44%|████▍     | 493/1111 [1:51:44<2:20:04, 13.60s/it]\n",
      "44%|████▍     | 494/1111 [1:51:58<2:19:50, 13.60s/it]\n",
      "45%|████▍     | 495/1111 [1:52:11<2:19:37, 13.60s/it]\n",
      "45%|████▍     | 496/1111 [1:52:25<2:19:23, 13.60s/it]\n",
      "45%|████▍     | 497/1111 [1:52:39<2:19:09, 13.60s/it]\n",
      "45%|████▍     | 498/1111 [1:52:52<2:18:56, 13.60s/it]\n",
      "45%|████▍     | 499/1111 [1:53:06<2:18:42, 13.60s/it]\n",
      "45%|████▌     | 500/1111 [1:53:19<2:18:29, 13.60s/it]\n",
      "{'loss': 0.3718, 'learning_rate': 5.4995499549954995e-05, 'epoch': 0.45}\n",
      "45%|████▌     | 500/1111 [1:53:19<2:18:29, 13.60s/it]\n",
      "45%|████▌     | 501/1111 [1:53:33<2:18:15, 13.60s/it]\n",
      "45%|████▌     | 502/1111 [1:53:47<2:18:02, 13.60s/it]\n",
      "45%|████▌     | 503/1111 [1:54:00<2:17:48, 13.60s/it]\n",
      "45%|████▌     | 504/1111 [1:54:14<2:17:34, 13.60s/it]\n",
      "45%|████▌     | 505/1111 [1:54:27<2:17:21, 13.60s/it]\n",
      "46%|████▌     | 506/1111 [1:54:41<2:17:07, 13.60s/it]\n",
      "46%|████▌     | 507/1111 [1:54:55<2:16:54, 13.60s/it]\n",
      "46%|████▌     | 508/1111 [1:55:08<2:16:40, 13.60s/it]\n",
      "46%|████▌     | 509/1111 [1:55:22<2:16:26, 13.60s/it]\n",
      "46%|████▌     | 510/1111 [1:55:35<2:16:13, 13.60s/it]\n",
      "{'loss': 0.3687, 'learning_rate': 5.4095409540954104e-05, 'epoch': 0.46}\n",
      "46%|████▌     | 510/1111 [1:55:35<2:16:13, 13.60s/it]\n",
      "46%|████▌     | 511/1111 [1:55:49<2:15:59, 13.60s/it]\n",
      "46%|████▌     | 512/1111 [1:56:03<2:15:46, 13.60s/it]\n",
      "46%|████▌     | 513/1111 [1:56:16<2:15:33, 13.60s/it]\n",
      "46%|████▋     | 514/1111 [1:56:30<2:15:19, 13.60s/it]\n",
      "46%|████▋     | 515/1111 [1:56:43<2:15:05, 13.60s/it]\n",
      "46%|████▋     | 516/1111 [1:56:57<2:14:52, 13.60s/it]\n",
      "47%|████▋     | 517/1111 [1:57:11<2:14:38, 13.60s/it]\n",
      "47%|████▋     | 518/1111 [1:57:24<2:14:24, 13.60s/it]\n",
      "47%|████▋     | 519/1111 [1:57:38<2:14:10, 13.60s/it]\n",
      "47%|████▋     | 520/1111 [1:57:51<2:13:57, 13.60s/it]\n",
      "{'loss': 0.3623, 'learning_rate': 5.3195319531953205e-05, 'epoch': 0.47}\n",
      "47%|████▋     | 520/1111 [1:57:51<2:13:57, 13.60s/it]\n",
      "47%|████▋     | 521/1111 [1:58:05<2:13:44, 13.60s/it]\n",
      "47%|████▋     | 522/1111 [1:58:19<2:13:30, 13.60s/it]\n",
      "47%|████▋     | 523/1111 [1:58:32<2:13:16, 13.60s/it]\n",
      "47%|████▋     | 524/1111 [1:58:46<2:13:03, 13.60s/it]\n",
      "47%|████▋     | 525/1111 [1:58:59<2:12:49, 13.60s/it]\n",
      "47%|████▋     | 526/1111 [1:59:13<2:12:36, 13.60s/it]\n",
      "47%|████▋     | 527/1111 [1:59:27<2:12:22, 13.60s/it]\n",
      "48%|████▊     | 528/1111 [1:59:40<2:12:08, 13.60s/it]\n",
      "48%|████▊     | 529/1111 [1:59:54<2:11:55, 13.60s/it]\n",
      "48%|████▊     | 530/1111 [2:00:07<2:11:41, 13.60s/it]\n",
      "{'loss': 0.3661, 'learning_rate': 5.229522952295229e-05, 'epoch': 0.48}\n",
      "48%|████▊     | 530/1111 [2:00:07<2:11:41, 13.60s/it]\n",
      "48%|████▊     | 531/1111 [2:00:21<2:11:28, 13.60s/it]\n",
      "48%|████▊     | 532/1111 [2:00:35<2:11:14, 13.60s/it]\n",
      "48%|████▊     | 533/1111 [2:00:48<2:11:00, 13.60s/it]\n",
      "48%|████▊     | 534/1111 [2:01:02<2:10:47, 13.60s/it]\n",
      "48%|████▊     | 535/1111 [2:01:15<2:10:33, 13.60s/it]\n",
      "48%|████▊     | 536/1111 [2:01:29<2:10:19, 13.60s/it]\n",
      "48%|████▊     | 537/1111 [2:01:43<2:10:05, 13.60s/it]\n",
      "48%|████▊     | 538/1111 [2:01:56<2:09:52, 13.60s/it]\n",
      "49%|████▊     | 539/1111 [2:02:10<2:09:39, 13.60s/it]\n",
      "49%|████▊     | 540/1111 [2:02:23<2:09:25, 13.60s/it]\n",
      "{'loss': 0.3577, 'learning_rate': 5.1395139513951395e-05, 'epoch': 0.49}\n",
      "49%|████▊     | 540/1111 [2:02:23<2:09:25, 13.60s/it]\n",
      "49%|████▊     | 541/1111 [2:02:37<2:09:11, 13.60s/it]\n",
      "49%|████▉     | 542/1111 [2:02:51<2:08:58, 13.60s/it]\n",
      "49%|████▉     | 543/1111 [2:03:04<2:08:44, 13.60s/it]\n",
      "49%|████▉     | 544/1111 [2:03:18<2:08:31, 13.60s/it]\n",
      "49%|████▉     | 545/1111 [2:03:31<2:08:17, 13.60s/it]\n",
      "49%|████▉     | 546/1111 [2:03:45<2:08:04, 13.60s/it]\n",
      "49%|████▉     | 547/1111 [2:03:59<2:07:50, 13.60s/it]\n",
      "49%|████▉     | 548/1111 [2:04:12<2:07:36, 13.60s/it]\n",
      "49%|████▉     | 549/1111 [2:04:26<2:07:22, 13.60s/it]\n",
      "50%|████▉     | 550/1111 [2:04:39<2:07:09, 13.60s/it]\n",
      "{'loss': 0.3681, 'learning_rate': 5.0495049504950497e-05, 'epoch': 0.5}\n",
      "50%|████▉     | 550/1111 [2:04:39<2:07:09, 13.60s/it]\n",
      "50%|████▉     | 551/1111 [2:04:53<2:06:55, 13.60s/it]\n",
      "50%|████▉     | 552/1111 [2:05:07<2:06:42, 13.60s/it]\n",
      "50%|████▉     | 553/1111 [2:05:20<2:06:28, 13.60s/it]\n",
      "50%|████▉     | 554/1111 [2:05:34<2:06:14, 13.60s/it]\n",
      "50%|████▉     | 555/1111 [2:05:47<2:06:01, 13.60s/it]\n",
      "50%|█████     | 556/1111 [2:06:01<2:05:47, 13.60s/it]\n",
      "50%|█████     | 557/1111 [2:06:15<2:05:33, 13.60s/it]\n",
      "50%|█████     | 558/1111 [2:06:28<2:05:20, 13.60s/it]\n",
      "50%|█████     | 559/1111 [2:06:42<2:05:06, 13.60s/it]\n",
      "50%|█████     | 560/1111 [2:06:55<2:04:53, 13.60s/it]\n",
      "{'loss': 0.3572, 'learning_rate': 4.95949594959496e-05, 'epoch': 0.5}\n",
      "50%|█████     | 560/1111 [2:06:55<2:04:53, 13.60s/it]\n",
      "50%|█████     | 561/1111 [2:07:09<2:04:39, 13.60s/it]\n",
      "51%|█████     | 562/1111 [2:07:23<2:04:26, 13.60s/it]\n",
      "51%|█████     | 563/1111 [2:07:36<2:04:12, 13.60s/it]\n",
      "51%|█████     | 564/1111 [2:07:50<2:03:59, 13.60s/it]\n",
      "51%|█████     | 565/1111 [2:08:03<2:03:45, 13.60s/it]\n",
      "51%|█████     | 566/1111 [2:08:17<2:03:31, 13.60s/it]\n",
      "51%|█████     | 567/1111 [2:08:31<2:03:18, 13.60s/it]\n",
      "51%|█████     | 568/1111 [2:08:44<2:03:05, 13.60s/it]\n",
      "51%|█████     | 569/1111 [2:08:58<2:02:51, 13.60s/it]\n",
      "51%|█████▏    | 570/1111 [2:09:11<2:02:37, 13.60s/it]\n",
      "{'loss': 0.3635, 'learning_rate': 4.86948694869487e-05, 'epoch': 0.51}\n",
      "51%|█████▏    | 570/1111 [2:09:11<2:02:37, 13.60s/it]\n",
      "51%|█████▏    | 571/1111 [2:09:25<2:02:24, 13.60s/it]\n",
      "51%|█████▏    | 572/1111 [2:09:39<2:02:10, 13.60s/it]\n",
      "52%|█████▏    | 573/1111 [2:09:52<2:01:57, 13.60s/it]\n",
      "52%|█████▏    | 574/1111 [2:10:06<2:01:43, 13.60s/it]\n",
      "52%|█████▏    | 575/1111 [2:10:19<2:01:29, 13.60s/it]\n",
      "52%|█████▏    | 576/1111 [2:10:33<2:01:15, 13.60s/it]\n",
      "52%|█████▏    | 577/1111 [2:10:47<2:01:02, 13.60s/it]\n",
      "52%|█████▏    | 578/1111 [2:11:00<2:00:48, 13.60s/it]\n",
      "52%|█████▏    | 579/1111 [2:11:14<2:00:34, 13.60s/it]\n",
      "52%|█████▏    | 580/1111 [2:11:27<2:00:20, 13.60s/it]\n",
      "{'loss': 0.3687, 'learning_rate': 4.77947794779478e-05, 'epoch': 0.52}\n",
      "52%|█████▏    | 580/1111 [2:11:27<2:00:20, 13.60s/it]\n",
      "52%|█████▏    | 581/1111 [2:11:41<2:00:07, 13.60s/it]\n",
      "52%|█████▏    | 582/1111 [2:11:55<1:59:54, 13.60s/it]\n",
      "52%|█████▏    | 583/1111 [2:12:08<1:59:40, 13.60s/it]\n",
      "53%|█████▎    | 584/1111 [2:12:22<1:59:26, 13.60s/it]\n",
      "53%|█████▎    | 585/1111 [2:12:35<1:59:13, 13.60s/it]\n",
      "53%|█████▎    | 586/1111 [2:12:49<1:58:59, 13.60s/it]\n",
      "53%|█████▎    | 587/1111 [2:13:03<1:58:45, 13.60s/it]\n",
      "53%|█████▎    | 588/1111 [2:13:16<1:58:32, 13.60s/it]\n",
      "53%|█████▎    | 589/1111 [2:13:30<1:58:18, 13.60s/it]\n",
      "53%|█████▎    | 590/1111 [2:13:43<1:58:05, 13.60s/it]\n",
      "{'loss': 0.362, 'learning_rate': 4.6894689468946896e-05, 'epoch': 0.53}\n",
      "53%|█████▎    | 590/1111 [2:13:43<1:58:05, 13.60s/it]\n",
      "53%|█████▎    | 591/1111 [2:13:57<1:57:51, 13.60s/it]\n",
      "53%|█████▎    | 592/1111 [2:14:11<1:57:38, 13.60s/it]\n",
      "53%|█████▎    | 593/1111 [2:14:24<1:57:24, 13.60s/it]\n",
      "53%|█████▎    | 594/1111 [2:14:38<1:57:10, 13.60s/it]\n",
      "54%|█████▎    | 595/1111 [2:14:51<1:56:57, 13.60s/it]\n",
      "54%|█████▎    | 596/1111 [2:15:05<1:56:43, 13.60s/it]\n",
      "54%|█████▎    | 597/1111 [2:15:19<1:56:30, 13.60s/it]\n",
      "54%|█████▍    | 598/1111 [2:15:32<1:56:16, 13.60s/it]\n",
      "54%|█████▍    | 599/1111 [2:15:46<1:56:03, 13.60s/it]\n",
      "54%|█████▍    | 600/1111 [2:15:59<1:55:49, 13.60s/it]\n",
      "{'loss': 0.3681, 'learning_rate': 4.5994599459946e-05, 'epoch': 0.54}\n",
      "54%|█████▍    | 600/1111 [2:15:59<1:55:49, 13.60s/it]\n",
      "54%|█████▍    | 601/1111 [2:16:13<1:55:36, 13.60s/it]\n",
      "54%|█████▍    | 602/1111 [2:16:27<1:55:22, 13.60s/it]\n",
      "54%|█████▍    | 603/1111 [2:16:40<1:55:08, 13.60s/it]\n",
      "54%|█████▍    | 604/1111 [2:16:54<1:54:54, 13.60s/it]\n",
      "54%|█████▍    | 605/1111 [2:17:07<1:54:41, 13.60s/it]\n",
      "55%|█████▍    | 606/1111 [2:17:21<1:54:27, 13.60s/it]\n",
      "55%|█████▍    | 607/1111 [2:17:35<1:54:14, 13.60s/it]\n",
      "55%|█████▍    | 608/1111 [2:17:48<1:54:00, 13.60s/it]\n",
      "55%|█████▍    | 609/1111 [2:18:02<1:53:46, 13.60s/it]\n",
      "55%|█████▍    | 610/1111 [2:18:15<1:53:33, 13.60s/it]\n",
      "{'loss': 0.345, 'learning_rate': 4.50945094509451e-05, 'epoch': 0.55}\n",
      "55%|█████▍    | 610/1111 [2:18:15<1:53:33, 13.60s/it]\n",
      "55%|█████▍    | 611/1111 [2:18:29<1:53:19, 13.60s/it]\n",
      "55%|█████▌    | 612/1111 [2:18:43<1:53:06, 13.60s/it]\n",
      "55%|█████▌    | 613/1111 [2:18:56<1:52:52, 13.60s/it]\n",
      "55%|█████▌    | 614/1111 [2:19:10<1:52:39, 13.60s/it]\n",
      "55%|█████▌    | 615/1111 [2:19:23<1:52:25, 13.60s/it]\n",
      "55%|█████▌    | 616/1111 [2:19:37<1:52:11, 13.60s/it]\n",
      "56%|█████▌    | 617/1111 [2:19:51<1:51:58, 13.60s/it]\n",
      "56%|█████▌    | 618/1111 [2:20:04<1:51:44, 13.60s/it]\n",
      "56%|█████▌    | 619/1111 [2:20:18<1:51:30, 13.60s/it]\n",
      "56%|█████▌    | 620/1111 [2:20:31<1:51:17, 13.60s/it]\n",
      "{'loss': 0.3651, 'learning_rate': 4.4194419441944194e-05, 'epoch': 0.56}\n",
      "56%|█████▌    | 620/1111 [2:20:31<1:51:17, 13.60s/it]\n",
      "56%|█████▌    | 621/1111 [2:20:45<1:51:04, 13.60s/it]\n",
      "56%|█████▌    | 622/1111 [2:20:59<1:50:50, 13.60s/it]\n",
      "56%|█████▌    | 623/1111 [2:21:12<1:50:36, 13.60s/it]\n",
      "56%|█████▌    | 624/1111 [2:21:26<1:50:23, 13.60s/it]\n",
      "56%|█████▋    | 625/1111 [2:21:39<1:50:09, 13.60s/it]\n",
      "56%|█████▋    | 626/1111 [2:21:53<1:49:55, 13.60s/it]\n",
      "56%|█████▋    | 627/1111 [2:22:07<1:49:42, 13.60s/it]\n",
      "57%|█████▋    | 628/1111 [2:22:20<1:49:28, 13.60s/it]\n",
      "57%|█████▋    | 629/1111 [2:22:34<1:49:15, 13.60s/it]\n",
      "57%|█████▋    | 630/1111 [2:22:47<1:49:01, 13.60s/it]\n",
      "{'loss': 0.3551, 'learning_rate': 4.3294329432943296e-05, 'epoch': 0.57}\n",
      "57%|█████▋    | 630/1111 [2:22:47<1:49:01, 13.60s/it]\n",
      "57%|█████▋    | 631/1111 [2:23:01<1:48:47, 13.60s/it]\n",
      "57%|█████▋    | 632/1111 [2:23:15<1:48:34, 13.60s/it]\n",
      "57%|█████▋    | 633/1111 [2:23:28<1:48:20, 13.60s/it]\n",
      "57%|█████▋    | 634/1111 [2:23:42<1:48:07, 13.60s/it]\n",
      "57%|█████▋    | 635/1111 [2:23:55<1:47:53, 13.60s/it]\n",
      "57%|█████▋    | 636/1111 [2:24:09<1:47:39, 13.60s/it]\n",
      "57%|█████▋    | 637/1111 [2:24:23<1:47:26, 13.60s/it]\n",
      "57%|█████▋    | 638/1111 [2:24:36<1:47:12, 13.60s/it]\n",
      "58%|█████▊    | 639/1111 [2:24:50<1:46:59, 13.60s/it]\n",
      "58%|█████▊    | 640/1111 [2:25:03<1:46:45, 13.60s/it]\n",
      "{'loss': 0.3567, 'learning_rate': 4.23942394239424e-05, 'epoch': 0.58}\n",
      "58%|█████▊    | 640/1111 [2:25:03<1:46:45, 13.60s/it]\n",
      "58%|█████▊    | 641/1111 [2:25:17<1:46:31, 13.60s/it]\n",
      "58%|█████▊    | 642/1111 [2:25:31<1:46:18, 13.60s/it]\n",
      "58%|█████▊    | 643/1111 [2:25:44<1:46:04, 13.60s/it]\n",
      "58%|█████▊    | 644/1111 [2:25:58<1:45:51, 13.60s/it]\n",
      "58%|█████▊    | 645/1111 [2:26:11<1:45:37, 13.60s/it]\n",
      "58%|█████▊    | 646/1111 [2:26:25<1:45:24, 13.60s/it]\n",
      "58%|█████▊    | 647/1111 [2:26:39<1:45:10, 13.60s/it]\n",
      "58%|█████▊    | 648/1111 [2:26:52<1:44:56, 13.60s/it]\n",
      "58%|█████▊    | 649/1111 [2:27:06<1:44:43, 13.60s/it]\n",
      "59%|█████▊    | 650/1111 [2:27:19<1:44:29, 13.60s/it]\n",
      "{'loss': 0.3488, 'learning_rate': 4.14941494149415e-05, 'epoch': 0.59}\n",
      "59%|█████▊    | 650/1111 [2:27:19<1:44:29, 13.60s/it]\n",
      "59%|█████▊    | 651/1111 [2:27:33<1:44:16, 13.60s/it]\n",
      "59%|█████▊    | 652/1111 [2:27:47<1:44:02, 13.60s/it]\n",
      "59%|█████▉    | 653/1111 [2:28:00<1:43:48, 13.60s/it]\n",
      "59%|█████▉    | 654/1111 [2:28:14<1:43:35, 13.60s/it]\n",
      "59%|█████▉    | 655/1111 [2:28:27<1:43:21, 13.60s/it]\n",
      "59%|█████▉    | 656/1111 [2:28:41<1:43:07, 13.60s/it]\n",
      "59%|█████▉    | 657/1111 [2:28:55<1:42:54, 13.60s/it]\n",
      "59%|█████▉    | 658/1111 [2:29:08<1:42:40, 13.60s/it]\n",
      "59%|█████▉    | 659/1111 [2:29:22<1:42:27, 13.60s/it]\n",
      "59%|█████▉    | 660/1111 [2:29:35<1:42:13, 13.60s/it]\n",
      "{'loss': 0.37, 'learning_rate': 4.05940594059406e-05, 'epoch': 0.59}\n",
      "59%|█████▉    | 660/1111 [2:29:35<1:42:13, 13.60s/it]\n",
      "59%|█████▉    | 661/1111 [2:29:49<1:41:59, 13.60s/it]\n",
      "60%|█████▉    | 662/1111 [2:30:03<1:41:46, 13.60s/it]\n",
      "60%|█████▉    | 663/1111 [2:30:16<1:41:32, 13.60s/it]\n",
      "60%|█████▉    | 664/1111 [2:30:30<1:41:19, 13.60s/it]\n",
      "60%|█████▉    | 665/1111 [2:30:43<1:41:05, 13.60s/it]\n",
      "60%|█████▉    | 666/1111 [2:30:57<1:40:51, 13.60s/it]\n",
      "60%|██████    | 667/1111 [2:31:11<1:40:38, 13.60s/it]\n",
      "60%|██████    | 668/1111 [2:31:24<1:40:24, 13.60s/it]\n",
      "60%|██████    | 669/1111 [2:31:38<1:40:10, 13.60s/it]\n",
      "60%|██████    | 670/1111 [2:31:51<1:39:57, 13.60s/it]\n",
      "{'loss': 0.3553, 'learning_rate': 3.9693969396939695e-05, 'epoch': 0.6}\n",
      "60%|██████    | 670/1111 [2:31:51<1:39:57, 13.60s/it]\n",
      "60%|██████    | 671/1111 [2:32:05<1:39:43, 13.60s/it]\n",
      "60%|██████    | 672/1111 [2:32:19<1:39:30, 13.60s/it]\n",
      "61%|██████    | 673/1111 [2:32:32<1:39:16, 13.60s/it]\n",
      "61%|██████    | 674/1111 [2:32:46<1:39:02, 13.60s/it]\n",
      "61%|██████    | 675/1111 [2:32:59<1:38:49, 13.60s/it]\n",
      "61%|██████    | 676/1111 [2:33:13<1:38:35, 13.60s/it]\n",
      "61%|██████    | 677/1111 [2:33:27<1:38:22, 13.60s/it]\n",
      "61%|██████    | 678/1111 [2:33:40<1:38:08, 13.60s/it]\n",
      "61%|██████    | 679/1111 [2:33:54<1:37:54, 13.60s/it]\n",
      "61%|██████    | 680/1111 [2:34:07<1:37:41, 13.60s/it]\n",
      "{'loss': 0.3643, 'learning_rate': 3.87938793879388e-05, 'epoch': 0.61}\n",
      "61%|██████    | 680/1111 [2:34:07<1:37:41, 13.60s/it]\n",
      "61%|██████▏   | 681/1111 [2:34:21<1:37:28, 13.60s/it]\n",
      "61%|██████▏   | 682/1111 [2:34:35<1:37:14, 13.60s/it]\n",
      "61%|██████▏   | 683/1111 [2:34:48<1:37:00, 13.60s/it]\n",
      "62%|██████▏   | 684/1111 [2:35:02<1:36:47, 13.60s/it]\n",
      "62%|██████▏   | 685/1111 [2:35:15<1:36:33, 13.60s/it]\n",
      "62%|██████▏   | 686/1111 [2:35:29<1:36:20, 13.60s/it]\n",
      "62%|██████▏   | 687/1111 [2:35:43<1:36:06, 13.60s/it]\n",
      "62%|██████▏   | 688/1111 [2:35:56<1:35:52, 13.60s/it]\n",
      "62%|██████▏   | 689/1111 [2:36:10<1:35:39, 13.60s/it]\n",
      "62%|██████▏   | 690/1111 [2:36:23<1:35:25, 13.60s/it]\n",
      "{'loss': 0.3606, 'learning_rate': 3.789378937893789e-05, 'epoch': 0.62}\n",
      "62%|██████▏   | 690/1111 [2:36:23<1:35:25, 13.60s/it]\n",
      "62%|██████▏   | 691/1111 [2:36:37<1:35:11, 13.60s/it]\n",
      "62%|██████▏   | 692/1111 [2:36:51<1:34:58, 13.60s/it]\n",
      "62%|██████▏   | 693/1111 [2:37:04<1:34:44, 13.60s/it]\n",
      "62%|██████▏   | 694/1111 [2:37:18<1:34:30, 13.60s/it]\n",
      "63%|██████▎   | 695/1111 [2:37:31<1:34:17, 13.60s/it]\n",
      "63%|██████▎   | 696/1111 [2:37:45<1:34:04, 13.60s/it]\n",
      "63%|██████▎   | 697/1111 [2:37:59<1:33:50, 13.60s/it]\n",
      "63%|██████▎   | 698/1111 [2:38:12<1:33:36, 13.60s/it]\n",
      "63%|██████▎   | 699/1111 [2:38:26<1:33:23, 13.60s/it]\n",
      "63%|██████▎   | 700/1111 [2:38:39<1:33:09, 13.60s/it]\n",
      "{'loss': 0.3677, 'learning_rate': 3.699369936993699e-05, 'epoch': 0.63}\n",
      "63%|██████▎   | 700/1111 [2:38:39<1:33:09, 13.60s/it]\n",
      "63%|██████▎   | 701/1111 [2:38:53<1:32:56, 13.60s/it]\n",
      "63%|██████▎   | 702/1111 [2:39:07<1:32:42, 13.60s/it]\n",
      "63%|██████▎   | 703/1111 [2:39:20<1:32:28, 13.60s/it]\n",
      "63%|██████▎   | 704/1111 [2:39:34<1:32:15, 13.60s/it]\n",
      "63%|██████▎   | 705/1111 [2:39:47<1:32:01, 13.60s/it]\n",
      "64%|██████▎   | 706/1111 [2:40:01<1:31:47, 13.60s/it]\n",
      "64%|██████▎   | 707/1111 [2:40:15<1:31:34, 13.60s/it]\n",
      "64%|██████▎   | 708/1111 [2:40:28<1:31:20, 13.60s/it]\n",
      "64%|██████▍   | 709/1111 [2:40:42<1:31:07, 13.60s/it]\n",
      "64%|██████▍   | 710/1111 [2:40:55<1:30:53, 13.60s/it]\n",
      "{'loss': 0.3568, 'learning_rate': 3.6093609360936095e-05, 'epoch': 0.64}\n",
      "64%|██████▍   | 710/1111 [2:40:55<1:30:53, 13.60s/it]\n",
      "64%|██████▍   | 711/1111 [2:41:09<1:30:39, 13.60s/it]\n",
      "64%|██████▍   | 712/1111 [2:41:23<1:30:26, 13.60s/it]\n",
      "64%|██████▍   | 713/1111 [2:41:36<1:30:12, 13.60s/it]\n",
      "64%|██████▍   | 714/1111 [2:41:50<1:29:59, 13.60s/it]\n",
      "64%|██████▍   | 715/1111 [2:42:03<1:29:45, 13.60s/it]\n",
      "64%|██████▍   | 716/1111 [2:42:17<1:29:31, 13.60s/it]\n",
      "65%|██████▍   | 717/1111 [2:42:31<1:29:18, 13.60s/it]\n",
      "65%|██████▍   | 718/1111 [2:42:44<1:29:04, 13.60s/it]\n",
      "65%|██████▍   | 719/1111 [2:42:58<1:28:51, 13.60s/it]\n",
      "65%|██████▍   | 720/1111 [2:43:11<1:28:37, 13.60s/it]\n",
      "{'loss': 0.3511, 'learning_rate': 3.5193519351935196e-05, 'epoch': 0.65}\n",
      "65%|██████▍   | 720/1111 [2:43:11<1:28:37, 13.60s/it]\n",
      "65%|██████▍   | 721/1111 [2:43:25<1:28:23, 13.60s/it]\n",
      "65%|██████▍   | 722/1111 [2:43:39<1:28:10, 13.60s/it]\n",
      "65%|██████▌   | 723/1111 [2:43:52<1:27:56, 13.60s/it]\n",
      "65%|██████▌   | 724/1111 [2:44:06<1:27:43, 13.60s/it]\n",
      "65%|██████▌   | 725/1111 [2:44:19<1:27:29, 13.60s/it]\n",
      "65%|██████▌   | 726/1111 [2:44:33<1:27:16, 13.60s/it]\n",
      "65%|██████▌   | 727/1111 [2:44:47<1:27:02, 13.60s/it]\n",
      "66%|██████▌   | 728/1111 [2:45:00<1:26:48, 13.60s/it]\n",
      "66%|██████▌   | 729/1111 [2:45:14<1:26:35, 13.60s/it]\n",
      "66%|██████▌   | 730/1111 [2:45:27<1:26:21, 13.60s/it]\n",
      "{'loss': 0.346, 'learning_rate': 3.42934293429343e-05, 'epoch': 0.66}\n",
      "66%|██████▌   | 730/1111 [2:45:27<1:26:21, 13.60s/it]\n",
      "66%|██████▌   | 731/1111 [2:45:41<1:26:08, 13.60s/it]\n",
      "66%|██████▌   | 732/1111 [2:45:55<1:25:54, 13.60s/it]\n",
      "66%|██████▌   | 733/1111 [2:46:08<1:25:40, 13.60s/it]\n",
      "66%|██████▌   | 734/1111 [2:46:22<1:25:27, 13.60s/it]\n",
      "66%|██████▌   | 735/1111 [2:46:35<1:25:14, 13.60s/it]\n",
      "66%|██████▌   | 736/1111 [2:46:49<1:25:00, 13.60s/it]\n",
      "66%|██████▋   | 737/1111 [2:47:03<1:24:46, 13.60s/it]\n",
      "66%|██████▋   | 738/1111 [2:47:16<1:24:32, 13.60s/it]\n",
      "67%|██████▋   | 739/1111 [2:47:30<1:24:18, 13.60s/it]\n",
      "67%|██████▋   | 740/1111 [2:47:43<1:24:05, 13.60s/it]\n",
      "{'loss': 0.3659, 'learning_rate': 3.339333933393339e-05, 'epoch': 0.67}\n",
      "67%|██████▋   | 740/1111 [2:47:43<1:24:05, 13.60s/it]\n",
      "67%|██████▋   | 741/1111 [2:47:57<1:23:52, 13.60s/it]\n",
      "67%|██████▋   | 742/1111 [2:48:11<1:23:38, 13.60s/it]\n",
      "67%|██████▋   | 743/1111 [2:48:24<1:23:24, 13.60s/it]\n",
      "67%|██████▋   | 744/1111 [2:48:38<1:23:11, 13.60s/it]\n",
      "67%|██████▋   | 745/1111 [2:48:51<1:22:57, 13.60s/it]\n",
      "67%|██████▋   | 746/1111 [2:49:05<1:22:43, 13.60s/it]\n",
      "67%|██████▋   | 747/1111 [2:49:19<1:22:30, 13.60s/it]\n",
      "67%|██████▋   | 748/1111 [2:49:32<1:22:16, 13.60s/it]\n",
      "67%|██████▋   | 749/1111 [2:49:46<1:22:03, 13.60s/it]\n",
      "68%|██████▊   | 750/1111 [2:49:59<1:21:49, 13.60s/it]\n",
      "{'loss': 0.3616, 'learning_rate': 3.2493249324932494e-05, 'epoch': 0.68}\n",
      "68%|██████▊   | 750/1111 [2:49:59<1:21:49, 13.60s/it]\n",
      "68%|██████▊   | 751/1111 [2:50:13<1:21:36, 13.60s/it]\n",
      "68%|██████▊   | 752/1111 [2:50:27<1:21:22, 13.60s/it]\n",
      "68%|██████▊   | 753/1111 [2:50:40<1:21:08, 13.60s/it]\n",
      "68%|██████▊   | 754/1111 [2:50:54<1:20:55, 13.60s/it]\n",
      "68%|██████▊   | 755/1111 [2:51:07<1:20:41, 13.60s/it]\n",
      "68%|██████▊   | 756/1111 [2:51:21<1:20:27, 13.60s/it]\n",
      "68%|██████▊   | 757/1111 [2:51:35<1:20:14, 13.60s/it]\n",
      "68%|██████▊   | 758/1111 [2:51:48<1:20:00, 13.60s/it]\n",
      "68%|██████▊   | 759/1111 [2:52:02<1:19:47, 13.60s/it]\n",
      "68%|██████▊   | 760/1111 [2:52:15<1:19:33, 13.60s/it]\n",
      "{'loss': 0.3453, 'learning_rate': 3.159315931593159e-05, 'epoch': 0.68}\n",
      "68%|██████▊   | 760/1111 [2:52:15<1:19:33, 13.60s/it]\n",
      "68%|██████▊   | 761/1111 [2:52:29<1:19:20, 13.60s/it]\n",
      "69%|██████▊   | 762/1111 [2:52:43<1:19:06, 13.60s/it]\n",
      "69%|██████▊   | 763/1111 [2:52:56<1:18:52, 13.60s/it]\n",
      "69%|██████▉   | 764/1111 [2:53:10<1:18:39, 13.60s/it]\n",
      "69%|██████▉   | 765/1111 [2:53:23<1:18:25, 13.60s/it]\n",
      "69%|██████▉   | 766/1111 [2:53:37<1:18:12, 13.60s/it]\n",
      "69%|██████▉   | 767/1111 [2:53:51<1:17:58, 13.60s/it]\n",
      "69%|██████▉   | 768/1111 [2:54:04<1:17:44, 13.60s/it]\n",
      "69%|██████▉   | 769/1111 [2:54:18<1:17:31, 13.60s/it]\n",
      "69%|██████▉   | 770/1111 [2:54:31<1:17:17, 13.60s/it]\n",
      "{'loss': 0.3717, 'learning_rate': 3.06930693069307e-05, 'epoch': 0.69}\n",
      "69%|██████▉   | 770/1111 [2:54:31<1:17:17, 13.60s/it]\n",
      "69%|██████▉   | 771/1111 [2:54:45<1:17:04, 13.60s/it]\n",
      "69%|██████▉   | 772/1111 [2:54:59<1:16:50, 13.60s/it]\n",
      "70%|██████▉   | 773/1111 [2:55:12<1:16:36, 13.60s/it]\n",
      "70%|██████▉   | 774/1111 [2:55:26<1:16:23, 13.60s/it]\n",
      "70%|██████▉   | 775/1111 [2:55:39<1:16:09, 13.60s/it]\n",
      "70%|██████▉   | 776/1111 [2:55:53<1:15:55, 13.60s/it]\n",
      "70%|██████▉   | 777/1111 [2:56:07<1:15:42, 13.60s/it]\n",
      "70%|███████   | 778/1111 [2:56:20<1:15:28, 13.60s/it]\n",
      "70%|███████   | 779/1111 [2:56:34<1:15:15, 13.60s/it]\n",
      "70%|███████   | 780/1111 [2:56:47<1:15:01, 13.60s/it]\n",
      "{'loss': 0.3625, 'learning_rate': 2.9792979297929795e-05, 'epoch': 0.7}\n",
      "70%|███████   | 780/1111 [2:56:47<1:15:01, 13.60s/it]\n",
      "70%|███████   | 781/1111 [2:57:01<1:14:48, 13.60s/it]\n",
      "70%|███████   | 782/1111 [2:57:15<1:14:34, 13.60s/it]\n",
      "70%|███████   | 783/1111 [2:57:28<1:14:20, 13.60s/it]\n",
      "71%|███████   | 784/1111 [2:57:42<1:14:07, 13.60s/it]\n",
      "71%|███████   | 785/1111 [2:57:55<1:13:53, 13.60s/it]\n",
      "71%|███████   | 786/1111 [2:58:09<1:13:39, 13.60s/it]\n",
      "71%|███████   | 787/1111 [2:58:23<1:13:26, 13.60s/it]\n",
      "71%|███████   | 788/1111 [2:58:36<1:13:12, 13.60s/it]\n",
      "71%|███████   | 789/1111 [2:58:50<1:12:59, 13.60s/it]\n",
      "71%|███████   | 790/1111 [2:59:03<1:12:45, 13.60s/it]\n",
      "{'loss': 0.3625, 'learning_rate': 2.8892889288928894e-05, 'epoch': 0.71}\n",
      "71%|███████   | 790/1111 [2:59:03<1:12:45, 13.60s/it]\n",
      "71%|███████   | 791/1111 [2:59:17<1:12:32, 13.60s/it]\n",
      "71%|███████▏  | 792/1111 [2:59:31<1:12:18, 13.60s/it]\n",
      "71%|███████▏  | 793/1111 [2:59:44<1:12:04, 13.60s/it]\n",
      "71%|███████▏  | 794/1111 [2:59:58<1:11:51, 13.60s/it]\n",
      "72%|███████▏  | 795/1111 [3:00:11<1:11:37, 13.60s/it]\n",
      "72%|███████▏  | 796/1111 [3:00:25<1:11:23, 13.60s/it]\n",
      "72%|███████▏  | 797/1111 [3:00:39<1:11:10, 13.60s/it]\n",
      "72%|███████▏  | 798/1111 [3:00:52<1:10:56, 13.60s/it]\n",
      "72%|███████▏  | 799/1111 [3:01:06<1:10:43, 13.60s/it]\n",
      "72%|███████▏  | 800/1111 [3:01:19<1:10:29, 13.60s/it]\n",
      "{'loss': 0.3653, 'learning_rate': 2.7992799279927995e-05, 'epoch': 0.72}\n",
      "72%|███████▏  | 800/1111 [3:01:19<1:10:29, 13.60s/it]\n",
      "72%|███████▏  | 801/1111 [3:01:33<1:10:16, 13.60s/it]\n",
      "72%|███████▏  | 802/1111 [3:01:47<1:10:02, 13.60s/it]\n",
      "72%|███████▏  | 803/1111 [3:02:00<1:09:48, 13.60s/it]\n",
      "72%|███████▏  | 804/1111 [3:02:14<1:09:35, 13.60s/it]\n",
      "72%|███████▏  | 805/1111 [3:02:27<1:09:21, 13.60s/it]\n",
      "73%|███████▎  | 806/1111 [3:02:41<1:09:07, 13.60s/it]\n",
      "73%|███████▎  | 807/1111 [3:02:55<1:08:54, 13.60s/it]\n",
      "73%|███████▎  | 808/1111 [3:03:08<1:08:40, 13.60s/it]\n",
      "73%|███████▎  | 809/1111 [3:03:22<1:08:26, 13.60s/it]\n",
      "73%|███████▎  | 810/1111 [3:03:35<1:08:13, 13.60s/it]\n",
      "{'loss': 0.3448, 'learning_rate': 2.709270927092709e-05, 'epoch': 0.73}\n",
      "73%|███████▎  | 810/1111 [3:03:35<1:08:13, 13.60s/it]\n",
      "73%|███████▎  | 811/1111 [3:03:49<1:07:59, 13.60s/it]\n",
      "73%|███████▎  | 812/1111 [3:04:03<1:07:46, 13.60s/it]\n",
      "73%|███████▎  | 813/1111 [3:04:16<1:07:32, 13.60s/it]\n",
      "73%|███████▎  | 814/1111 [3:04:30<1:07:19, 13.60s/it]\n",
      "73%|███████▎  | 815/1111 [3:04:43<1:07:05, 13.60s/it]\n",
      "73%|███████▎  | 816/1111 [3:04:57<1:06:52, 13.60s/it]\n",
      "74%|███████▎  | 817/1111 [3:05:11<1:06:38, 13.60s/it]\n",
      "74%|███████▎  | 818/1111 [3:05:24<1:06:24, 13.60s/it]\n",
      "74%|███████▎  | 819/1111 [3:05:38<1:06:10, 13.60s/it]\n",
      "74%|███████▍  | 820/1111 [3:05:51<1:05:57, 13.60s/it]\n",
      "{'loss': 0.3467, 'learning_rate': 2.6192619261926195e-05, 'epoch': 0.74}\n",
      "74%|███████▍  | 820/1111 [3:05:51<1:05:57, 13.60s/it]\n",
      "74%|███████▍  | 821/1111 [3:06:05<1:05:43, 13.60s/it]\n",
      "74%|███████▍  | 822/1111 [3:06:19<1:05:30, 13.60s/it]\n",
      "74%|███████▍  | 823/1111 [3:06:32<1:05:16, 13.60s/it]\n",
      "74%|███████▍  | 824/1111 [3:06:46<1:05:03, 13.60s/it]\n",
      "74%|███████▍  | 825/1111 [3:06:59<1:04:49, 13.60s/it]\n",
      "74%|███████▍  | 826/1111 [3:07:13<1:04:35, 13.60s/it]\n",
      "74%|███████▍  | 827/1111 [3:07:27<1:04:22, 13.60s/it]\n",
      "75%|███████▍  | 828/1111 [3:07:40<1:04:08, 13.60s/it]\n",
      "75%|███████▍  | 829/1111 [3:07:54<1:03:54, 13.60s/it]\n",
      "75%|███████▍  | 830/1111 [3:08:07<1:03:41, 13.60s/it]\n",
      "{'loss': 0.3594, 'learning_rate': 2.5292529252925297e-05, 'epoch': 0.75}\n",
      "75%|███████▍  | 830/1111 [3:08:07<1:03:41, 13.60s/it]\n",
      "75%|███████▍  | 831/1111 [3:08:21<1:03:27, 13.60s/it]\n",
      "75%|███████▍  | 832/1111 [3:08:34<1:03:14, 13.60s/it]\n",
      "75%|███████▍  | 833/1111 [3:08:48<1:03:00, 13.60s/it]\n",
      "75%|███████▌  | 834/1111 [3:09:02<1:02:46, 13.60s/it]\n",
      "75%|███████▌  | 835/1111 [3:09:15<1:02:33, 13.60s/it]\n",
      "75%|███████▌  | 836/1111 [3:09:29<1:02:19, 13.60s/it]\n",
      "75%|███████▌  | 837/1111 [3:09:42<1:02:06, 13.60s/it]\n",
      "75%|███████▌  | 838/1111 [3:09:56<1:01:52, 13.60s/it]\n",
      "76%|███████▌  | 839/1111 [3:10:10<1:01:38, 13.60s/it]\n",
      "76%|███████▌  | 840/1111 [3:10:23<1:01:25, 13.60s/it]\n",
      "{'loss': 0.3519, 'learning_rate': 2.4392439243924395e-05, 'epoch': 0.76}\n",
      "76%|███████▌  | 840/1111 [3:10:23<1:01:25, 13.60s/it]\n",
      "76%|███████▌  | 841/1111 [3:10:37<1:01:11, 13.60s/it]\n",
      "76%|███████▌  | 842/1111 [3:10:50<1:00:58, 13.60s/it]\n",
      "76%|███████▌  | 843/1111 [3:11:04<1:00:44, 13.60s/it]\n",
      "76%|███████▌  | 844/1111 [3:11:18<1:00:31, 13.60s/it]\n",
      "76%|███████▌  | 845/1111 [3:11:31<1:00:17, 13.60s/it]\n",
      "76%|███████▌  | 846/1111 [3:11:45<1:00:04, 13.60s/it]\n",
      "76%|███████▌  | 847/1111 [3:11:58<59:50, 13.60s/it]\n",
      "76%|███████▋  | 848/1111 [3:12:12<59:37, 13.60s/it]\n",
      "76%|███████▋  | 849/1111 [3:12:26<59:23, 13.60s/it]\n",
      "77%|███████▋  | 850/1111 [3:12:39<59:09, 13.60s/it]\n",
      "{'loss': 0.3541, 'learning_rate': 2.3492349234923493e-05, 'epoch': 0.77}\n",
      "77%|███████▋  | 850/1111 [3:12:39<59:09, 13.60s/it]\n",
      "77%|███████▋  | 851/1111 [3:12:53<58:56, 13.60s/it]\n",
      "77%|███████▋  | 852/1111 [3:13:06<58:42, 13.60s/it]\n",
      "77%|███████▋  | 853/1111 [3:13:20<58:28, 13.60s/it]\n",
      "77%|███████▋  | 854/1111 [3:13:34<58:15, 13.60s/it]\n",
      "77%|███████▋  | 855/1111 [3:13:47<58:01, 13.60s/it]\n",
      "77%|███████▋  | 856/1111 [3:14:01<57:47, 13.60s/it]\n",
      "77%|███████▋  | 857/1111 [3:14:14<57:34, 13.60s/it]\n",
      "77%|███████▋  | 858/1111 [3:14:28<57:20, 13.60s/it]\n",
      "77%|███████▋  | 859/1111 [3:14:42<57:07, 13.60s/it]\n",
      "77%|███████▋  | 860/1111 [3:14:55<56:53, 13.60s/it]\n",
      "{'loss': 0.3422, 'learning_rate': 2.2592259225922595e-05, 'epoch': 0.77}\n",
      "77%|███████▋  | 860/1111 [3:14:55<56:53, 13.60s/it]\n",
      "77%|███████▋  | 861/1111 [3:15:09<56:39, 13.60s/it]\n",
      "78%|███████▊  | 862/1111 [3:15:22<56:26, 13.60s/it]\n",
      "78%|███████▊  | 863/1111 [3:15:36<56:12, 13.60s/it]\n",
      "78%|███████▊  | 864/1111 [3:15:50<55:58, 13.60s/it]\n",
      "78%|███████▊  | 865/1111 [3:16:03<55:45, 13.60s/it]\n",
      "78%|███████▊  | 866/1111 [3:16:17<55:31, 13.60s/it]\n",
      "78%|███████▊  | 867/1111 [3:16:30<55:18, 13.60s/it]\n",
      "78%|███████▊  | 868/1111 [3:16:44<55:04, 13.60s/it]\n",
      "78%|███████▊  | 869/1111 [3:16:58<54:50, 13.60s/it]\n",
      "78%|███████▊  | 870/1111 [3:17:11<54:37, 13.60s/it]\n",
      "{'loss': 0.3565, 'learning_rate': 2.1692169216921693e-05, 'epoch': 0.78}\n",
      "78%|███████▊  | 870/1111 [3:17:11<54:37, 13.60s/it]\n",
      "78%|███████▊  | 871/1111 [3:17:25<54:23, 13.60s/it]\n",
      "78%|███████▊  | 872/1111 [3:17:38<54:10, 13.60s/it]\n",
      "79%|███████▊  | 873/1111 [3:17:52<53:56, 13.60s/it]\n",
      "79%|███████▊  | 874/1111 [3:18:06<53:43, 13.60s/it]\n",
      "79%|███████▉  | 875/1111 [3:18:19<53:29, 13.60s/it]\n",
      "79%|███████▉  | 876/1111 [3:18:33<53:15, 13.60s/it]\n",
      "79%|███████▉  | 877/1111 [3:18:46<53:02, 13.60s/it]\n",
      "79%|███████▉  | 878/1111 [3:19:00<52:48, 13.60s/it]\n",
      "79%|███████▉  | 879/1111 [3:19:14<52:35, 13.60s/it]\n",
      "79%|███████▉  | 880/1111 [3:19:27<52:21, 13.60s/it]\n",
      "{'loss': 0.3459, 'learning_rate': 2.079207920792079e-05, 'epoch': 0.79}\n",
      "79%|███████▉  | 880/1111 [3:19:27<52:21, 13.60s/it]\n",
      "79%|███████▉  | 881/1111 [3:19:41<52:07, 13.60s/it]\n",
      "79%|███████▉  | 882/1111 [3:19:54<51:54, 13.60s/it]\n",
      "79%|███████▉  | 883/1111 [3:20:08<51:40, 13.60s/it]\n",
      "80%|███████▉  | 884/1111 [3:20:22<51:27, 13.60s/it]\n",
      "80%|███████▉  | 885/1111 [3:20:35<51:13, 13.60s/it]\n",
      "80%|███████▉  | 886/1111 [3:20:49<50:59, 13.60s/it]\n",
      "80%|███████▉  | 887/1111 [3:21:02<50:46, 13.60s/it]\n",
      "80%|███████▉  | 888/1111 [3:21:16<50:32, 13.60s/it]\n",
      "80%|████████  | 889/1111 [3:21:30<50:19, 13.60s/it]\n",
      "80%|████████  | 890/1111 [3:21:43<50:05, 13.60s/it]\n",
      "{'loss': 0.3411, 'learning_rate': 1.9891989198919896e-05, 'epoch': 0.8}\n",
      "80%|████████  | 890/1111 [3:21:43<50:05, 13.60s/it]\n",
      "80%|████████  | 891/1111 [3:21:57<49:51, 13.60s/it]\n",
      "80%|████████  | 892/1111 [3:22:10<49:38, 13.60s/it]\n",
      "80%|████████  | 893/1111 [3:22:24<49:24, 13.60s/it]\n",
      "80%|████████  | 894/1111 [3:22:38<49:10, 13.60s/it]\n",
      "81%|████████  | 895/1111 [3:22:51<48:57, 13.60s/it]\n",
      "81%|████████  | 896/1111 [3:23:05<48:43, 13.60s/it]\n",
      "81%|████████  | 897/1111 [3:23:18<48:30, 13.60s/it]\n",
      "81%|████████  | 898/1111 [3:23:32<48:16, 13.60s/it]\n",
      "81%|████████  | 899/1111 [3:23:46<48:03, 13.60s/it]\n",
      "81%|████████  | 900/1111 [3:23:59<47:49, 13.60s/it]\n",
      "{'loss': 0.3416, 'learning_rate': 1.8991899189918994e-05, 'epoch': 0.81}\n",
      "81%|████████  | 900/1111 [3:23:59<47:49, 13.60s/it]\n",
      "81%|████████  | 901/1111 [3:24:13<47:35, 13.60s/it]\n",
      "81%|████████  | 902/1111 [3:24:26<47:22, 13.60s/it]\n",
      "81%|████████▏ | 903/1111 [3:24:40<47:08, 13.60s/it]\n",
      "81%|████████▏ | 904/1111 [3:24:54<46:54, 13.60s/it]\n",
      "81%|████████▏ | 905/1111 [3:25:07<46:41, 13.60s/it]\n",
      "82%|████████▏ | 906/1111 [3:25:21<46:27, 13.60s/it]\n",
      "82%|████████▏ | 907/1111 [3:25:34<46:14, 13.60s/it]\n",
      "82%|████████▏ | 908/1111 [3:25:48<46:00, 13.60s/it]\n",
      "82%|████████▏ | 909/1111 [3:26:02<45:47, 13.60s/it]\n",
      "82%|████████▏ | 910/1111 [3:26:15<45:33, 13.60s/it]\n",
      "{'loss': 0.34, 'learning_rate': 1.8091809180918092e-05, 'epoch': 0.82}\n",
      "82%|████████▏ | 910/1111 [3:26:15<45:33, 13.60s/it]\n",
      "82%|████████▏ | 911/1111 [3:26:29<45:19, 13.60s/it]\n",
      "82%|████████▏ | 912/1111 [3:26:42<45:06, 13.60s/it]\n",
      "82%|████████▏ | 913/1111 [3:26:56<44:52, 13.60s/it]\n",
      "82%|████████▏ | 914/1111 [3:27:10<44:39, 13.60s/it]\n",
      "82%|████████▏ | 915/1111 [3:27:23<44:25, 13.60s/it]\n",
      "82%|████████▏ | 916/1111 [3:27:37<44:11, 13.60s/it]\n",
      "83%|████████▎ | 917/1111 [3:27:50<43:58, 13.60s/it]\n",
      "83%|████████▎ | 918/1111 [3:28:04<43:44, 13.60s/it]\n",
      "83%|████████▎ | 919/1111 [3:28:18<43:30, 13.60s/it]\n",
      "83%|████████▎ | 920/1111 [3:28:31<43:17, 13.60s/it]\n",
      "{'loss': 0.359, 'learning_rate': 1.7191719171917194e-05, 'epoch': 0.83}\n",
      "83%|████████▎ | 920/1111 [3:28:31<43:17, 13.60s/it]\n",
      "83%|████████▎ | 921/1111 [3:28:45<43:03, 13.60s/it]\n",
      "83%|████████▎ | 922/1111 [3:28:58<42:50, 13.60s/it]\n",
      "83%|████████▎ | 923/1111 [3:29:12<42:36, 13.60s/it]\n",
      "83%|████████▎ | 924/1111 [3:29:26<42:22, 13.60s/it]\n",
      "83%|████████▎ | 925/1111 [3:29:39<42:09, 13.60s/it]\n",
      "83%|████████▎ | 926/1111 [3:29:53<41:55, 13.60s/it]\n",
      "83%|████████▎ | 927/1111 [3:30:06<41:42, 13.60s/it]\n",
      "84%|████████▎ | 928/1111 [3:30:20<41:28, 13.60s/it]\n",
      "84%|████████▎ | 929/1111 [3:30:34<41:15, 13.60s/it]\n",
      "84%|████████▎ | 930/1111 [3:30:47<41:01, 13.60s/it]\n",
      "{'loss': 0.3652, 'learning_rate': 1.6291629162916292e-05, 'epoch': 0.84}\n",
      "84%|████████▎ | 930/1111 [3:30:47<41:01, 13.60s/it]\n",
      "84%|████████▍ | 931/1111 [3:31:01<40:47, 13.60s/it]\n",
      "84%|████████▍ | 932/1111 [3:31:14<40:34, 13.60s/it]\n",
      "84%|████████▍ | 933/1111 [3:31:28<40:20, 13.60s/it]\n",
      "84%|████████▍ | 934/1111 [3:31:42<40:06, 13.60s/it]\n",
      "84%|████████▍ | 935/1111 [3:31:55<39:53, 13.60s/it]\n",
      "84%|████████▍ | 936/1111 [3:32:09<39:39, 13.60s/it]\n",
      "84%|████████▍ | 937/1111 [3:32:22<39:26, 13.60s/it]\n",
      "84%|████████▍ | 938/1111 [3:32:36<39:12, 13.60s/it]\n",
      "85%|████████▍ | 939/1111 [3:32:50<38:59, 13.60s/it]\n",
      "85%|████████▍ | 940/1111 [3:33:03<38:45, 13.60s/it]\n",
      "{'loss': 0.3401, 'learning_rate': 1.5391539153915394e-05, 'epoch': 0.85}\n",
      "85%|████████▍ | 940/1111 [3:33:03<38:45, 13.60s/it]\n",
      "85%|████████▍ | 941/1111 [3:33:17<38:31, 13.60s/it]\n",
      "85%|████████▍ | 942/1111 [3:33:30<38:18, 13.60s/it]\n",
      "85%|████████▍ | 943/1111 [3:33:44<38:04, 13.60s/it]\n",
      "85%|████████▍ | 944/1111 [3:33:58<37:51, 13.60s/it]\n",
      "85%|████████▌ | 945/1111 [3:34:11<37:37, 13.60s/it]\n",
      "85%|████████▌ | 946/1111 [3:34:25<37:23, 13.60s/it]\n",
      "85%|████████▌ | 947/1111 [3:34:38<37:10, 13.60s/it]\n",
      "85%|████████▌ | 948/1111 [3:34:52<36:56, 13.60s/it]\n",
      "85%|████████▌ | 949/1111 [3:35:06<36:43, 13.60s/it]\n",
      "86%|████████▌ | 950/1111 [3:35:19<36:29, 13.60s/it]\n",
      "{'loss': 0.3473, 'learning_rate': 1.4491449144914493e-05, 'epoch': 0.86}\n",
      "86%|████████▌ | 950/1111 [3:35:19<36:29, 13.60s/it]\n",
      "86%|████████▌ | 951/1111 [3:35:33<36:15, 13.60s/it]\n",
      "86%|████████▌ | 952/1111 [3:35:46<36:02, 13.60s/it]\n",
      "86%|████████▌ | 953/1111 [3:36:00<35:48, 13.60s/it]\n",
      "86%|████████▌ | 954/1111 [3:36:14<35:35, 13.60s/it]\n",
      "86%|████████▌ | 955/1111 [3:36:27<35:21, 13.60s/it]\n",
      "86%|████████▌ | 956/1111 [3:36:41<35:07, 13.60s/it]\n",
      "86%|████████▌ | 957/1111 [3:36:54<34:54, 13.60s/it]\n",
      "86%|████████▌ | 958/1111 [3:37:08<34:40, 13.60s/it]\n",
      "86%|████████▋ | 959/1111 [3:37:22<34:27, 13.60s/it]\n",
      "86%|████████▋ | 960/1111 [3:37:35<34:13, 13.60s/it]\n",
      "{'loss': 0.3501, 'learning_rate': 1.3591359135913592e-05, 'epoch': 0.86}\n",
      "86%|████████▋ | 960/1111 [3:37:35<34:13, 13.60s/it]\n",
      "86%|████████▋ | 961/1111 [3:37:49<33:59, 13.60s/it]\n",
      "87%|████████▋ | 962/1111 [3:38:02<33:46, 13.60s/it]\n",
      "87%|████████▋ | 963/1111 [3:38:16<33:32, 13.60s/it]\n",
      "87%|████████▋ | 964/1111 [3:38:30<33:19, 13.60s/it]\n",
      "87%|████████▋ | 965/1111 [3:38:43<33:05, 13.60s/it]\n",
      "87%|████████▋ | 966/1111 [3:38:57<32:52, 13.60s/it]\n",
      "87%|████████▋ | 967/1111 [3:39:10<32:38, 13.60s/it]\n",
      "87%|████████▋ | 968/1111 [3:39:24<32:24, 13.60s/it]\n",
      "87%|████████▋ | 969/1111 [3:39:38<32:11, 13.60s/it]\n",
      "87%|████████▋ | 970/1111 [3:39:51<31:57, 13.60s/it]\n",
      "{'loss': 0.3453, 'learning_rate': 1.2691269126912692e-05, 'epoch': 0.87}\n",
      "87%|████████▋ | 970/1111 [3:39:51<31:57, 13.60s/it]\n",
      "87%|████████▋ | 971/1111 [3:40:05<31:43, 13.60s/it]\n",
      "87%|████████▋ | 972/1111 [3:40:18<31:30, 13.60s/it]\n",
      "88%|████████▊ | 973/1111 [3:40:32<31:16, 13.60s/it]\n",
      "88%|████████▊ | 974/1111 [3:40:46<31:03, 13.60s/it]\n",
      "88%|████████▊ | 975/1111 [3:40:59<30:49, 13.60s/it]\n",
      "88%|████████▊ | 976/1111 [3:41:13<30:35, 13.60s/it]\n",
      "88%|████████▊ | 977/1111 [3:41:26<30:22, 13.60s/it]\n",
      "88%|████████▊ | 978/1111 [3:41:40<30:08, 13.60s/it]\n",
      "88%|████████▊ | 979/1111 [3:41:54<29:55, 13.60s/it]\n",
      "88%|████████▊ | 980/1111 [3:42:07<29:41, 13.60s/it]\n",
      "{'loss': 0.3545, 'learning_rate': 1.1791179117911793e-05, 'epoch': 0.88}\n",
      "88%|████████▊ | 980/1111 [3:42:07<29:41, 13.60s/it]\n",
      "88%|████████▊ | 981/1111 [3:42:21<29:27, 13.60s/it]\n",
      "88%|████████▊ | 982/1111 [3:42:34<29:14, 13.60s/it]\n",
      "88%|████████▊ | 983/1111 [3:42:48<29:00, 13.60s/it]\n",
      "89%|████████▊ | 984/1111 [3:43:02<28:47, 13.60s/it]\n",
      "89%|████████▊ | 985/1111 [3:43:15<28:33, 13.60s/it]\n",
      "89%|████████▊ | 986/1111 [3:43:29<28:19, 13.60s/it]\n",
      "89%|████████▉ | 987/1111 [3:43:42<28:06, 13.60s/it]\n",
      "89%|████████▉ | 988/1111 [3:43:56<27:52, 13.60s/it]\n",
      "89%|████████▉ | 989/1111 [3:44:10<27:39, 13.60s/it]\n",
      "89%|████████▉ | 990/1111 [3:44:23<27:25, 13.60s/it]\n",
      "{'loss': 0.3556, 'learning_rate': 1.0891089108910891e-05, 'epoch': 0.89}\n",
      "89%|████████▉ | 990/1111 [3:44:23<27:25, 13.60s/it]\n",
      "89%|████████▉ | 991/1111 [3:44:37<27:12, 13.60s/it]\n",
      "89%|████████▉ | 992/1111 [3:44:50<26:58, 13.60s/it]\n",
      "89%|████████▉ | 993/1111 [3:45:04<26:44, 13.60s/it]\n",
      "89%|████████▉ | 994/1111 [3:45:18<26:31, 13.60s/it]\n",
      "90%|████████▉ | 995/1111 [3:45:31<26:17, 13.60s/it]\n",
      "90%|████████▉ | 996/1111 [3:45:45<26:04, 13.60s/it]\n",
      "90%|████████▉ | 997/1111 [3:45:58<25:50, 13.60s/it]\n",
      "90%|████████▉ | 998/1111 [3:46:12<25:36, 13.60s/it]\n",
      "90%|████████▉ | 999/1111 [3:46:26<25:23, 13.60s/it]\n",
      "90%|█████████ | 1000/1111 [3:46:39<25:09, 13.60s/it]\n",
      "{'loss': 0.3488, 'learning_rate': 9.990999099909991e-06, 'epoch': 0.9}\n",
      "90%|█████████ | 1000/1111 [3:46:39<25:09, 13.60s/it]\n",
      "90%|█████████ | 1001/1111 [3:46:53<24:56, 13.60s/it]\n",
      "90%|█████████ | 1002/1111 [3:47:06<24:42, 13.60s/it]\n",
      "90%|█████████ | 1003/1111 [3:47:20<24:28, 13.60s/it]\n",
      "90%|█████████ | 1004/1111 [3:47:34<24:15, 13.60s/it]\n",
      "90%|█████████ | 1005/1111 [3:47:47<24:01, 13.60s/it]\n",
      "91%|█████████ | 1006/1111 [3:48:01<23:47, 13.60s/it]\n",
      "91%|█████████ | 1007/1111 [3:48:14<23:34, 13.60s/it]\n",
      "91%|█████████ | 1008/1111 [3:48:28<23:20, 13.60s/it]\n",
      "91%|█████████ | 1009/1111 [3:48:42<23:07, 13.60s/it]\n",
      "91%|█████████ | 1010/1111 [3:48:55<22:53, 13.60s/it]\n",
      "{'loss': 0.3373, 'learning_rate': 9.090909090909091e-06, 'epoch': 0.91}\n",
      "91%|█████████ | 1010/1111 [3:48:55<22:53, 13.60s/it]\n",
      "91%|█████████ | 1011/1111 [3:49:09<22:39, 13.60s/it]\n",
      "91%|█████████ | 1012/1111 [3:49:22<22:26, 13.60s/it]\n",
      "91%|█████████ | 1013/1111 [3:49:36<22:12, 13.60s/it]\n",
      "91%|█████████▏| 1014/1111 [3:49:50<21:59, 13.60s/it]\n",
      "91%|█████████▏| 1015/1111 [3:50:03<21:45, 13.60s/it]\n",
      "91%|█████████▏| 1016/1111 [3:50:17<21:31, 13.60s/it]\n",
      "92%|█████████▏| 1017/1111 [3:50:30<21:18, 13.60s/it]\n",
      "92%|█████████▏| 1018/1111 [3:50:44<21:04, 13.60s/it]\n",
      "92%|█████████▏| 1019/1111 [3:50:58<20:51, 13.60s/it]\n",
      "92%|█████████▏| 1020/1111 [3:51:11<20:37, 13.60s/it]\n",
      "{'loss': 0.348, 'learning_rate': 8.190819081908191e-06, 'epoch': 0.92}\n",
      "92%|█████████▏| 1020/1111 [3:51:11<20:37, 13.60s/it]\n",
      "92%|█████████▏| 1021/1111 [3:51:25<20:24, 13.60s/it]\n",
      "92%|█████████▏| 1022/1111 [3:51:38<20:10, 13.60s/it]\n",
      "92%|█████████▏| 1023/1111 [3:51:52<19:56, 13.60s/it]\n",
      "92%|█████████▏| 1024/1111 [3:52:06<19:43, 13.60s/it]\n",
      "92%|█████████▏| 1025/1111 [3:52:19<19:29, 13.60s/it]\n",
      "92%|█████████▏| 1026/1111 [3:52:33<19:15, 13.60s/it]\n",
      "92%|█████████▏| 1027/1111 [3:52:46<19:02, 13.60s/it]\n",
      "93%|█████████▎| 1028/1111 [3:53:00<18:48, 13.60s/it]\n",
      "93%|█████████▎| 1029/1111 [3:53:14<18:35, 13.60s/it]\n",
      "93%|█████████▎| 1030/1111 [3:53:27<18:21, 13.60s/it]\n",
      "{'loss': 0.3652, 'learning_rate': 7.290729072907292e-06, 'epoch': 0.93}\n",
      "93%|█████████▎| 1030/1111 [3:53:27<18:21, 13.60s/it]\n",
      "93%|█████████▎| 1031/1111 [3:53:41<18:07, 13.60s/it]\n",
      "93%|█████████▎| 1032/1111 [3:53:54<17:54, 13.60s/it]\n",
      "93%|█████████▎| 1033/1111 [3:54:08<17:40, 13.60s/it]\n",
      "93%|█████████▎| 1034/1111 [3:54:22<17:27, 13.60s/it]\n",
      "93%|█████████▎| 1035/1111 [3:54:35<17:13, 13.60s/it]\n",
      "93%|█████████▎| 1036/1111 [3:54:49<16:59, 13.60s/it]\n",
      "93%|█████████▎| 1037/1111 [3:55:02<16:46, 13.60s/it]\n",
      "93%|█████████▎| 1038/1111 [3:55:16<16:32, 13.60s/it]\n",
      "94%|█████████▎| 1039/1111 [3:55:30<16:19, 13.60s/it]\n",
      "94%|█████████▎| 1040/1111 [3:55:43<16:05, 13.60s/it]\n",
      "{'loss': 0.3498, 'learning_rate': 6.390639063906391e-06, 'epoch': 0.94}\n",
      "94%|█████████▎| 1040/1111 [3:55:43<16:05, 13.60s/it]\n",
      "94%|█████████▎| 1041/1111 [3:55:57<15:51, 13.60s/it]\n",
      "94%|█████████▍| 1042/1111 [3:56:10<15:38, 13.60s/it]\n",
      "94%|█████████▍| 1043/1111 [3:56:24<15:24, 13.60s/it]\n",
      "94%|█████████▍| 1044/1111 [3:56:38<15:11, 13.60s/it]\n",
      "94%|█████████▍| 1045/1111 [3:56:51<14:57, 13.60s/it]\n",
      "94%|█████████▍| 1046/1111 [3:57:05<14:43, 13.60s/it]\n",
      "94%|█████████▍| 1047/1111 [3:57:18<14:30, 13.60s/it]\n",
      "94%|█████████▍| 1048/1111 [3:57:32<14:16, 13.60s/it]\n",
      "94%|█████████▍| 1049/1111 [3:57:46<14:03, 13.60s/it]\n",
      "95%|█████████▍| 1050/1111 [3:57:59<13:49, 13.60s/it]\n",
      "{'loss': 0.3628, 'learning_rate': 5.4905490549054906e-06, 'epoch': 0.95}\n",
      "95%|█████████▍| 1050/1111 [3:57:59<13:49, 13.60s/it]\n",
      "95%|█████████▍| 1051/1111 [3:58:13<13:35, 13.60s/it]\n",
      "95%|█████████▍| 1052/1111 [3:58:26<13:22, 13.60s/it]\n",
      "95%|█████████▍| 1053/1111 [3:58:40<13:08, 13.60s/it]\n",
      "95%|█████████▍| 1054/1111 [3:58:54<12:55, 13.60s/it]\n",
      "95%|█████████▍| 1055/1111 [3:59:07<12:41, 13.60s/it]\n",
      "95%|█████████▌| 1056/1111 [3:59:21<12:27, 13.60s/it]\n",
      "95%|█████████▌| 1057/1111 [3:59:34<12:14, 13.60s/it]\n",
      "95%|█████████▌| 1058/1111 [3:59:48<12:00, 13.60s/it]\n",
      "95%|█████████▌| 1059/1111 [4:00:02<11:47, 13.60s/it]\n",
      "95%|█████████▌| 1060/1111 [4:00:15<11:33, 13.60s/it]\n",
      "{'loss': 0.3594, 'learning_rate': 4.590459045904591e-06, 'epoch': 0.95}\n",
      "95%|█████████▌| 1060/1111 [4:00:15<11:33, 13.60s/it]\n",
      "95%|█████████▌| 1061/1111 [4:00:29<11:19, 13.60s/it]\n",
      "96%|█████████▌| 1062/1111 [4:00:42<11:06, 13.60s/it]\n",
      "96%|█████████▌| 1063/1111 [4:00:56<10:52, 13.60s/it]\n",
      "96%|█████████▌| 1064/1111 [4:01:10<10:39, 13.60s/it]\n",
      "96%|█████████▌| 1065/1111 [4:01:23<10:25, 13.60s/it]\n",
      "96%|█████████▌| 1066/1111 [4:01:37<10:11, 13.60s/it]\n",
      "96%|█████████▌| 1067/1111 [4:01:50<09:58, 13.60s/it]\n",
      "96%|█████████▌| 1068/1111 [4:02:04<09:44, 13.60s/it]\n",
      "96%|█████████▌| 1069/1111 [4:02:18<09:31, 13.60s/it]\n",
      "96%|█████████▋| 1070/1111 [4:02:31<09:17, 13.60s/it]\n",
      "{'loss': 0.3608, 'learning_rate': 3.6903690369036903e-06, 'epoch': 0.96}\n",
      "96%|█████████▋| 1070/1111 [4:02:31<09:17, 13.60s/it]\n",
      "96%|█████████▋| 1071/1111 [4:02:45<09:03, 13.60s/it]\n",
      "96%|█████████▋| 1072/1111 [4:02:58<08:50, 13.60s/it]\n",
      "97%|█████████▋| 1073/1111 [4:03:12<08:36, 13.60s/it]\n",
      "97%|█████████▋| 1074/1111 [4:03:26<08:23, 13.60s/it]\n",
      "97%|█████████▋| 1075/1111 [4:03:39<08:09, 13.60s/it]\n",
      "97%|█████████▋| 1076/1111 [4:03:53<07:55, 13.60s/it]\n",
      "97%|█████████▋| 1077/1111 [4:04:06<07:42, 13.60s/it]\n",
      "97%|█████████▋| 1078/1111 [4:04:20<07:28, 13.60s/it]\n",
      "97%|█████████▋| 1079/1111 [4:04:34<07:15, 13.60s/it]\n",
      "97%|█████████▋| 1080/1111 [4:04:47<07:01, 13.60s/it]\n",
      "{'loss': 0.3457, 'learning_rate': 2.79027902790279e-06, 'epoch': 0.97}\n",
      "97%|█████████▋| 1080/1111 [4:04:47<07:01, 13.60s/it]\n",
      "97%|█████████▋| 1081/1111 [4:05:01<06:47, 13.60s/it]\n",
      "97%|█████████▋| 1082/1111 [4:05:14<06:34, 13.60s/it]\n",
      "97%|█████████▋| 1083/1111 [4:05:28<06:20, 13.60s/it]\n",
      "98%|█████████▊| 1084/1111 [4:05:42<06:07, 13.60s/it]\n",
      "98%|█████████▊| 1085/1111 [4:05:55<05:53, 13.60s/it]\n",
      "98%|█████████▊| 1086/1111 [4:06:09<05:39, 13.60s/it]\n",
      "98%|█████████▊| 1087/1111 [4:06:22<05:26, 13.60s/it]\n",
      "98%|█████████▊| 1088/1111 [4:06:36<05:12, 13.60s/it]\n",
      "98%|█████████▊| 1089/1111 [4:06:50<04:59, 13.60s/it]\n",
      "98%|█████████▊| 1090/1111 [4:07:03<04:45, 13.60s/it]\n",
      "{'loss': 0.3497, 'learning_rate': 1.8901890189018903e-06, 'epoch': 0.98}\n",
      "98%|█████████▊| 1090/1111 [4:07:03<04:45, 13.60s/it]\n",
      "98%|█████████▊| 1091/1111 [4:07:17<04:31, 13.60s/it]\n",
      "98%|█████████▊| 1092/1111 [4:07:30<04:18, 13.60s/it]\n",
      "98%|█████████▊| 1093/1111 [4:07:44<04:04, 13.60s/it]\n",
      "98%|█████████▊| 1094/1111 [4:07:58<03:51, 13.60s/it]\n",
      "99%|█████████▊| 1095/1111 [4:08:11<03:37, 13.60s/it]\n",
      "99%|█████████▊| 1096/1111 [4:08:25<03:23, 13.60s/it]\n",
      "99%|█████████▊| 1097/1111 [4:08:38<03:10, 13.60s/it]\n",
      "99%|█████████▉| 1098/1111 [4:08:52<02:56, 13.60s/it]\n",
      "99%|█████████▉| 1099/1111 [4:09:06<02:43, 13.60s/it]\n",
      "99%|█████████▉| 1100/1111 [4:09:19<02:29, 13.60s/it]\n",
      "{'loss': 0.3708, 'learning_rate': 9.900990099009902e-07, 'epoch': 0.99}\n",
      "99%|█████████▉| 1100/1111 [4:09:19<02:29, 13.60s/it]\n",
      "99%|█████████▉| 1101/1111 [4:09:33<02:15, 13.60s/it]\n",
      "99%|█████████▉| 1102/1111 [4:09:46<02:02, 13.60s/it]\n",
      "99%|█████████▉| 1103/1111 [4:10:00<01:48, 13.60s/it]\n",
      "99%|█████████▉| 1104/1111 [4:10:14<01:35, 13.60s/it]\n",
      "99%|█████████▉| 1105/1111 [4:10:27<01:21, 13.60s/it]\n",
      "100%|█████████▉| 1106/1111 [4:10:41<01:07, 13.60s/it]\n",
      "100%|█████████▉| 1107/1111 [4:10:54<00:54, 13.60s/it]\n",
      "100%|█████████▉| 1108/1111 [4:11:08<00:40, 13.60s/it]\n",
      "100%|█████████▉| 1109/1111 [4:11:22<00:27, 13.60s/it]\n",
      "100%|█████████▉| 1110/1111 [4:11:35<00:13, 13.60s/it]\n",
      "{'loss': 0.3656, 'learning_rate': 9.000900090009001e-08, 'epoch': 1.0}\n",
      "100%|█████████▉| 1110/1111 [4:11:35<00:13, 13.60s/it]\n",
      "100%|██████████| 1111/1111 [4:11:45<00:00, 12.62s/it]\n",
      "{'train_runtime': 15105.9474, 'train_samples_per_second': 0.294, 'train_steps_per_second': 0.074, 'train_loss': 0.39439105552987513, 'epoch': 1.0}\n",
      "100%|██████████| 1111/1111 [4:11:45<00:00, 12.62s/it]\n",
      "100%|██████████| 1111/1111 [4:11:45<00:00, 13.60s/it]\n",
      "adapter_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]\n",
      "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "#033[A\n",
      "training_args.bin:   0%|          | 0.00/4.09k [00:00<?, ?B/s]#033[A#033[A\n",
      "training_args.bin: 100%|██████████| 4.09k/4.09k [00:00<00:00, 52.0kB/s]\n",
      "adapter_model.bin:  12%|█▏        | 16.0M/134M [00:00<00:02, 51.4MB/s]\n",
      "adapter_model.bin:  24%|██▍       | 32.0M/134M [00:00<00:01, 59.2MB/s]\n",
      "adapter_model.bin:  36%|███▌      | 48.0M/134M [00:00<00:01, 63.0MB/s]\n",
      "adapter_model.bin:  48%|████▊     | 64.0M/134M [00:01<00:01, 57.3MB/s]\n",
      "adapter_model.bin:  60%|█████▉    | 80.0M/134M [00:01<00:01, 44.8MB/s]\n",
      "adapter_model.bin:  71%|███████▏  | 96.0M/134M [00:01<00:00, 49.2MB/s]\n",
      "adapter_model.bin:  80%|███████▉  | 107M/134M [00:01<00:00, 56.8MB/s]\n",
      "adapter_model.bin:  85%|████████▌ | 114M/134M [00:02<00:00, 52.5MB/s]\n",
      "adapter_model.bin:  95%|█████████▌| 128M/134M [00:02<00:00, 56.3MB/s]\n",
      "adapter_model.bin: 100%|██████████| 134M/134M [00:02<00:00, 46.9MB/s]\n",
      "Upload 2 LFS files:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]#033[A\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]\n",
      "***MERGING***\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "***Pushing Model to Hub***\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]\n",
      "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "#033[A\n",
      "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:   0%|          | 13.1M/3.50G [00:00<00:26, 131MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 9.45M/9.98G [00:00<02:08, 77.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   1%|          | 26.2M/3.50G [00:00<00:34, 102MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 17.2M/9.98G [00:00<02:39, 62.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 32.0M/9.98G [00:00<02:14, 74.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   1%|          | 36.7M/3.50G [00:00<00:51, 67.3MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 48.0M/9.98G [00:00<02:24, 68.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   1%|▏         | 48.0M/3.50G [00:00<00:56, 60.8MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 61.2M/9.98G [00:00<01:59, 82.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   2%|▏         | 61.7M/3.50G [00:00<00:44, 78.1MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:   2%|▏         | 71.0M/3.50G [00:00<00:49, 69.8MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 70.4M/9.98G [00:00<02:20, 70.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   2%|▏         | 80.0M/3.50G [00:01<00:51, 66.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 80.0M/9.98G [00:01<02:52, 57.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   3%|▎         | 96.0M/3.50G [00:01<00:49, 68.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 96.0M/9.98G [00:01<02:35, 63.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 111M/9.98G [00:01<02:07, 77.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   3%|▎         | 112M/3.50G [00:01<00:56, 60.2MB/s] #033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 120M/9.98G [00:01<02:49, 58.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   4%|▎         | 128M/3.50G [00:01<00:59, 56.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|▏         | 128M/9.98G [00:02<03:12, 51.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   4%|▍         | 144M/3.50G [00:02<00:52, 64.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|▏         | 144M/9.98G [00:02<02:39, 61.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   5%|▍         | 160M/3.50G [00:02<00:49, 68.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 160M/9.98G [00:02<02:28, 66.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   5%|▌         | 176M/3.50G [00:02<00:48, 68.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 176M/9.98G [00:02<02:16, 71.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   5%|▌         | 192M/3.50G [00:02<00:45, 72.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 192M/9.98G [00:02<02:15, 72.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   6%|▌         | 208M/3.50G [00:03<00:45, 71.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 208M/9.98G [00:03<02:17, 70.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 224M/9.98G [00:03<02:14, 72.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   6%|▋         | 224M/3.50G [00:03<00:50, 64.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 240M/9.98G [00:03<02:06, 76.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 256M/9.98G [00:03<02:00, 80.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   7%|▋         | 240M/3.50G [00:03<01:00, 53.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 272M/9.98G [00:03<02:09, 75.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 288M/9.98G [00:04<01:51, 86.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   7%|▋         | 256M/3.50G [00:04<01:00, 53.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 297M/9.98G [00:04<02:10, 74.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   8%|▊         | 272M/3.50G [00:04<00:59, 54.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 305M/9.98G [00:04<02:18, 69.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 320M/9.98G [00:04<02:16, 71.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   8%|▊         | 288M/3.50G [00:04<00:55, 58.0MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 334M/9.98G [00:04<01:53, 85.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   9%|▊         | 304M/3.50G [00:04<00:49, 64.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 344M/9.98G [00:04<01:57, 81.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   4%|▎         | 353M/9.98G [00:04<02:12, 72.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:   9%|▉         | 320M/3.50G [00:04<00:48, 66.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▎         | 368M/9.98G [00:05<02:05, 76.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  10%|▉         | 336M/3.50G [00:05<00:48, 64.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 384M/9.98G [00:05<02:11, 72.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  10%|█         | 352M/3.50G [00:05<00:49, 63.7MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  11%|█         | 368M/3.50G [00:05<00:44, 70.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 400M/9.98G [00:05<02:51, 55.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  11%|█         | 384M/3.50G [00:05<00:45, 68.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 416M/9.98G [00:06<02:42, 58.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  11%|█▏        | 400M/3.50G [00:06<00:52, 59.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 432M/9.98G [00:06<02:49, 56.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  12%|█▏        | 416M/3.50G [00:06<00:48, 63.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 448M/9.98G [00:06<02:31, 63.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  12%|█▏        | 432M/3.50G [00:06<00:43, 70.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 464M/9.98G [00:06<02:46, 57.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  13%|█▎        | 448M/3.50G [00:06<00:43, 70.7MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 478M/9.98G [00:07<02:25, 65.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  13%|█▎        | 464M/3.50G [00:07<00:45, 66.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 485M/9.98G [00:07<02:58, 53.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  14%|█▎        | 480M/3.50G [00:07<00:39, 77.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 496M/9.98G [00:07<02:57, 53.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  14%|█▍        | 496M/3.50G [00:07<00:43, 69.6MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  15%|█▍        | 512M/3.50G [00:07<00:39, 75.7MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  15%|█▌        | 528M/3.50G [00:08<00:50, 58.6MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|█▌        | 544M/3.50G [00:08<00:51, 57.0MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|█▌        | 560M/3.50G [00:08<00:54, 54.0MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|█▋        | 576M/3.50G [00:09<00:56, 52.0MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  17%|█▋        | 592M/3.50G [00:09<00:52, 54.9MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  17%|█▋        | 608M/3.50G [00:09<00:50, 57.8MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  18%|█▊        | 624M/3.50G [00:09<00:44, 65.2MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  18%|█▊        | 640M/3.50G [00:09<00:41, 68.8MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  19%|█▊        | 656M/3.50G [00:10<00:38, 74.2MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  19%|█▉        | 672M/3.50G [00:10<00:35, 79.2MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  20%|█▉        | 688M/3.50G [00:10<00:38, 73.4MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  20%|██        | 702M/3.50G [00:10<00:34, 81.9MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  20%|██        | 711M/3.50G [00:10<00:39, 70.9MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|██        | 720M/3.50G [00:11<00:47, 58.4MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|██        | 736M/3.50G [00:11<00:42, 65.3MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|██▏       | 752M/3.50G [00:11<00:42, 65.2MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  22%|██▏       | 768M/3.50G [00:11<00:40, 66.7MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  22%|██▏       | 784M/3.50G [00:12<00:40, 67.6MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  23%|██▎       | 800M/3.50G [00:12<00:36, 73.2MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  23%|██▎       | 816M/3.50G [00:12<00:38, 69.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 512M/9.98G [00:12<20:05, 7.85MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  24%|██▍       | 832M/3.50G [00:12<00:38, 70.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 528M/9.98G [00:12<14:04, 11.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  24%|██▍       | 848M/3.50G [00:13<00:44, 59.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 544M/9.98G [00:13<10:26, 15.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  25%|██▍       | 864M/3.50G [00:13<00:40, 64.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 560M/9.98G [00:13<07:39, 20.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  25%|██▌       | 880M/3.50G [00:13<00:41, 63.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 576M/9.98G [00:13<06:08, 25.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  26%|██▌       | 896M/3.50G [00:13<00:38, 67.0MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  26%|██▌       | 912M/3.50G [00:13<00:38, 66.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 592M/9.98G [00:14<05:43, 27.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 608M/9.98G [00:14<04:43, 33.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  27%|██▋       | 928M/3.50G [00:14<00:51, 50.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▋         | 624M/9.98G [00:14<03:50, 40.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  27%|██▋       | 944M/3.50G [00:14<00:47, 54.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▋         | 640M/9.98G [00:14<03:42, 42.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  27%|██▋       | 960M/3.50G [00:14<00:41, 60.6MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  28%|██▊       | 976M/3.50G [00:15<00:42, 59.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 656M/9.98G [00:15<03:33, 43.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  28%|██▊       | 992M/3.50G [00:15<00:38, 64.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 672M/9.98G [00:15<03:03, 50.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  29%|██▉       | 1.01G/3.50G [00:15<00:37, 67.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 688M/9.98G [00:15<02:43, 56.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 704M/9.98G [00:15<02:32, 60.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  29%|██▉       | 1.02G/3.50G [00:15<00:38, 63.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 720M/9.98G [00:16<02:19, 66.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  30%|██▉       | 1.04G/3.50G [00:16<00:37, 65.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 736M/9.98G [00:16<02:15, 68.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 752M/9.98G [00:16<02:12, 69.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  30%|███       | 1.06G/3.50G [00:16<00:48, 50.3MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  31%|███       | 1.07G/3.50G [00:16<00:43, 55.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 768M/9.98G [00:16<02:49, 54.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  31%|███       | 1.09G/3.50G [00:17<00:39, 61.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 784M/9.98G [00:17<02:24, 63.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  32%|███▏      | 1.10G/3.50G [00:17<00:35, 67.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 800M/9.98G [00:17<02:16, 67.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 816M/9.98G [00:17<02:06, 72.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 832M/9.98G [00:17<02:09, 70.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  32%|███▏      | 1.12G/3.50G [00:17<00:56, 41.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 848M/9.98G [00:17<02:17, 66.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  32%|███▏      | 1.14G/3.50G [00:18<00:47, 49.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▊         | 864M/9.98G [00:18<02:09, 70.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  33%|███▎      | 1.15G/3.50G [00:18<00:42, 55.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 880M/9.98G [00:18<02:07, 71.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  33%|███▎      | 1.17G/3.50G [00:18<00:39, 58.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 896M/9.98G [00:18<02:03, 73.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 912M/9.98G [00:18<02:04, 72.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 928M/9.98G [00:18<01:54, 79.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 944M/9.98G [00:19<03:55, 38.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  34%|███▍      | 1.18G/3.50G [00:20<01:33, 24.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 960M/9.98G [00:20<03:19, 45.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  34%|███▍      | 1.20G/3.50G [00:20<01:13, 31.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 976M/9.98G [00:20<02:51, 52.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 992M/9.98G [00:20<02:29, 60.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  35%|███▍      | 1.22G/3.50G [00:20<01:01, 37.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.01G/9.98G [00:20<02:16, 65.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  35%|███▌      | 1.23G/3.50G [00:20<00:52, 43.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.02G/9.98G [00:20<02:19, 64.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  36%|███▌      | 1.25G/3.50G [00:20<00:45, 49.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.04G/9.98G [00:21<02:11, 68.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  36%|███▌      | 1.26G/3.50G [00:21<00:40, 55.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.06G/9.98G [00:21<02:00, 74.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.07G/9.98G [00:21<02:03, 71.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  37%|███▋      | 1.28G/3.50G [00:21<00:47, 46.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.09G/9.98G [00:21<01:59, 74.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  37%|███▋      | 1.30G/3.50G [00:21<00:41, 53.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.10G/9.98G [00:21<01:57, 75.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  37%|███▋      | 1.31G/3.50G [00:21<00:34, 64.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.12G/9.98G [00:22<02:04, 71.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  38%|███▊      | 1.33G/3.50G [00:22<00:33, 64.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█▏        | 1.13G/9.98G [00:22<01:46, 82.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  38%|███▊      | 1.34G/3.50G [00:22<00:27, 78.9MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|███▊      | 1.35G/3.50G [00:22<00:27, 78.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█▏        | 1.14G/9.98G [00:22<01:59, 73.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  39%|███▉      | 1.36G/3.50G [00:22<00:28, 75.1MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|███▉      | 1.38G/3.50G [00:22<00:28, 75.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.15G/9.98G [00:22<03:10, 46.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  40%|███▉      | 1.39G/3.50G [00:22<00:27, 76.9MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  40%|████      | 1.41G/3.50G [00:23<00:26, 79.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.17G/9.98G [00:23<02:57, 49.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  41%|████      | 1.42G/3.50G [00:23<00:25, 81.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.18G/9.98G [00:23<02:27, 59.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  41%|████      | 1.44G/3.50G [00:23<00:23, 87.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.20G/9.98G [00:23<02:21, 62.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  42%|████▏     | 1.46G/3.50G [00:23<00:26, 77.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.22G/9.98G [00:23<02:12, 66.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  42%|████▏     | 1.47G/3.50G [00:23<00:24, 81.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.23G/9.98G [00:24<02:14, 65.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  43%|████▎     | 1.49G/3.50G [00:24<00:23, 84.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.25G/9.98G [00:24<02:09, 67.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  43%|████▎     | 1.50G/3.50G [00:24<00:28, 70.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.26G/9.98G [00:24<02:15, 64.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  43%|████▎     | 1.52G/3.50G [00:24<00:28, 69.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.28G/9.98G [00:24<02:14, 64.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  44%|████▍     | 1.54G/3.50G [00:24<00:27, 71.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.30G/9.98G [00:24<02:09, 66.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  44%|████▍     | 1.55G/3.50G [00:25<00:26, 72.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.31G/9.98G [00:25<02:14, 64.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.33G/9.98G [00:25<01:54, 75.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.34G/9.98G [00:25<01:50, 78.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▎        | 1.36G/9.98G [00:25<02:06, 67.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.38G/9.98G [00:26<02:04, 68.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.39G/9.98G [00:26<01:58, 72.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.41G/9.98G [00:26<02:11, 65.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.42G/9.98G [00:26<01:53, 75.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.44G/9.98G [00:26<01:49, 78.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  45%|████▍     | 1.57G/3.50G [00:27<01:51, 17.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.46G/9.98G [00:27<03:07, 45.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  45%|████▌     | 1.58G/3.50G [00:27<01:26, 22.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.47G/9.98G [00:27<02:45, 51.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.49G/9.98G [00:28<02:35, 54.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  46%|████▌     | 1.60G/3.50G [00:28<01:11, 26.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.50G/9.98G [00:28<02:21, 59.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  46%|████▌     | 1.62G/3.50G [00:28<00:59, 31.6MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  47%|████▋     | 1.63G/3.50G [00:28<00:52, 35.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.52G/9.98G [00:28<03:07, 45.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.54G/9.98G [00:28<02:31, 55.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  47%|████▋     | 1.65G/3.50G [00:29<00:44, 41.4MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.55G/9.98G [00:29<02:11, 64.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  48%|████▊     | 1.66G/3.50G [00:29<00:40, 45.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.57G/9.98G [00:29<01:58, 71.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.58G/9.98G [00:29<01:50, 76.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  48%|████▊     | 1.68G/3.50G [00:29<00:36, 49.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.60G/9.98G [00:29<01:52, 74.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  48%|████▊     | 1.70G/3.50G [00:29<00:35, 51.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.62G/9.98G [00:29<02:01, 68.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  49%|████▉     | 1.71G/3.50G [00:30<00:33, 53.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▋        | 1.63G/9.98G [00:30<02:05, 66.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  49%|████▉     | 1.73G/3.50G [00:30<00:33, 53.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▋        | 1.64G/9.98G [00:30<01:57, 70.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.65G/9.98G [00:30<02:13, 62.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  50%|████▉     | 1.74G/3.50G [00:30<00:30, 57.4MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  50%|█████     | 1.76G/3.50G [00:30<00:28, 61.5MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  51%|█████     | 1.78G/3.50G [00:31<00:26, 64.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.66G/9.98G [00:31<03:32, 39.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.68G/9.98G [00:31<02:46, 49.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  51%|█████     | 1.79G/3.50G [00:31<00:34, 49.8MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  52%|█████▏    | 1.81G/3.50G [00:31<00:32, 52.2MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  52%|█████▏    | 1.82G/3.50G [00:32<00:29, 56.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.70G/9.98G [00:32<03:58, 34.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.71G/9.98G [00:32<03:18, 41.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  53%|█████▎    | 1.84G/3.50G [00:32<00:29, 56.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.73G/9.98G [00:32<03:01, 45.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  53%|█████▎    | 1.86G/3.50G [00:32<00:30, 54.5MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  53%|█████▎    | 1.87G/3.50G [00:32<00:28, 57.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.74G/9.98G [00:32<03:10, 43.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.76G/9.98G [00:33<02:48, 48.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.78G/9.98G [00:33<02:28, 55.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.79G/9.98G [00:33<02:23, 57.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  54%|█████▍    | 1.89G/3.50G [00:33<00:49, 32.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.81G/9.98G [00:33<02:21, 57.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  54%|█████▍    | 1.90G/3.50G [00:34<00:42, 38.0MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  55%|█████▍    | 1.92G/3.50G [00:34<00:37, 42.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.82G/9.98G [00:34<03:09, 43.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  55%|█████▌    | 1.94G/3.50G [00:34<00:32, 47.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.84G/9.98G [00:34<03:02, 44.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  56%|█████▌    | 1.95G/3.50G [00:34<00:29, 52.2MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  56%|█████▌    | 1.96G/3.50G [00:35<00:26, 58.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▊        | 1.86G/9.98G [00:35<02:38, 51.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  56%|█████▋    | 1.97G/3.50G [00:35<00:27, 54.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.87G/9.98G [00:35<02:32, 53.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  57%|█████▋    | 1.98G/3.50G [00:35<00:27, 55.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.89G/9.98G [00:35<02:30, 53.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  57%|█████▋    | 2.00G/3.50G [00:35<00:27, 55.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.90G/9.98G [00:35<02:22, 56.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  58%|█████▊    | 2.02G/3.50G [00:35<00:25, 57.3MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  58%|█████▊    | 2.03G/3.50G [00:36<00:23, 62.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.92G/9.98G [00:36<02:23, 56.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.93G/9.98G [00:36<02:11, 61.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  59%|█████▊    | 2.05G/3.50G [00:36<00:23, 61.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.94G/9.98G [00:36<02:36, 51.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  59%|█████▉    | 2.06G/3.50G [00:36<00:22, 62.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.95G/9.98G [00:36<02:30, 53.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  59%|█████▉    | 2.08G/3.50G [00:36<00:22, 63.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.97G/9.98G [00:37<02:22, 56.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  60%|█████▉    | 2.10G/3.50G [00:37<00:22, 63.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.98G/9.98G [00:37<02:09, 61.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  60%|██████    | 2.11G/3.50G [00:37<00:21, 64.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.00G/9.98G [00:37<02:23, 55.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  61%|██████    | 2.13G/3.50G [00:37<00:20, 67.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.02G/9.98G [00:37<02:18, 57.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  61%|██████▏   | 2.14G/3.50G [00:37<00:20, 67.8MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.03G/9.98G [00:38<02:10, 60.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  62%|██████▏   | 2.16G/3.50G [00:38<00:19, 67.9MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  62%|██████▏   | 2.18G/3.50G [00:38<00:20, 65.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.05G/9.98G [00:38<02:11, 60.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  63%|██████▎   | 2.19G/3.50G [00:38<00:19, 65.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.06G/9.98G [00:38<02:24, 54.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  63%|██████▎   | 2.21G/3.50G [00:38<00:19, 65.2MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██████▎   | 2.22G/3.50G [00:39<00:18, 68.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.08G/9.98G [00:39<02:31, 52.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.10G/9.98G [00:39<02:36, 50.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  64%|██████▍   | 2.24G/3.50G [00:39<00:22, 55.4MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██████▍   | 2.26G/3.50G [00:39<00:20, 59.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.11G/9.98G [00:39<03:02, 43.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  65%|██████▍   | 2.27G/3.50G [00:39<00:20, 61.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██▏       | 2.13G/9.98G [00:40<02:38, 49.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  65%|██████▌   | 2.29G/3.50G [00:40<00:18, 64.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██▏       | 2.14G/9.98G [00:40<02:22, 54.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  66%|██████▌   | 2.30G/3.50G [00:40<00:19, 62.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.16G/9.98G [00:40<02:03, 63.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.17G/9.98G [00:40<01:53, 68.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  66%|██████▋   | 2.32G/3.50G [00:40<00:18, 65.0MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██████▋   | 2.34G/3.50G [00:40<00:17, 66.4MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██████▋   | 2.35G/3.50G [00:41<00:17, 66.3MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  68%|██████▊   | 2.37G/3.50G [00:41<00:15, 70.8MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  68%|██████▊   | 2.38G/3.50G [00:41<00:15, 72.0MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  69%|██████▊   | 2.40G/3.50G [00:41<00:14, 75.0MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  69%|██████▉   | 2.42G/3.50G [00:41<00:14, 77.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.18G/9.98G [00:42<06:10, 21.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  69%|██████▉   | 2.43G/3.50G [00:42<00:15, 68.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.19G/9.98G [00:42<05:03, 25.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  70%|██████▉   | 2.45G/3.50G [00:42<00:16, 64.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.21G/9.98G [00:42<04:05, 31.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  70%|███████   | 2.46G/3.50G [00:42<00:16, 64.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.22G/9.98G [00:42<03:14, 39.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  71%|███████   | 2.48G/3.50G [00:42<00:15, 66.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.24G/9.98G [00:43<02:51, 45.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  71%|███████▏  | 2.50G/3.50G [00:43<00:14, 67.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.26G/9.98G [00:43<02:22, 54.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  72%|███████▏  | 2.51G/3.50G [00:43<00:17, 56.7MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  72%|███████▏  | 2.53G/3.50G [00:43<00:16, 58.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.27G/9.98G [00:43<03:06, 41.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  73%|███████▎  | 2.54G/3.50G [00:44<00:16, 57.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.29G/9.98G [00:44<02:51, 44.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  73%|███████▎  | 2.56G/3.50G [00:44<00:14, 64.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.30G/9.98G [00:44<02:37, 48.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  73%|███████▎  | 2.56G/3.50G [00:44<00:16, 56.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.32G/9.98G [00:44<02:21, 53.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  74%|███████▎  | 2.58G/3.50G [00:44<00:17, 53.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.34G/9.98G [00:44<02:09, 59.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  74%|███████▍  | 2.59G/3.50G [00:44<00:15, 57.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▎       | 2.35G/9.98G [00:45<02:03, 61.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▍  | 2.61G/3.50G [00:45<00:14, 61.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▎       | 2.37G/9.98G [00:45<01:58, 64.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▍  | 2.62G/3.50G [00:45<00:14, 60.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.38G/9.98G [00:45<01:54, 66.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▌  | 2.64G/3.50G [00:45<00:13, 62.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.40G/9.98G [00:45<02:01, 62.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.42G/9.98G [00:46<01:57, 64.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  76%|███████▌  | 2.66G/3.50G [00:46<00:17, 47.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.43G/9.98G [00:46<01:55, 65.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  76%|███████▋  | 2.67G/3.50G [00:46<00:17, 48.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.45G/9.98G [00:46<02:01, 61.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.46G/9.98G [00:46<01:56, 64.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  77%|███████▋  | 2.69G/3.50G [00:46<00:15, 51.7MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  77%|███████▋  | 2.70G/3.50G [00:46<00:13, 59.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.48G/9.98G [00:47<01:59, 62.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  78%|███████▊  | 2.72G/3.50G [00:47<00:13, 58.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.50G/9.98G [00:47<02:00, 62.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  78%|███████▊  | 2.74G/3.50G [00:47<00:12, 60.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.51G/9.98G [00:47<01:48, 68.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  79%|███████▊  | 2.75G/3.50G [00:47<00:12, 61.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.53G/9.98G [00:47<01:53, 65.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  79%|███████▉  | 2.77G/3.50G [00:47<00:11, 63.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.54G/9.98G [00:47<01:50, 67.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  80%|███████▉  | 2.78G/3.50G [00:48<00:11, 61.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.56G/9.98G [00:48<01:55, 64.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  80%|███████▉  | 2.80G/3.50G [00:48<00:11, 62.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.58G/9.98G [00:48<02:06, 58.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  80%|████████  | 2.82G/3.50G [00:48<00:10, 63.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.59G/9.98G [00:48<02:01, 60.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  81%|████████  | 2.83G/3.50G [00:48<00:10, 66.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.61G/9.98G [00:49<01:55, 63.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  81%|████████▏ | 2.85G/3.50G [00:49<00:10, 64.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▋       | 2.62G/9.98G [00:49<01:51, 66.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▋       | 2.64G/9.98G [00:49<01:46, 69.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  82%|████████▏ | 2.86G/3.50G [00:49<00:10, 61.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.66G/9.98G [00:49<01:43, 70.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  82%|████████▏ | 2.88G/3.50G [00:49<00:10, 59.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.67G/9.98G [00:49<01:42, 71.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  83%|████████▎ | 2.90G/3.50G [00:50<00:09, 61.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.69G/9.98G [00:50<01:45, 69.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  83%|████████▎ | 2.91G/3.50G [00:50<00:09, 64.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.70G/9.98G [00:50<01:44, 69.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  84%|████████▎ | 2.93G/3.50G [00:50<00:08, 67.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.72G/9.98G [00:50<01:46, 68.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  84%|████████▍ | 2.94G/3.50G [00:50<00:08, 62.5MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|████████▍ | 2.96G/3.50G [00:51<00:08, 61.3MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|████████▌ | 2.98G/3.50G [00:51<00:08, 62.5MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|████████▌ | 2.99G/3.50G [00:51<00:07, 69.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.74G/9.98G [00:51<03:22, 35.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  86%|████████▌ | 3.01G/3.50G [00:51<00:07, 64.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.75G/9.98G [00:51<02:58, 40.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  86%|████████▋ | 3.02G/3.50G [00:51<00:07, 66.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.77G/9.98G [00:52<02:31, 47.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  87%|████████▋ | 3.04G/3.50G [00:52<00:06, 73.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.78G/9.98G [00:52<02:19, 51.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  87%|████████▋ | 3.06G/3.50G [00:52<00:06, 69.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.80G/9.98G [00:52<02:40, 44.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  88%|████████▊ | 3.07G/3.50G [00:52<00:07, 56.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.82G/9.98G [00:53<02:21, 50.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  88%|████████▊ | 3.09G/3.50G [00:53<00:06, 61.8MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  89%|████████▊ | 3.10G/3.50G [00:53<00:05, 72.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.83G/9.98G [00:53<02:08, 55.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  89%|████████▉ | 3.11G/3.50G [00:53<00:05, 65.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▊       | 2.84G/9.98G [00:53<01:53, 63.1MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  89%|████████▉ | 3.12G/3.50G [00:53<00:06, 61.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▊       | 2.85G/9.98G [00:53<02:09, 54.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  90%|████████▉ | 3.14G/3.50G [00:53<00:06, 60.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▊       | 2.86G/9.98G [00:53<02:20, 50.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  90%|█████████ | 3.15G/3.50G [00:54<00:05, 61.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.88G/9.98G [00:54<02:04, 57.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.89G/9.98G [00:54<01:48, 65.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  91%|█████████ | 3.17G/3.50G [00:54<00:05, 66.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.90G/9.98G [00:54<01:57, 60.5MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  91%|█████████ | 3.18G/3.50G [00:54<00:04, 65.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.91G/9.98G [00:54<02:02, 57.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  91%|█████████▏| 3.20G/3.50G [00:54<00:04, 68.1MB/s]#033[A#033[A\n",
      "pytorch_model-00002-of-00002.bin:  92%|█████████▏| 3.21G/3.50G [00:54<00:04, 72.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.93G/9.98G [00:54<02:03, 57.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  92%|█████████▏| 3.22G/3.50G [00:55<00:04, 59.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.94G/9.98G [00:55<01:56, 60.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  92%|█████████▏| 3.23G/3.50G [00:55<00:04, 63.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.96G/9.98G [00:55<01:56, 60.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.97G/9.98G [00:55<01:43, 67.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  93%|█████████▎| 3.25G/3.50G [00:55<00:04, 54.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.98G/9.98G [00:55<01:58, 59.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  93%|█████████▎| 3.26G/3.50G [00:55<00:04, 57.9MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.99G/9.98G [00:55<02:03, 56.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  94%|█████████▎| 3.28G/3.50G [00:56<00:03, 57.2MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.01G/9.98G [00:56<02:01, 57.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  94%|█████████▍| 3.30G/3.50G [00:56<00:03, 58.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.02G/9.98G [00:56<01:59, 58.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  95%|█████████▍| 3.31G/3.50G [00:56<00:03, 60.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.04G/9.98G [00:56<01:56, 59.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  95%|█████████▌| 3.33G/3.50G [00:56<00:02, 72.1MB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.06G/9.98G [00:56<01:48, 63.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.07G/9.98G [00:57<01:43, 66.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  95%|█████████▌| 3.34G/3.50G [00:57<00:03, 42.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.09G/9.98G [00:57<01:41, 67.8MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  96%|█████████▌| 3.34G/3.50G [00:57<00:03, 41.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.10G/9.98G [00:57<01:36, 71.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  31%|███▏      | 3.12G/9.98G [00:57<01:41, 67.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  96%|█████████▌| 3.36G/3.50G [00:57<00:03, 43.6MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███▏      | 3.14G/9.98G [00:58<01:52, 60.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  96%|█████████▋| 3.38G/3.50G [00:58<00:02, 43.5MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.15G/9.98G [00:58<01:48, 62.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.17G/9.98G [00:58<01:52, 60.6MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  97%|█████████▋| 3.39G/3.50G [00:58<00:03, 34.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.18G/9.98G [00:58<01:49, 62.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  97%|█████████▋| 3.41G/3.50G [00:59<00:02, 39.3MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.20G/9.98G [00:59<01:46, 63.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.21G/9.98G [00:59<01:42, 66.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.22G/9.98G [00:59<01:51, 60.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  98%|█████████▊| 3.42G/3.50G [00:59<00:01, 40.0MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.23G/9.98G [00:59<01:47, 62.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.25G/9.98G [00:59<01:34, 71.3MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  98%|█████████▊| 3.44G/3.50G [00:59<00:01, 40.1MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.26G/9.98G [01:00<01:41, 66.2MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  99%|█████████▊| 3.46G/3.50G [01:00<00:01, 41.7MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.28G/9.98G [01:00<01:41, 65.9MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  99%|█████████▉| 3.47G/3.50G [01:00<00:00, 44.8MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.30G/9.98G [01:00<01:52, 59.4MB/s]\n",
      "pytorch_model-00002-of-00002.bin: 100%|█████████▉| 3.49G/3.50G [01:00<00:00, 47.4MB/s]#033[A#033[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.31G/9.98G [01:00<01:41, 66.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.33G/9.98G [01:01<01:31, 73.0MB/s]\n",
      "pytorch_model-00002-of-00002.bin: 100%|██████████| 3.50G/3.50G [01:01<00:00, 57.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▎      | 3.34G/9.98G [01:01<01:37, 68.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▎      | 3.36G/9.98G [01:01<01:26, 76.1MB/s]\n",
      "Upload 2 LFS files:  50%|█████     | 1/2 [01:01<01:01, 61.46s/it]\n",
      "#033[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.38G/9.98G [01:01<02:07, 51.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.39G/9.98G [01:02<01:51, 58.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.41G/9.98G [01:02<01:47, 61.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.42G/9.98G [01:02<01:38, 66.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.44G/9.98G [01:02<01:34, 69.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.46G/9.98G [01:03<01:31, 71.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.47G/9.98G [01:03<01:30, 71.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.49G/9.98G [01:03<01:32, 70.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▌      | 3.50G/9.98G [01:03<01:58, 54.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▌      | 3.52G/9.98G [01:04<01:44, 61.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▌      | 3.54G/9.98G [01:04<01:43, 62.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.55G/9.98G [01:04<01:38, 65.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.57G/9.98G [01:04<01:42, 62.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.58G/9.98G [01:05<01:38, 65.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.60G/9.98G [01:05<01:36, 66.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.62G/9.98G [01:05<01:35, 66.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▋      | 3.63G/9.98G [01:05<01:33, 67.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.65G/9.98G [01:06<01:35, 66.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.66G/9.98G [01:06<01:36, 65.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.68G/9.98G [01:06<01:26, 72.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.68G/9.98G [01:06<01:35, 65.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.70G/9.98G [01:06<01:47, 58.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.71G/9.98G [01:07<02:10, 48.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.73G/9.98G [01:07<02:00, 51.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.74G/9.98G [01:07<01:43, 60.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.75G/9.98G [01:07<02:02, 50.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.76G/9.98G [01:09<04:44, 21.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.78G/9.98G [01:09<03:35, 28.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.79G/9.98G [01:09<02:51, 36.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.81G/9.98G [01:09<02:16, 45.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.82G/9.98G [01:10<01:58, 51.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.84G/9.98G [01:10<02:04, 49.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▊      | 3.86G/9.98G [01:10<01:50, 55.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.87G/9.98G [01:10<01:45, 58.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.89G/9.98G [01:11<01:39, 61.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.90G/9.98G [01:11<01:27, 69.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.91G/9.98G [01:11<01:31, 66.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.92G/9.98G [01:11<01:38, 61.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.94G/9.98G [01:11<01:25, 71.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  40%|███▉      | 3.95G/9.98G [01:12<01:37, 61.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  40%|███▉      | 3.97G/9.98G [01:12<01:28, 68.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  40%|███▉      | 3.98G/9.98G [01:12<01:29, 67.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  40%|████      | 4.00G/9.98G [01:12<01:24, 70.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  40%|████      | 4.02G/9.98G [01:12<01:20, 74.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  40%|████      | 4.03G/9.98G [01:13<01:17, 76.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.05G/9.98G [01:13<01:09, 85.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.06G/9.98G [01:13<01:11, 82.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.08G/9.98G [01:13<01:10, 83.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.10G/9.98G [01:13<01:12, 81.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.11G/9.98G [01:14<01:15, 77.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  41%|████▏     | 4.13G/9.98G [01:14<01:19, 73.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.14G/9.98G [01:14<01:18, 74.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.16G/9.98G [01:14<01:10, 82.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.18G/9.98G [01:14<01:11, 80.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.19G/9.98G [01:15<01:18, 74.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.21G/9.98G [01:15<01:19, 72.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.22G/9.98G [01:15<01:23, 69.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.24G/9.98G [01:15<01:19, 72.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.26G/9.98G [01:16<01:26, 66.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.27G/9.98G [01:16<01:19, 72.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.29G/9.98G [01:16<01:22, 68.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.30G/9.98G [01:16<01:22, 69.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.32G/9.98G [01:16<01:21, 69.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.34G/9.98G [01:17<01:20, 69.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▎     | 4.35G/9.98G [01:17<01:22, 68.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.37G/9.98G [01:17<01:17, 72.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.38G/9.98G [01:17<01:15, 73.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.40G/9.98G [01:18<01:51, 50.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.42G/9.98G [01:18<01:35, 58.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.43G/9.98G [01:18<01:26, 64.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▍     | 4.45G/9.98G [01:18<01:17, 71.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▍     | 4.46G/9.98G [01:19<01:15, 73.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▍     | 4.48G/9.98G [01:19<01:10, 77.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▌     | 4.50G/9.98G [01:19<01:11, 77.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▌     | 4.51G/9.98G [01:19<01:12, 75.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▌     | 4.53G/9.98G [01:19<01:13, 74.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.54G/9.98G [01:20<01:16, 71.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.56G/9.98G [01:20<01:18, 69.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.58G/9.98G [01:20<01:15, 71.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.59G/9.98G [01:20<01:23, 64.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.61G/9.98G [01:21<01:16, 70.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▋     | 4.62G/9.98G [01:21<01:12, 74.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.64G/9.98G [01:21<01:17, 69.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.66G/9.98G [01:21<01:07, 79.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.67G/9.98G [01:22<01:16, 69.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.69G/9.98G [01:22<01:15, 70.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.70G/9.98G [01:22<01:11, 73.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.72G/9.98G [01:22<01:14, 70.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.74G/9.98G [01:22<01:13, 71.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.75G/9.98G [01:23<01:10, 73.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.77G/9.98G [01:23<01:30, 57.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.78G/9.98G [01:23<01:20, 64.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.80G/9.98G [01:23<01:19, 64.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.82G/9.98G [01:24<01:15, 68.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.83G/9.98G [01:24<01:12, 70.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▊     | 4.85G/9.98G [01:24<01:14, 68.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.86G/9.98G [01:24<01:10, 72.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.88G/9.98G [01:25<01:12, 70.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.90G/9.98G [01:25<01:57, 43.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.91G/9.98G [01:25<01:41, 50.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.93G/9.98G [01:26<01:28, 57.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  50%|████▉     | 4.94G/9.98G [01:26<01:19, 63.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  50%|████▉     | 4.96G/9.98G [01:26<01:14, 67.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  50%|████▉     | 4.97G/9.98G [01:26<01:02, 79.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  50%|████▉     | 4.98G/9.98G [01:26<01:12, 68.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  50%|█████     | 4.99G/9.98G [01:26<01:13, 68.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  50%|█████     | 5.01G/9.98G [01:27<01:16, 64.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  50%|█████     | 5.02G/9.98G [01:27<01:04, 76.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.04G/9.98G [01:27<01:06, 74.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.05G/9.98G [01:27<00:59, 83.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.06G/9.98G [01:27<01:08, 71.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.07G/9.98G [01:28<01:12, 67.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.09G/9.98G [01:28<01:46, 45.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.10G/9.98G [01:28<01:42, 47.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████▏    | 5.12G/9.98G [01:29<01:30, 53.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████▏    | 5.14G/9.98G [01:29<01:20, 59.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.15G/9.98G [01:29<01:14, 65.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.17G/9.98G [01:29<01:13, 65.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.18G/9.98G [01:29<01:10, 68.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.20G/9.98G [01:30<01:06, 71.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.22G/9.98G [01:30<01:11, 66.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.23G/9.98G [01:30<01:06, 71.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.25G/9.98G [01:31<01:20, 58.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.26G/9.98G [01:31<01:24, 56.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.28G/9.98G [01:31<01:15, 62.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.30G/9.98G [01:31<01:08, 68.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.31G/9.98G [01:31<01:03, 73.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.33G/9.98G [01:32<01:01, 75.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▎    | 5.34G/9.98G [01:32<01:01, 75.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▎    | 5.36G/9.98G [01:32<01:00, 76.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.38G/9.98G [01:32<01:07, 67.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.39G/9.98G [01:33<01:05, 70.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.41G/9.98G [01:33<01:07, 68.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.42G/9.98G [01:33<01:10, 64.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▍    | 5.44G/9.98G [01:33<01:09, 65.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▍    | 5.46G/9.98G [01:33<01:04, 70.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▍    | 5.47G/9.98G [01:34<01:03, 70.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.49G/9.98G [01:34<01:13, 61.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.50G/9.98G [01:34<01:13, 60.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.52G/9.98G [01:35<01:10, 63.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.54G/9.98G [01:35<01:26, 51.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.55G/9.98G [01:35<01:13, 60.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.57G/9.98G [01:35<01:09, 63.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.58G/9.98G [01:36<01:05, 67.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.60G/9.98G [01:36<01:07, 64.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▋    | 5.62G/9.98G [01:36<01:03, 68.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▋    | 5.63G/9.98G [01:36<01:19, 54.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.65G/9.98G [01:37<01:16, 56.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.66G/9.98G [01:37<01:08, 63.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.68G/9.98G [01:37<01:11, 59.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.70G/9.98G [01:37<01:12, 59.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.71G/9.98G [01:38<01:29, 47.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.73G/9.98G [01:38<01:34, 44.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.74G/9.98G [01:39<01:22, 51.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.76G/9.98G [01:39<01:19, 53.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.78G/9.98G [01:39<01:12, 58.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.79G/9.98G [01:39<01:12, 58.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.81G/9.98G [01:40<01:11, 58.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.82G/9.98G [01:40<01:11, 57.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▊    | 5.84G/9.98G [01:40<01:04, 63.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▊    | 5.86G/9.98G [01:40<01:00, 68.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.87G/9.98G [01:40<00:51, 79.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.89G/9.98G [01:41<00:56, 72.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.90G/9.98G [01:41<00:54, 74.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.92G/9.98G [01:41<00:51, 79.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.94G/9.98G [01:41<00:51, 78.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  60%|█████▉    | 5.95G/9.98G [01:42<00:54, 73.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  60%|█████▉    | 5.97G/9.98G [01:42<00:55, 71.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  60%|█████▉    | 5.98G/9.98G [01:42<00:52, 75.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  60%|██████    | 6.00G/9.98G [01:42<00:49, 79.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  60%|██████    | 6.02G/9.98G [01:42<00:51, 77.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  60%|██████    | 6.03G/9.98G [01:43<00:50, 78.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.05G/9.98G [01:43<00:50, 77.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.06G/9.98G [01:43<00:50, 76.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.08G/9.98G [01:43<01:00, 64.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.10G/9.98G [01:43<00:55, 70.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████▏   | 6.11G/9.98G [01:44<00:59, 65.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████▏   | 6.13G/9.98G [01:44<00:54, 70.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.14G/9.98G [01:44<00:55, 68.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.16G/9.98G [01:45<01:33, 40.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.18G/9.98G [01:45<01:18, 48.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.19G/9.98G [01:46<01:42, 36.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.21G/9.98G [01:46<01:30, 41.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.22G/9.98G [01:46<01:19, 47.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.24G/9.98G [01:48<02:33, 24.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.26G/9.98G [01:48<02:04, 30.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.27G/9.98G [01:48<01:44, 35.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.29G/9.98G [01:48<01:22, 44.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.30G/9.98G [01:49<01:13, 49.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.32G/9.98G [01:49<01:06, 55.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▎   | 6.34G/9.98G [01:49<00:59, 61.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▎   | 6.35G/9.98G [01:49<00:54, 66.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.37G/9.98G [01:50<01:27, 41.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.38G/9.98G [01:50<01:15, 47.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.40G/9.98G [01:51<01:16, 46.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.42G/9.98G [01:51<01:12, 49.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.43G/9.98G [01:51<01:03, 55.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▍   | 6.45G/9.98G [01:51<00:58, 60.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▍   | 6.46G/9.98G [01:51<00:58, 60.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▍   | 6.48G/9.98G [01:52<00:54, 64.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▌   | 6.50G/9.98G [01:52<00:50, 68.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▌   | 6.51G/9.98G [01:52<00:46, 74.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▌   | 6.53G/9.98G [01:52<00:44, 77.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.54G/9.98G [01:52<00:43, 79.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.56G/9.98G [01:53<00:44, 76.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.58G/9.98G [01:53<00:47, 71.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.59G/9.98G [01:53<00:51, 65.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.61G/9.98G [01:54<00:55, 61.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▋   | 6.62G/9.98G [01:54<00:50, 66.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.64G/9.98G [01:54<00:50, 65.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.66G/9.98G [01:54<00:49, 67.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.67G/9.98G [01:54<00:45, 72.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.69G/9.98G [01:55<00:43, 75.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.70G/9.98G [01:55<00:44, 73.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.72G/9.98G [01:55<00:46, 70.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.74G/9.98G [01:55<00:43, 75.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.75G/9.98G [01:56<00:50, 64.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.77G/9.98G [01:56<00:48, 66.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.78G/9.98G [01:56<00:44, 72.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.80G/9.98G [01:56<00:43, 73.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.82G/9.98G [01:56<00:47, 66.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.83G/9.98G [01:57<00:55, 56.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▊   | 6.85G/9.98G [01:57<01:14, 42.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.86G/9.98G [01:58<01:03, 49.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.88G/9.98G [01:58<00:55, 55.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.90G/9.98G [01:58<00:49, 62.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.91G/9.98G [01:58<00:44, 68.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.93G/9.98G [01:58<00:42, 71.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.94G/9.98G [01:59<00:45, 66.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.96G/9.98G [01:59<00:41, 72.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.97G/9.98G [01:59<00:37, 79.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.98G/9.98G [01:59<00:51, 58.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  70%|███████   | 6.99G/9.98G [02:00<00:58, 50.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  70%|███████   | 7.01G/9.98G [02:00<00:54, 54.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  70%|███████   | 7.02G/9.98G [02:00<00:48, 60.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.04G/9.98G [02:00<00:47, 61.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.06G/9.98G [02:01<00:45, 64.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.07G/9.98G [02:01<00:42, 67.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.09G/9.98G [02:01<00:39, 72.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.10G/9.98G [02:01<00:41, 69.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████▏  | 7.12G/9.98G [02:02<01:04, 44.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.14G/9.98G [02:02<00:59, 47.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.15G/9.98G [02:02<00:54, 51.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.17G/9.98G [02:03<00:48, 57.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.18G/9.98G [02:03<00:47, 59.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.20G/9.98G [02:03<00:45, 61.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.22G/9.98G [02:03<00:42, 64.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.23G/9.98G [02:03<00:36, 75.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.25G/9.98G [02:04<00:36, 75.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.26G/9.98G [02:04<00:40, 67.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.28G/9.98G [02:04<00:40, 66.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.29G/9.98G [02:04<00:35, 75.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.30G/9.98G [02:04<00:43, 62.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.31G/9.98G [02:05<00:44, 59.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.33G/9.98G [02:05<00:38, 68.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▎  | 7.34G/9.98G [02:05<00:33, 78.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.36G/9.98G [02:05<00:34, 75.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.38G/9.98G [02:05<00:32, 79.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.39G/9.98G [02:06<00:36, 71.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.41G/9.98G [02:06<00:34, 75.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.42G/9.98G [02:06<00:36, 70.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▍  | 7.44G/9.98G [02:06<00:35, 70.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▍  | 7.46G/9.98G [02:07<00:34, 73.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▍  | 7.47G/9.98G [02:07<00:33, 73.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▌  | 7.49G/9.98G [02:07<00:33, 73.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▌  | 7.50G/9.98G [02:07<00:33, 74.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▌  | 7.52G/9.98G [02:08<00:54, 45.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.54G/9.98G [02:08<00:46, 52.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.55G/9.98G [02:08<00:40, 60.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.57G/9.98G [02:09<00:40, 58.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.58G/9.98G [02:09<00:36, 64.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.60G/9.98G [02:09<00:34, 69.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▋  | 7.62G/9.98G [02:09<00:42, 55.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▋  | 7.63G/9.98G [02:10<00:37, 62.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.65G/9.98G [02:10<00:36, 64.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.66G/9.98G [02:10<00:36, 62.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.68G/9.98G [02:10<00:36, 62.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.70G/9.98G [02:10<00:33, 68.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.71G/9.98G [02:11<00:33, 68.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.73G/9.98G [02:11<00:31, 72.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.74G/9.98G [02:11<00:31, 70.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.76G/9.98G [02:11<00:36, 60.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.78G/9.98G [02:12<00:32, 68.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.79G/9.98G [02:12<00:34, 64.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.81G/9.98G [02:12<00:32, 67.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.82G/9.98G [02:13<00:41, 52.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▊  | 7.84G/9.98G [02:13<00:38, 55.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▊  | 7.86G/9.98G [02:13<00:34, 61.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.87G/9.98G [02:13<00:31, 67.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.89G/9.98G [02:13<00:27, 75.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.90G/9.98G [02:14<00:31, 65.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.92G/9.98G [02:14<00:29, 69.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  80%|███████▉  | 7.94G/9.98G [02:14<00:27, 74.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  80%|███████▉  | 7.95G/9.98G [02:14<00:29, 69.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  80%|███████▉  | 7.97G/9.98G [02:15<00:29, 67.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  80%|████████  | 7.98G/9.98G [02:15<00:47, 42.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  80%|████████  | 8.00G/9.98G [02:16<00:44, 44.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  80%|████████  | 8.02G/9.98G [02:16<00:39, 50.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.03G/9.98G [02:16<00:35, 54.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.05G/9.98G [02:16<00:35, 54.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.06G/9.98G [02:17<00:30, 63.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.08G/9.98G [02:17<00:27, 69.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.10G/9.98G [02:17<00:25, 72.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████▏ | 8.11G/9.98G [02:17<00:30, 61.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████▏ | 8.13G/9.98G [02:18<00:30, 60.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.14G/9.98G [02:18<00:30, 59.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.16G/9.98G [02:18<00:26, 68.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.18G/9.98G [02:18<00:27, 64.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.19G/9.98G [02:19<00:28, 63.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.21G/9.98G [02:19<00:28, 61.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.22G/9.98G [02:19<00:27, 64.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.24G/9.98G [02:20<00:43, 39.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.26G/9.98G [02:20<00:36, 46.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.27G/9.98G [02:20<00:33, 50.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.29G/9.98G [02:20<00:28, 59.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.30G/9.98G [02:21<00:27, 59.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.32G/9.98G [02:21<00:27, 61.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▎ | 8.34G/9.98G [02:21<00:28, 57.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▎ | 8.35G/9.98G [02:22<00:29, 55.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.37G/9.98G [02:22<00:25, 62.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.38G/9.98G [02:22<00:34, 46.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.40G/9.98G [02:23<00:31, 49.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.42G/9.98G [02:23<00:25, 60.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.42G/9.98G [02:23<00:28, 54.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.43G/9.98G [02:23<00:29, 52.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.45G/9.98G [02:24<00:37, 40.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.46G/9.98G [02:24<00:46, 32.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.48G/9.98G [02:25<00:41, 36.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▌ | 8.50G/9.98G [02:25<00:35, 41.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▌ | 8.51G/9.98G [02:25<00:28, 51.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▌ | 8.53G/9.98G [02:25<00:24, 58.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.54G/9.98G [02:25<00:22, 64.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.56G/9.98G [02:26<00:21, 65.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.58G/9.98G [02:26<00:21, 65.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.59G/9.98G [02:26<00:20, 68.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▋ | 8.61G/9.98G [02:26<00:20, 66.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▋ | 8.62G/9.98G [02:27<00:20, 64.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.64G/9.98G [02:27<00:19, 67.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.66G/9.98G [02:27<00:19, 67.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.67G/9.98G [02:27<00:19, 68.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.69G/9.98G [02:28<00:21, 58.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.70G/9.98G [02:28<00:19, 64.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.72G/9.98G [02:28<00:18, 69.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.74G/9.98G [02:28<00:16, 73.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.75G/9.98G [02:29<00:24, 50.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.77G/9.98G [02:29<00:22, 52.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.78G/9.98G [02:29<00:20, 59.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.80G/9.98G [02:29<00:18, 62.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.82G/9.98G [02:30<00:17, 65.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▊ | 8.83G/9.98G [02:30<00:16, 69.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▊ | 8.85G/9.98G [02:30<00:15, 72.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.86G/9.98G [02:30<00:14, 75.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.88G/9.98G [02:30<00:13, 78.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.90G/9.98G [02:31<00:13, 77.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.91G/9.98G [02:31<00:13, 76.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.93G/9.98G [02:31<00:14, 73.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  90%|████████▉ | 8.94G/9.98G [02:31<00:13, 74.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  90%|████████▉ | 8.96G/9.98G [02:32<00:16, 60.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  90%|████████▉ | 8.98G/9.98G [02:32<00:17, 56.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  90%|█████████ | 8.99G/9.98G [02:32<00:15, 61.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  90%|█████████ | 9.01G/9.98G [02:32<00:13, 69.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  90%|█████████ | 9.02G/9.98G [02:33<00:12, 75.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.04G/9.98G [02:33<00:13, 69.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.06G/9.98G [02:33<00:14, 65.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.07G/9.98G [02:33<00:13, 65.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.09G/9.98G [02:34<00:12, 69.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████▏| 9.10G/9.98G [02:34<00:18, 47.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████▏| 9.12G/9.98G [02:34<00:16, 52.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.14G/9.98G [02:35<00:14, 59.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.15G/9.98G [02:35<00:14, 55.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.17G/9.98G [02:35<00:14, 56.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.18G/9.98G [02:35<00:12, 62.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.20G/9.98G [02:36<00:11, 67.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.22G/9.98G [02:36<00:10, 70.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.23G/9.98G [02:36<00:11, 65.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.25G/9.98G [02:37<00:14, 48.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.26G/9.98G [02:37<00:14, 49.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.28G/9.98G [02:37<00:12, 55.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.30G/9.98G [02:37<00:11, 60.7MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.31G/9.98G [02:37<00:10, 66.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.33G/9.98G [02:38<00:09, 69.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▎| 9.34G/9.98G [02:38<00:07, 81.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.36G/9.98G [02:38<00:07, 77.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.38G/9.98G [02:38<00:07, 80.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.39G/9.98G [02:38<00:07, 81.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.41G/9.98G [02:39<00:07, 78.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.42G/9.98G [02:39<00:06, 79.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▍| 9.44G/9.98G [02:39<00:07, 75.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▍| 9.46G/9.98G [02:39<00:06, 82.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▍| 9.47G/9.98G [02:39<00:06, 81.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▌| 9.49G/9.98G [02:40<00:06, 80.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▌| 9.50G/9.98G [02:40<00:05, 82.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▌| 9.52G/9.98G [02:40<00:05, 76.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.54G/9.98G [02:40<00:06, 63.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.55G/9.98G [02:41<00:06, 67.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.57G/9.98G [02:41<00:06, 66.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.58G/9.98G [02:41<00:06, 57.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.60G/9.98G [02:41<00:06, 58.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▋| 9.62G/9.98G [02:42<00:05, 62.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.63G/9.98G [02:42<00:05, 65.1MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.65G/9.98G [02:42<00:05, 65.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.66G/9.98G [02:42<00:04, 66.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.68G/9.98G [02:43<00:05, 56.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.70G/9.98G [02:43<00:04, 62.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.71G/9.98G [02:43<00:03, 66.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.73G/9.98G [02:43<00:03, 70.0MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.74G/9.98G [02:44<00:05, 46.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.76G/9.98G [02:44<00:04, 47.1MB/s]\n",
      "\n",
      "2023-10-09 21:41:20 Uploading - Uploading generated training modelpytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.78G/9.98G [02:45<00:04, 45.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.79G/9.98G [02:45<00:03, 53.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.81G/9.98G [02:45<00:02, 58.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.82G/9.98G [02:45<00:02, 60.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▊| 9.84G/9.98G [02:46<00:02, 62.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.86G/9.98G [02:46<00:01, 61.4MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.87G/9.98G [02:46<00:01, 64.5MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.89G/9.98G [02:46<00:01, 64.3MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.90G/9.98G [02:47<00:01, 61.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.92G/9.98G [02:47<00:00, 65.2MB/s]\n",
      "pytorch_model-00001-of-00002.bin: 100%|█████████▉| 9.94G/9.98G [02:47<00:00, 68.9MB/s]\n",
      "pytorch_model-00001-of-00002.bin: 100%|█████████▉| 9.95G/9.98G [02:47<00:00, 68.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin: 100%|█████████▉| 9.97G/9.98G [02:47<00:00, 73.8MB/s]\n",
      "pytorch_model-00001-of-00002.bin: 100%|██████████| 9.98G/9.98G [02:48<00:00, 59.4MB/s]\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [02:48<00:00, 88.25s/it]#033[A\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [02:48<00:00, 84.23s/it]\n",
      "***Retreiving & Saving Tokenizer***\n",
      "***Pushing Tokenizer to Hub***\n",
      "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]\n",
      "tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 1.99MB/s]\n",
      "2023-10-09 21:41:15,512 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2023-10-09 21:41:15,512 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2023-10-09 21:41:15,512 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2023-10-09 21:41:25 Completed - Training job completed\n",
      "Training seconds: 16151\n",
      "Billable seconds: 16151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.telegram.org/bot***REMOVED***/getMe \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.telegram.org/bot***REMOVED***/sendMessage \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import telegram\n",
    "import my_const\n",
    "\n",
    "api_key = my_const.TELE_API_KEY#'***REMOVED***'\n",
    "usr_id = my_const.TELE_USER #'***REMOVED***'\n",
    "\n",
    "# starting the train job with our uploaded datasets as input\n",
    "try:\n",
    "        huggingface_estimator.fit(wait=True)\n",
    "        msg = 'SageMaker Training Finished!'\n",
    "except Exception as e:\n",
    "        msg = 'SageMaker Training Finished with Error'\n",
    "        print(\"Error: \", e)\n",
    "finally:\n",
    "        bot = telegram.Bot(token=api_key)\n",
    "        async with bot:\n",
    "                await bot.send_message(chat_id=usr_id, text=msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps \n",
    "\n",
    "You can deploy your fine-tuned LLaMA model to a SageMaker endpoint and use it for inference. Check out the [Deploy Falcon 7B & 40B on Amazon SageMaker](https://www.philschmid.de/sagemaker-falcon-llm) and [Securely deploy LLMs inside VPCs with Hugging Face and Amazon SageMaker](https://www.philschmid.de/sagemaker-llm-vpc) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Model from S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.huggingface.model.HuggingFaceModel object at 0x155132770>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "s3_model_uri = \"s3://sagemaker-ms-thesis-llm/models/goatV10-testData-withAutoInference-with-2023-09-02-11-38-37-525/output/model.tar.gz\"\n",
    "image_uri = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi0.9.3-gpu-py39-cu118-ubuntu20.04-v1.0\"\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.4xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(1024), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length of the generation (including input text)\n",
    "  'MAX_BATCH_TOTAL_TOKENS': json.dumps(8192),\n",
    "  # 'HF_MODEL_QUANTIZE': \"bitsandbytes\",# Comment in to quantize\n",
    "# \n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    model_data=s3_model_uri,\n",
    "    env=config,\n",
    "    # source_dir=\"GOAT/code/\",\n",
    "    # entry_point=\"inference.py\"\n",
    ")\n",
    "\n",
    "print(llm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.tokens:Loading cached SSO token for slu-sso\n",
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2023-09-02-11-49-34-978\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-tgi-inference-2023-09-02-11-49-35-809\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-tgi-inference-2023-09-02-11-49-35-809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint huggingface-pytorch-tgi-inference-2023-09-02-11-49-35-809: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm \u001b[39m=\u001b[39m llm_model\u001b[39m.\u001b[39;49mdeploy(\n\u001b[1;32m      2\u001b[0m   initial_instance_count\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m   instance_type\u001b[39m=\u001b[39;49minstance_type,\n\u001b[1;32m      4\u001b[0m   container_startup_health_check_timeout\u001b[39m=\u001b[39;49mhealth_check_timeout, \u001b[39m# 10 minutes to be able to load the model\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/projects/llm-data-driven-optimization/venv_310/lib/python3.10/site-packages/sagemaker/huggingface/model.py:313\u001b[0m, in \u001b[0;36mHuggingFaceModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     inference_tool \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mneuron\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m instance_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mml.inf1\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mneuronx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_uri \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserving_image_uri(\n\u001b[1;32m    308\u001b[0m         region_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_session\u001b[39m.\u001b[39mboto_session\u001b[39m.\u001b[39mregion_name,\n\u001b[1;32m    309\u001b[0m         instance_type\u001b[39m=\u001b[39minstance_type,\n\u001b[1;32m    310\u001b[0m         inference_tool\u001b[39m=\u001b[39minference_tool,\n\u001b[1;32m    311\u001b[0m     )\n\u001b[0;32m--> 313\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(HuggingFaceModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mdeploy(\n\u001b[1;32m    314\u001b[0m     initial_instance_count,\n\u001b[1;32m    315\u001b[0m     instance_type,\n\u001b[1;32m    316\u001b[0m     serializer,\n\u001b[1;32m    317\u001b[0m     deserializer,\n\u001b[1;32m    318\u001b[0m     accelerator_type,\n\u001b[1;32m    319\u001b[0m     endpoint_name,\n\u001b[1;32m    320\u001b[0m     tags,\n\u001b[1;32m    321\u001b[0m     kms_key,\n\u001b[1;32m    322\u001b[0m     wait,\n\u001b[1;32m    323\u001b[0m     data_capture_config,\n\u001b[1;32m    324\u001b[0m     async_inference_config,\n\u001b[1;32m    325\u001b[0m     serverless_inference_config,\n\u001b[1;32m    326\u001b[0m     volume_size\u001b[39m=\u001b[39;49mvolume_size,\n\u001b[1;32m    327\u001b[0m     model_data_download_timeout\u001b[39m=\u001b[39;49mmodel_data_download_timeout,\n\u001b[1;32m    328\u001b[0m     container_startup_health_check_timeout\u001b[39m=\u001b[39;49mcontainer_startup_health_check_timeout,\n\u001b[1;32m    329\u001b[0m     inference_recommendation_id\u001b[39m=\u001b[39;49minference_recommendation_id,\n\u001b[1;32m    330\u001b[0m     explainer_config\u001b[39m=\u001b[39;49mexplainer_config,\n\u001b[1;32m    331\u001b[0m )\n",
      "File \u001b[0;32m~/projects/llm-data-driven-optimization/venv_310/lib/python3.10/site-packages/sagemaker/model.py:1430\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[39mif\u001b[39;00m is_explainer_enabled:\n\u001b[1;32m   1428\u001b[0m     explainer_config_dict \u001b[39m=\u001b[39m explainer_config\u001b[39m.\u001b[39m_to_request_dict()\n\u001b[0;32m-> 1430\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msagemaker_session\u001b[39m.\u001b[39;49mendpoint_from_production_variants(\n\u001b[1;32m   1431\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint_name,\n\u001b[1;32m   1432\u001b[0m     production_variants\u001b[39m=\u001b[39;49m[production_variant],\n\u001b[1;32m   1433\u001b[0m     tags\u001b[39m=\u001b[39;49mtags,\n\u001b[1;32m   1434\u001b[0m     kms_key\u001b[39m=\u001b[39;49mkms_key,\n\u001b[1;32m   1435\u001b[0m     wait\u001b[39m=\u001b[39;49mwait,\n\u001b[1;32m   1436\u001b[0m     data_capture_config_dict\u001b[39m=\u001b[39;49mdata_capture_config_dict,\n\u001b[1;32m   1437\u001b[0m     explainer_config_dict\u001b[39m=\u001b[39;49mexplainer_config_dict,\n\u001b[1;32m   1438\u001b[0m     async_inference_config_dict\u001b[39m=\u001b[39;49masync_inference_config_dict,\n\u001b[1;32m   1439\u001b[0m )\n\u001b[1;32m   1441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor_cls:\n\u001b[1;32m   1442\u001b[0m     predictor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor_cls(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_session)\n",
      "File \u001b[0;32m~/projects/llm-data-driven-optimization/venv_310/lib/python3.10/site-packages/sagemaker/session.py:4727\u001b[0m, in \u001b[0;36mSession.endpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict)\u001b[0m\n\u001b[1;32m   4724\u001b[0m LOGGER\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mCreating endpoint-config with name \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, name)\n\u001b[1;32m   4725\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_client\u001b[39m.\u001b[39mcreate_endpoint_config(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig_options)\n\u001b[0;32m-> 4727\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_endpoint(\n\u001b[1;32m   4728\u001b[0m     endpoint_name\u001b[39m=\u001b[39;49mname, config_name\u001b[39m=\u001b[39;49mname, tags\u001b[39m=\u001b[39;49mendpoint_tags, wait\u001b[39m=\u001b[39;49mwait\n\u001b[1;32m   4729\u001b[0m )\n",
      "File \u001b[0;32m~/projects/llm-data-driven-optimization/venv_310/lib/python3.10/site-packages/sagemaker/session.py:4072\u001b[0m, in \u001b[0;36mSession.create_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   4068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_client\u001b[39m.\u001b[39mcreate_endpoint(\n\u001b[1;32m   4069\u001b[0m     EndpointName\u001b[39m=\u001b[39mendpoint_name, EndpointConfigName\u001b[39m=\u001b[39mconfig_name, Tags\u001b[39m=\u001b[39mtags\n\u001b[1;32m   4070\u001b[0m )\n\u001b[1;32m   4071\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m-> 4072\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait_for_endpoint(endpoint_name)\n\u001b[1;32m   4073\u001b[0m \u001b[39mreturn\u001b[39;00m endpoint_name\n",
      "File \u001b[0;32m~/projects/llm-data-driven-optimization/venv_310/lib/python3.10/site-packages/sagemaker/session.py:4424\u001b[0m, in \u001b[0;36mSession.wait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m   4418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCapacityError\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(reason):\n\u001b[1;32m   4419\u001b[0m         \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mCapacityError(\n\u001b[1;32m   4420\u001b[0m             message\u001b[39m=\u001b[39mmessage,\n\u001b[1;32m   4421\u001b[0m             allowed_statuses\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mInService\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   4422\u001b[0m             actual_status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m   4423\u001b[0m         )\n\u001b[0;32m-> 4424\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   4425\u001b[0m         message\u001b[39m=\u001b[39mmessage,\n\u001b[1;32m   4426\u001b[0m         allowed_statuses\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mInService\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   4427\u001b[0m         actual_status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m   4428\u001b[0m     )\n\u001b[1;32m   4429\u001b[0m \u001b[39mreturn\u001b[39;00m desc\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint huggingface-pytorch-tgi-inference-2023-09-02-11-49-35-809: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.."
     ]
    }
   ],
   "source": [
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.telegram.org/bot***REMOVED***/getMe \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.telegram.org/bot***REMOVED***/sendMessage \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import telegram\n",
    "import asyncio\n",
    "\n",
    "api_key = '***REMOVED***'\n",
    "usr_id = '***REMOVED***'\n",
    "\n",
    "bot = telegram.Bot(token=api_key)\n",
    "async with bot:\n",
    "        await bot.send_message(chat_id=usr_id, text='SageMaker Model Deploy Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Input Data for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple String Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.pad_token_id = 0\n",
    "# tokenizer.padding_side = \"left\"  # Allow batched inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "   \"inputs\": \"<s>[INST] <<SYS>>\\n\\n You are a helpful math assistant\\n\\n<<SYS>>\\n\\n10 + 6 = \\n[/INST]<s>\"\n",
    "   # \"inputs\": \"\"\"You are a helpful AI assistant who responds to question simple and straightforward questions.\n",
    "   # Question: What is the Capital of California?\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"prompt\": \"[INST] What is the capital of CA? [/INST]\",\n",
    "    \"system_prompt\": \"You are a helpful assistant\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "{\n",
      "\"outputs\": \" <<SYS>>\\n\\n You are a helpful math assistant\\n\\n<<SYS>>\\n\\n10 + 6 = 16\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "  \"inputs\":  json.dumps(data),\n",
    "  \"parameters\": {\n",
    "    # \"do_sample\": True,\n",
    "    \"top_p\": 0.6,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\": 50,\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    # \"stop\": [\"</s>\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "# send request to endpoint\n",
    "response = llm.predict(payload)\n",
    "\n",
    "print(response[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
