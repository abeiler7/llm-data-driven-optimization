{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_PROFILE=dev-admin\n",
      "env: AWS_REGION=us-east-1\n",
      "env: HF_HOME=~/.cache/huggingface\n",
      "env: TOKENIZERS_PARALLELISM=fale\n"
     ]
    }
   ],
   "source": [
    "%env AWS_PROFILE=dev-admin\n",
    "%env AWS_REGION=us-east-1\n",
    "%env HF_HOME=~/.cache/huggingface\n",
    "%env TOKENIZERS_PARALLELISM=fale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker bucket: sagemaker-ms-thesis-llm\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "from scripts.aws_init import init_sagemaker\n",
    "\n",
    "sagemaker_session_bucket = \"sagemaker-ms-thesis-llm\"\n",
    "role = \"arn:aws:iam::171706357329:role/service-role/AmazonSageMakerServiceCatalogProductsExecutionRole\"\n",
    "\n",
    "sess = init_sagemaker(sagemaker_session_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewbeiler/projects/llm-data-driven-optimization/venv_310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset json (/Users/andrewbeiler/.cache/huggingface/datasets/tiedong___json/tiedong--goat-55b7467c033a1462/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 1746300\n",
      "Example Datapoint {'instruction': '1449119*27', 'output': '1449119 * 27 = 1449119 * (20 + 7) = 1449119 * 20 + 1449119 * 7 = 28982380 + 10143833 = 39126213', 'answer': '39126213', 'input': '1449119 * 27'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "\n",
    "tokenizer = None\n",
    "\n",
    "cutoff_len = 512\n",
    "\n",
    "dataset = load_dataset(\"tiedong/goat\", split=\"train\")\n",
    "print(f\"dataset size: {len(dataset)}\")\n",
    "print(f\"Example Datapoint {dataset[randrange(len(dataset))]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_sample size: 10\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "n_samples = 10#0000\n",
    "n_shards = math.ceil(len(dataset)/n_samples)\n",
    "dataset_sampled = dataset.shard(n_shards,2)\n",
    "print(f\"dataset_sample size: {len(dataset_sampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = dataset_sampled.train_test_split(\n",
    "    test_size=0.15, shuffle=True, seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "/Users/andrewbeiler/projects/llm-data-driven-optimization/venv_310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.pad_token_id = 0\n",
    "# tokenizer.padding_side = \"left\"  # Allow batched inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(prompt, add_eos_token=True):\n",
    "        result = tokenizer(\n",
    "            prompt,\n",
    "            # truncation=True,\n",
    "            # max_length=cutoff_len,\n",
    "            # return_tensors=None,\n",
    "        )\n",
    "        # print(f\"Result: {result}\")\n",
    "        # if (\n",
    "        #     result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        #     and len(result[\"input_ids\"]) < cutoff_len\n",
    "        #     and add_eos_token\n",
    "        # ):\n",
    "        #     result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        #     result[\"attention_mask\"].append(1)\n",
    "\n",
    "        # result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_goat(sample):\n",
    "    # instruction = f\"### Instruction\\n{sample['instruction']}\"\n",
    "    # # context = f\"### Context\\n{sample['context']}\" if len(sample[\"context\"]) > 0 else None\n",
    "    # response = f\"### Answer\\n{sample['output']}\"\n",
    "    # # join all the parts together\n",
    "    # # prompt = \"\\n\\n\".join([i for i in [instruction, context, response] if i is not None])\n",
    "    # prompt = \"\\n\\n\".join([i for i in [instruction, response] if i is not None])\n",
    "    # return prompt\n",
    "    return f\"<s>[INST] {sample['instruction']} [/INST] {sample['output']}</s>\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompter import Prompter\n",
    "\n",
    "prompter = Prompter()\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "        # full_prompt = prompter.generate_prompt(\n",
    "        #     data_point[\"instruction\"],\n",
    "        #     data_point[\"output\"],\n",
    "        # )\n",
    "        full_prompt = format_goat(data_point)\n",
    "        print(f\"Full Prompt: {full_prompt}\")\n",
    "        tokenized_full_prompt = tokenize(full_prompt)\n",
    "        # print(f\"Tokenized Prompt: {tokenized_full_prompt}\")\n",
    "        return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "# empty list to save remainder from batches to use in next batch\n",
    "remainder = {\"input_ids\": [], \"attention_mask\": [], \"token_type_ids\": []}\n",
    "\n",
    "def chunk(sample, chunk_length=2048):\n",
    "    # define global remainder variable to save remainder from batches to use in next batch\n",
    "    global remainder\n",
    "    batch_chunk_length = 0\n",
    "    # Concatenate all texts and add remainder from previous batch\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "    concatenated_examples = {k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()}\n",
    "    # get total number of tokens for batch\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "\n",
    "    # get max number of chunks for batch\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_chunk_length = (batch_total_length // chunk_length) * chunk_length\n",
    "    else:\n",
    "        batch_chunk_length = batch_total_length\n",
    "    \n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # add remainder to global variable for next batch\n",
    "    remainder = {k: concatenated_examples[k][batch_chunk_length:] for k in concatenated_examples.keys()}\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "# # tokenize and chunk dataset\n",
    "# lm_dataset = dataset_sampled.map(\n",
    "#     lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(dataset_sampled.features)\n",
    "# ).map(\n",
    "#     partial(chunk, chunk_length=2048),\n",
    "#     batched=True,\n",
    "# )\n",
    "\n",
    "# # Print total number of samples\n",
    "# print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/andrewbeiler/.cache/huggingface/datasets/tiedong___json/tiedong--goat-55b7467c033a1462/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-434482acd5484a9b.arrow\n",
      "Loading cached processed dataset at /Users/andrewbeiler/.cache/huggingface/datasets/tiedong___json/tiedong--goat-55b7467c033a1462/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-f16f2df15bfe1847.arrow\n",
      "Loading cached processed dataset at /Users/andrewbeiler/.cache/huggingface/datasets/tiedong___json/tiedong--goat-55b7467c033a1462/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ba0473180637368d.arrow\n",
      "Loading cached processed dataset at /Users/andrewbeiler/.cache/huggingface/datasets/tiedong___json/tiedong--goat-55b7467c033a1462/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-5fcb74cd59e3d8f1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Point: {'input_ids': [1, 1, 518, 25580, 29962, 20535, 403, 278, 1234, 304, 29871, 29953, 29953, 29906, 29941, 29896, 29953, 29896, 29941, 29906, 29953, 29955, 29955, 29896, 29955, 29974, 29953, 29900, 29947, 29947, 29906, 29946, 29900, 29929, 29947, 29900, 29929, 29889, 518, 29914, 25580, 29962, 29871, 29953, 29953, 29906, 29941, 29896, 29953, 29896, 29941, 29906, 29953, 29955, 29955, 29896, 29955, 718, 29871, 29953, 29900, 29947, 29947, 29906, 29946, 29900, 29929, 29947, 29900, 29929, 353, 29871, 29953, 29953, 29906, 29929, 29906, 29946, 29929, 29945, 29953, 29955, 29955, 29945, 29906, 29953, 2, 1, 1, 518, 25580, 29962, 29871, 29941, 29953, 29896, 29900, 29941, 29946, 29906, 29929, 29947, 29929, 29945, 29953, 29945, 29900, 29946, 29914, 29946, 518, 29914, 25580, 29962, 29871, 29941, 29953, 29896, 29900, 29941, 29946, 29906, 29929, 29947, 29929, 29945, 29953, 29945, 29900, 29946, 847, 29871, 29946, 353, 29871, 29929, 29900, 29906, 29945, 29947, 29945, 29955, 29946, 29955, 29941, 29929, 29896, 29906, 29953, 2, 1, 1, 518, 25580, 29962, 3529, 8147, 29871, 29953, 29941, 29929, 29929, 29899, 29953, 29947, 29941, 29945, 322, 2649, 592, 278, 16259, 21957, 29889, 518, 29914, 25580, 29962, 29871, 29953, 29941, 29929, 29929, 448, 29871, 29953, 29947, 29941, 29945, 353, 448, 29946, 29941, 29953, 2, 1, 1, 518, 25580, 29962, 29871, 29896, 29929, 29906, 29946, 29953, 29896, 29900, 29906, 29929, 29955, 29945, 29947, 29941, 29947, 29947, 448, 29871, 29946, 29896, 29929, 29900, 29953, 29953, 29900, 29945, 29941, 29947, 29906, 29955, 29900, 29947, 29953, 518, 29914, 25580, 29962, 29871, 29896, 29929, 29906, 29946, 29953, 29896, 29900, 29906, 29929, 29955, 29945, 29947, 29941, 29947, 29947, 448, 29871, 29946, 29896, 29929, 29900, 29953, 29953, 29900, 29945, 29941, 29947, 29906, 29955, 29900, 29947, 29953, 353, 448, 29906, 29906, 29953, 29953, 29900, 29945, 29900, 29906, 29946, 29900, 29953, 29947, 29953, 29929, 29947, 2, 1, 1, 518, 25580, 29962, 29871, 29947, 29930, 29945, 29953, 29941, 29929, 29900, 29941, 29896, 29945, 29900, 29945, 29941, 29906, 29945, 518, 29914, 25580, 29962, 29871, 29947, 334, 29871, 29945, 29953, 29941, 29929, 29900, 29941, 29896, 29945, 29900, 29945, 29941, 29906, 29945, 353, 29871, 29946, 29945, 29896, 29896, 29906, 29906, 29945, 29906, 29900, 29946, 29906, 29953, 29900, 29900, 2, 1, 1, 518, 25580, 29962, 4250, 2408, 278, 995, 363, 29871, 29941, 29900, 29955, 29946, 847, 29871, 29929, 29953, 29947, 29889, 518, 29914, 25580, 29962, 29871, 29941, 29900, 29955, 29946, 448, 29871, 29929, 29953, 29947, 334, 29871, 29941, 353, 29871, 29941, 29900, 29955, 29946, 448, 29871, 29906, 29929, 29900, 29946, 353, 29871, 29896, 29955, 29900, 13, 8439, 1079, 29892, 29871, 29941, 29900, 29955, 29946, 847, 29871, 29929, 29953, 29947, 353, 29871, 29941, 390, 29871, 29896, 29955, 29900, 2, 1, 1, 518, 25580, 29962, 29871, 29947, 29900, 29896, 29955, 29974, 29945, 29955, 29929, 29955, 29900, 29941, 29941, 518, 29914, 25580, 29962, 29871, 29947, 29900, 29896, 29955, 718, 29871, 29945, 29955, 29929, 29955, 29900, 29941, 29941, 353, 29871, 29945, 29947, 29900, 29945, 29900, 29945, 29900, 2, 1, 1, 518, 25580, 29962, 29871, 29941, 29945, 29929, 29955, 29929, 29941, 29946, 29914, 29955, 518, 29914, 25580, 29962, 29871, 29941, 29945, 29929, 29955, 29929, 29941, 29946, 847, 29871, 29955, 353, 29871, 29945, 29896, 29941, 29929, 29929, 29900, 390, 29871, 29946, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 1, 518, 25580, 29962, 20535, 403, 278, 1234, 304, 29871, 29953, 29953, 29906, 29941, 29896, 29953, 29896, 29941, 29906, 29953, 29955, 29955, 29896, 29955, 29974, 29953, 29900, 29947, 29947, 29906, 29946, 29900, 29929, 29947, 29900, 29929, 29889, 518, 29914, 25580, 29962, 29871, 29953, 29953, 29906, 29941, 29896, 29953, 29896, 29941, 29906, 29953, 29955, 29955, 29896, 29955, 718, 29871, 29953, 29900, 29947, 29947, 29906, 29946, 29900, 29929, 29947, 29900, 29929, 353, 29871, 29953, 29953, 29906, 29929, 29906, 29946, 29929, 29945, 29953, 29955, 29955, 29945, 29906, 29953, 2, 1, 1, 518, 25580, 29962, 29871, 29941, 29953, 29896, 29900, 29941, 29946, 29906, 29929, 29947, 29929, 29945, 29953, 29945, 29900, 29946, 29914, 29946, 518, 29914, 25580, 29962, 29871, 29941, 29953, 29896, 29900, 29941, 29946, 29906, 29929, 29947, 29929, 29945, 29953, 29945, 29900, 29946, 847, 29871, 29946, 353, 29871, 29929, 29900, 29906, 29945, 29947, 29945, 29955, 29946, 29955, 29941, 29929, 29896, 29906, 29953, 2, 1, 1, 518, 25580, 29962, 3529, 8147, 29871, 29953, 29941, 29929, 29929, 29899, 29953, 29947, 29941, 29945, 322, 2649, 592, 278, 16259, 21957, 29889, 518, 29914, 25580, 29962, 29871, 29953, 29941, 29929, 29929, 448, 29871, 29953, 29947, 29941, 29945, 353, 448, 29946, 29941, 29953, 2, 1, 1, 518, 25580, 29962, 29871, 29896, 29929, 29906, 29946, 29953, 29896, 29900, 29906, 29929, 29955, 29945, 29947, 29941, 29947, 29947, 448, 29871, 29946, 29896, 29929, 29900, 29953, 29953, 29900, 29945, 29941, 29947, 29906, 29955, 29900, 29947, 29953, 518, 29914, 25580, 29962, 29871, 29896, 29929, 29906, 29946, 29953, 29896, 29900, 29906, 29929, 29955, 29945, 29947, 29941, 29947, 29947, 448, 29871, 29946, 29896, 29929, 29900, 29953, 29953, 29900, 29945, 29941, 29947, 29906, 29955, 29900, 29947, 29953, 353, 448, 29906, 29906, 29953, 29953, 29900, 29945, 29900, 29906, 29946, 29900, 29953, 29947, 29953, 29929, 29947, 2, 1, 1, 518, 25580, 29962, 29871, 29947, 29930, 29945, 29953, 29941, 29929, 29900, 29941, 29896, 29945, 29900, 29945, 29941, 29906, 29945, 518, 29914, 25580, 29962, 29871, 29947, 334, 29871, 29945, 29953, 29941, 29929, 29900, 29941, 29896, 29945, 29900, 29945, 29941, 29906, 29945, 353, 29871, 29946, 29945, 29896, 29896, 29906, 29906, 29945, 29906, 29900, 29946, 29906, 29953, 29900, 29900, 2, 1, 1, 518, 25580, 29962, 4250, 2408, 278, 995, 363, 29871, 29941, 29900, 29955, 29946, 847, 29871, 29929, 29953, 29947, 29889, 518, 29914, 25580, 29962, 29871, 29941, 29900, 29955, 29946, 448, 29871, 29929, 29953, 29947, 334, 29871, 29941, 353, 29871, 29941, 29900, 29955, 29946, 448, 29871, 29906, 29929, 29900, 29946, 353, 29871, 29896, 29955, 29900, 13, 8439, 1079, 29892, 29871, 29941, 29900, 29955, 29946, 847, 29871, 29929, 29953, 29947, 353, 29871, 29941, 390, 29871, 29896, 29955, 29900, 2, 1, 1, 518, 25580, 29962, 29871, 29947, 29900, 29896, 29955, 29974, 29945, 29955, 29929, 29955, 29900, 29941, 29941, 518, 29914, 25580, 29962, 29871, 29947, 29900, 29896, 29955, 718, 29871, 29945, 29955, 29929, 29955, 29900, 29941, 29941, 353, 29871, 29945, 29947, 29900, 29945, 29900, 29945, 29900, 2, 1, 1, 518, 25580, 29962, 29871, 29941, 29945, 29929, 29955, 29929, 29941, 29946, 29914, 29955, 518, 29914, 25580, 29962, 29871, 29941, 29945, 29929, 29955, 29929, 29941, 29946, 847, 29871, 29955, 353, 29871, 29945, 29896, 29941, 29929, 29929, 29900, 390, 29871, 29946, 2]}\n",
      "Tuning Set: {'input_ids': [1, 1, 518, 25580, 29962, 4505, 29871, 29941, 29900, 29900, 29916, 29953, 29906, 29946, 29900, 29947, 29906, 518, 29914, 25580, 29962, 29871, 29941, 29900, 29900, 334, 29871, 29953, 29906, 29946, 29900, 29947, 29906, 353, 29871, 29896, 29947, 29955, 29906, 29906, 29946, 29953, 29900, 29900, 2, 1, 1, 518, 25580, 29962, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 29916, 29941, 29953, 29945, 29953, 353, 518, 29914, 25580, 29962, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 29871, 29941, 29953, 29945, 29953, 353, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 313, 29941, 29900, 29900, 29900, 718, 29871, 29953, 29900, 29900, 718, 29871, 29945, 29900, 718, 29871, 29953, 29897, 353, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 29871, 29941, 29900, 29900, 29900, 718, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 29871, 29953, 29900, 29900, 718, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 29871, 29945, 29900, 718, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 29871, 29953, 353, 29871, 29953, 29946, 29945, 29896, 29947, 29941, 29929, 29929, 29900, 29900, 29900, 718, 29871, 29896, 29906, 29929, 29900, 29941, 29953, 29955, 29929, 29947, 29900, 29900, 718, 29871, 29896, 29900, 29955, 29945, 29941, 29900, 29953, 29953, 29945, 29900, 718, 29871, 29896, 29906, 29929, 29900, 29941, 29953, 29955, 29929, 29947, 353, 29871, 29955, 29955, 29946, 29906, 29906, 29900, 29955, 29947, 29947, 29900, 29900, 718, 29871, 29896, 29900, 29955, 29945, 29941, 29900, 29953, 29953, 29945, 29900, 718, 29871, 29896, 29906, 29929, 29900, 29941, 29953, 29955, 29929, 29947, 353, 29871, 29955, 29947, 29946, 29929, 29955, 29941, 29947, 29945, 29946, 29945, 29900, 718, 29871, 29896, 29906, 29929, 29900, 29941, 29953, 29955, 29929, 29947, 353, 29871, 29955, 29947, 29953, 29906, 29953, 29946, 29906, 29906, 29906, 29946, 29947, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 1, 518, 25580, 29962, 4505, 29871, 29941, 29900, 29900, 29916, 29953, 29906, 29946, 29900, 29947, 29906, 518, 29914, 25580, 29962, 29871, 29941, 29900, 29900, 334, 29871, 29953, 29906, 29946, 29900, 29947, 29906, 353, 29871, 29896, 29947, 29955, 29906, 29906, 29946, 29953, 29900, 29900, 2, 1, 1, 518, 25580, 29962, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 29916, 29941, 29953, 29945, 29953, 353, 518, 29914, 25580, 29962, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 29871, 29941, 29953, 29945, 29953, 353, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 313, 29941, 29900, 29900, 29900, 718, 29871, 29953, 29900, 29900, 718, 29871, 29945, 29900, 718, 29871, 29953, 29897, 353, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 29871, 29941, 29900, 29900, 29900, 718, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 29871, 29953, 29900, 29900, 718, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 29871, 29945, 29900, 718, 29871, 29906, 29896, 29945, 29900, 29953, 29896, 29941, 29941, 334, 29871, 29953, 353, 29871, 29953, 29946, 29945, 29896, 29947, 29941, 29929, 29929, 29900, 29900, 29900, 718, 29871, 29896, 29906, 29929, 29900, 29941, 29953, 29955, 29929, 29947, 29900, 29900, 718, 29871, 29896, 29900, 29955, 29945, 29941, 29900, 29953, 29953, 29945, 29900, 718, 29871, 29896, 29906, 29929, 29900, 29941, 29953, 29955, 29929, 29947, 353, 29871, 29955, 29955, 29946, 29906, 29906, 29900, 29955, 29947, 29947, 29900, 29900, 718, 29871, 29896, 29900, 29955, 29945, 29941, 29900, 29953, 29953, 29945, 29900, 718, 29871, 29896, 29906, 29929, 29900, 29941, 29953, 29955, 29929, 29947, 353, 29871, 29955, 29947, 29946, 29929, 29955, 29941, 29947, 29945, 29946, 29945, 29900, 718, 29871, 29896, 29906, 29929, 29900, 29941, 29953, 29955, 29929, 29947, 353, 29871, 29955, 29947, 29953, 29906, 29953, 29946, 29906, 29906, 29906, 29946, 29947, 2]}\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "# apply prompt template per sample\n",
    "train_data = (\n",
    "    train_val[\"train\"].map(\n",
    "        generate_and_tokenize_prompt, remove_columns=list(dataset.features)\n",
    "    ).map(\n",
    "        partial(chunk, chunk_length=2048), batched=True,\n",
    "    )\n",
    ")\n",
    "val_data = (\n",
    "    train_val[\"test\"].map(\n",
    "        generate_and_tokenize_prompt, remove_columns=list(dataset.features)\n",
    "    ).map(\n",
    "        partial(chunk, chunk_length=2048), batched=True,\n",
    "    )\n",
    ")\n",
    "# train_data = dataset_sampled.map(generate_and_tokenize_prompt, remove_columns=list(dataset.features))\n",
    "# print random sample\n",
    "print(f\"Training Data Point: {train_data[randint(0, len(train_data)-1)]}\")\n",
    "print(f\"Tuning Set: {val_data[randint(0, len(val_data)-1)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Saved to: s3://sagemaker-ms-thesis-llm/datasets/goat/v9/training\n",
      "Validation Dataset Saved to: s3://sagemaker-ms-thesis-llm/datasets/goat/v9/validation\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "ver = \"v9\"\n",
    "dataset_name = \"goat\"\n",
    "training_data_path = f's3://{sagemaker_session_bucket}/datasets/{dataset_name}/{ver}/training'\n",
    "training_val_path = f's3://{sagemaker_session_bucket}/datasets/{dataset_name}/{ver}/validation'\n",
    "train_data.save_to_disk(training_data_path)\n",
    "val_data.save_to_disk(training_val_path)\n",
    "\n",
    "print(f\"Training Dataset Saved to: {training_data_path}\")\n",
    "print(f\"Validation Dataset Saved to: {training_val_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "import asyncio\n",
    "\n",
    "api_key = '***REMOVED***'\n",
    "usr_id = '***REMOVED***'\n",
    "\n",
    "bot = telegram.Bot(token=api_key)\n",
    "async with bot:\n",
    "        await bot.send_message(chat_id=usr_id, text='Hey!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
